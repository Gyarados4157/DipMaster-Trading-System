#!/usr/bin/env python3
"""
DipMaster Overfitting Detection Suite
è¿‡æ‹Ÿåˆæ£€æµ‹å¥—ä»¶ - å…¨é¢è¯„ä¼°ç­–ç•¥ä¼˜åŒ–ä¸­çš„è¿‡æ‹Ÿåˆé£é™©

ä¸“é—¨ç”¨äºæ£€æµ‹DipMasterç­–ç•¥å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ä¸­å¯èƒ½å­˜åœ¨çš„è¿‡æ‹Ÿåˆç°è±¡ï¼š
1. æ ·æœ¬å†…å¤–è¡¨ç°å·®å¼‚åˆ†æ
2. æ—¶é—´åºåˆ—å‰å‘éªŒè¯
3. å‚æ•°æ•æ„Ÿæ€§åˆ†æ
4. äº¤å‰éªŒè¯æµ‹è¯•
5. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

Author: DipMaster Risk Analysis Team
Date: 2025-08-13
Version: 1.0.0
"""

import sys
import os
import json
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import itertools
import warnings
from scipy import stats
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class OverfittingMetrics:
    """è¿‡æ‹Ÿåˆæ£€æµ‹æŒ‡æ ‡"""
    parameter_set: str
    in_sample_win_rate: float
    out_sample_win_rate: float
    performance_degradation: float
    statistical_significance: float
    parameter_sensitivity: float
    overfitting_score: float  # 0-100, 100è¡¨ç¤ºä¸¥é‡è¿‡æ‹Ÿåˆ
    risk_level: str  # LOW, MEDIUM, HIGH, CRITICAL

class OverfittingDetector:
    """è¿‡æ‹Ÿåˆæ£€æµ‹å™¨"""
    
    def __init__(self):
        self.original_config = {
            'rsi_range': (30, 50),
            'ma_period': 20,
            'profit_target': 0.008,
            'min_holding_minutes': 15,
            'max_holding_minutes': 180
        }
        
        # ä¼˜åŒ–åçš„å‚æ•°ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰
        self.optimized_config = {
            'rsi_range': (40, 60),
            'ma_period': 30,
            'profit_target': 0.012,
            'min_holding_minutes': 15,
            'max_holding_minutes': 180
        }
        
        self.results = {}
        
    def load_historical_data(self, symbol: str = "ICPUSDT") -> pd.DataFrame:
        """åŠ è½½å†å²æ•°æ®"""
        data_file = f"data/market_data/{symbol}_5m_2years.csv"
        
        logger.info(f"ğŸ“Š åŠ è½½æ•°æ®ç”¨äºè¿‡æ‹Ÿåˆæ£€æµ‹: {symbol}")
        
        try:
            df = pd.read_csv(data_file)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            df.sort_index(inplace=True)
            
            logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df)}æ¡è®°å½•")
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def split_data_temporal(self, df: pd.DataFrame, 
                           train_ratio: float = 0.7) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """æ—¶é—´åºåˆ—æ•°æ®åˆ†å‰²"""
        
        split_point = int(len(df) * train_ratio)
        
        train_data = df.iloc[:split_point].copy()
        test_data = df.iloc[split_point:].copy()
        
        logger.info(f"ğŸ”„ æ•°æ®åˆ†å‰²: è®­ç»ƒé›†{len(train_data)}æ¡ ({train_ratio:.0%}), "
                   f"æµ‹è¯•é›†{len(test_data)}æ¡ ({1-train_ratio:.0%})")
        logger.info(f"ğŸ“… è®­ç»ƒæœŸé—´: {train_data.index[0].strftime('%Y-%m-%d')} åˆ° {train_data.index[-1].strftime('%Y-%m-%d')}")
        logger.info(f"ğŸ“… æµ‹è¯•æœŸé—´: {test_data.index[0].strftime('%Y-%m-%d')} åˆ° {test_data.index[-1].strftime('%Y-%m-%d')}")
        
        return train_data, test_data
    
    def calculate_indicators(self, df: pd.DataFrame, ma_period: int = 20) -> pd.DataFrame:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ç§»åŠ¨å¹³å‡çº¿
        df[f'ma{ma_period}'] = df['close'].rolling(ma_period).mean()
        
        # ä»·æ ¼å˜åŒ–
        df['is_dip'] = df['close'] < df['open']
        
        return df
    
    def simulate_strategy(self, df: pd.DataFrame, config: Dict) -> Dict:
        """ç­–ç•¥æ¨¡æ‹Ÿ"""
        
        # è®¡ç®—æŒ‡æ ‡
        df = self.calculate_indicators(df, config['ma_period'])
        
        # åˆå§‹åŒ–
        trades = []
        current_position = None
        capital = 10000
        
        rsi_low, rsi_high = config['rsi_range']
        ma_col = f"ma{config['ma_period']}"
        
        for i in range(len(df)):
            row = df.iloc[i]
            current_time = df.index[i]
            
            # è·³è¿‡ç©ºå€¼
            if pd.isna(row['rsi']) or pd.isna(row[ma_col]):
                continue
            
            # å‡ºåœºæ£€æŸ¥
            if current_position:
                holding_minutes = (current_time - current_position['entry_time']).total_seconds() / 60
                pnl_pct = ((row['close'] - current_position['entry_price']) / current_position['entry_price']) * 100
                
                should_exit = False
                exit_reason = ""
                
                # ç›ˆåˆ©ç›®æ ‡
                if pnl_pct >= config['profit_target'] * 100:
                    should_exit = True
                    exit_reason = "profit_target"
                
                # æœ€å¤§æŒä»“æ—¶é—´
                elif holding_minutes >= config['max_holding_minutes']:
                    should_exit = True
                    exit_reason = "max_holding"
                
                # è¾¹ç•Œå‡ºåœºï¼ˆç®€åŒ–ï¼‰
                elif holding_minutes >= config['min_holding_minutes'] and current_time.minute in [15, 30, 45, 0]:
                    if np.random.random() < 0.7:  # 70%æ¦‚ç‡è¾¹ç•Œå‡ºåœº
                        should_exit = True
                        exit_reason = "boundary"
                
                if should_exit:
                    # è®°å½•äº¤æ˜“
                    pnl_usd = (row['close'] - current_position['entry_price']) * current_position['quantity']
                    commission = abs(pnl_usd) * 0.0008  # åŒè¾¹æ‰‹ç»­è´¹
                    net_pnl = pnl_usd - commission
                    
                    trades.append({
                        'entry_time': current_position['entry_time'],
                        'exit_time': current_time,
                        'entry_price': current_position['entry_price'],
                        'exit_price': row['close'],
                        'holding_minutes': holding_minutes,
                        'pnl_usd': net_pnl,
                        'pnl_percent': pnl_pct,
                        'exit_reason': exit_reason,
                        'win': net_pnl > 0
                    })
                    
                    capital += net_pnl
                    current_position = None
            
            # å…¥åœºæ£€æŸ¥
            if not current_position:
                # DipMasterå…¥åœºæ¡ä»¶
                if (rsi_low <= row['rsi'] <= rsi_high and  # RSIèŒƒå›´
                    row['is_dip'] and                      # é€¢è·Œ
                    row['close'] < row[ma_col]):           # ä½äºMA
                    
                    current_position = {
                        'entry_time': current_time,
                        'entry_price': row['close'],
                        'quantity': 1000 / row['close']  # å›ºå®š1000ç¾å…ƒ
                    }
        
        # è®¡ç®—æŒ‡æ ‡
        if trades:
            wins = [t for t in trades if t['win']]
            win_rate = len(wins) / len(trades) * 100
            total_return = (capital - 10000) / 10000 * 100
            avg_holding = np.mean([t['holding_minutes'] for t in trades])
        else:
            win_rate = 0
            total_return = 0
            avg_holding = 0
        
        return {
            'total_trades': len(trades),
            'win_rate': win_rate,
            'total_return': total_return,
            'final_capital': capital,
            'avg_holding_minutes': avg_holding,
            'trades': trades
        }
    
    def test_parameter_sensitivity(self, df: pd.DataFrame) -> Dict:
        """å‚æ•°æ•æ„Ÿæ€§æµ‹è¯•"""
        
        logger.info("ğŸ”¬ å¼€å§‹å‚æ•°æ•æ„Ÿæ€§åˆ†æ...")
        
        base_config = self.optimized_config.copy()
        sensitivity_results = {}
        
        # æµ‹è¯•RSIèŒƒå›´æ•æ„Ÿæ€§
        rsi_variations = [
            (35, 55), (38, 58), (40, 60), (42, 62), (45, 65)
        ]
        
        rsi_results = []
        for rsi_range in rsi_variations:
            config = base_config.copy()
            config['rsi_range'] = rsi_range
            
            result = self.simulate_strategy(df, config)
            rsi_results.append({
                'rsi_range': rsi_range,
                'win_rate': result['win_rate'],
                'total_return': result['total_return'],
                'total_trades': result['total_trades']
            })
        
        sensitivity_results['rsi_sensitivity'] = rsi_results
        
        # æµ‹è¯•MAå‘¨æœŸæ•æ„Ÿæ€§
        ma_variations = [25, 28, 30, 32, 35]
        
        ma_results = []
        for ma_period in ma_variations:
            config = base_config.copy()
            config['ma_period'] = ma_period
            
            result = self.simulate_strategy(df, config)
            ma_results.append({
                'ma_period': ma_period,
                'win_rate': result['win_rate'],
                'total_return': result['total_return'],
                'total_trades': result['total_trades']
            })
        
        sensitivity_results['ma_sensitivity'] = ma_results
        
        # æµ‹è¯•ç›ˆåˆ©ç›®æ ‡æ•æ„Ÿæ€§
        profit_variations = [0.008, 0.010, 0.012, 0.014, 0.016]
        
        profit_results = []
        for profit_target in profit_variations:
            config = base_config.copy()
            config['profit_target'] = profit_target
            
            result = self.simulate_strategy(df, config)
            profit_results.append({
                'profit_target': profit_target,
                'win_rate': result['win_rate'],
                'total_return': result['total_return'],
                'total_trades': result['total_trades']
            })
        
        sensitivity_results['profit_sensitivity'] = profit_results
        
        logger.info("âœ… å‚æ•°æ•æ„Ÿæ€§åˆ†æå®Œæˆ")
        return sensitivity_results
    
    def forward_validation(self, df: pd.DataFrame, 
                          window_months: int = 6) -> Dict:
        """å‰å‘éªŒè¯ï¼ˆWalk-Forward Analysisï¼‰"""
        
        logger.info(f"ğŸ”„ å¼€å§‹å‰å‘éªŒè¯åˆ†æ (çª—å£: {window_months}ä¸ªæœˆ)")
        
        # æŒ‰æœˆä»½åˆ†å‰²æ•°æ®
        df['year_month'] = df.index.to_period('M')
        monthly_groups = df.groupby('year_month')
        
        # è·å–æ‰€æœ‰æœˆä»½
        all_periods = sorted(df['year_month'].unique())
        
        if len(all_periods) < window_months + 2:
            logger.warning("âš ï¸ æ•°æ®ä¸è¶³ä»¥è¿›è¡Œå‰å‘éªŒè¯")
            return {}
        
        validation_results = []
        
        # æ»‘åŠ¨çª—å£éªŒè¯
        for i in range(len(all_periods) - window_months - 1):
            # è®­ç»ƒæœŸé—´
            train_periods = all_periods[i:i + window_months]
            train_data = pd.concat([monthly_groups.get_group(p) for p in train_periods])
            
            # æµ‹è¯•æœŸé—´ï¼ˆä¸‹ä¸€ä¸ªæœˆï¼‰
            test_period = all_periods[i + window_months]
            test_data = monthly_groups.get_group(test_period)
            
            if len(test_data) < 100:  # è·³è¿‡æ•°æ®ä¸è¶³çš„æœˆä»½
                continue
            
            # åœ¨è®­ç»ƒé›†ä¸Š"ä¼˜åŒ–"ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºä½¿ç”¨å›ºå®šçš„æœ€ä¼˜å‚æ•°ï¼‰
            train_result = self.simulate_strategy(train_data, self.optimized_config)
            
            # åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯
            test_result = self.simulate_strategy(test_data, self.optimized_config)
            
            validation_results.append({
                'train_period': f"{train_periods[0]} to {train_periods[-1]}",
                'test_period': str(test_period),
                'train_win_rate': train_result['win_rate'],
                'test_win_rate': test_result['win_rate'],
                'train_return': train_result['total_return'],
                'test_return': test_result['total_return'],
                'performance_degradation': train_result['win_rate'] - test_result['win_rate'],
                'train_trades': train_result['total_trades'],
                'test_trades': test_result['total_trades']
            })
            
            logger.info(f"ğŸ“Š éªŒè¯ {test_period}: è®­ç»ƒèƒœç‡{train_result['win_rate']:.1f}%, "
                       f"æµ‹è¯•èƒœç‡{test_result['win_rate']:.1f}%, "
                       f"å·®å¼‚{train_result['win_rate'] - test_result['win_rate']:+.1f}%")
        
        return {
            'validation_results': validation_results,
            'avg_performance_degradation': np.mean([r['performance_degradation'] for r in validation_results]) if validation_results else 0,
            'max_performance_degradation': max([r['performance_degradation'] for r in validation_results]) if validation_results else 0,
            'degradation_std': np.std([r['performance_degradation'] for r in validation_results]) if validation_results else 0
        }
    
    def detect_overfitting_comprehensive(self, symbol: str = "ICPUSDT") -> Dict:
        """ç»¼åˆè¿‡æ‹Ÿåˆæ£€æµ‹"""
        
        logger.info("ğŸš¨ å¼€å§‹ç»¼åˆè¿‡æ‹Ÿåˆæ£€æµ‹åˆ†æ")
        
        # åŠ è½½æ•°æ®
        df = self.load_historical_data(symbol)
        if df.empty:
            return {}
        
        # 1. æ ·æœ¬å†…å¤–åˆ†æ
        logger.info("ğŸ“Š Phase 1: æ ·æœ¬å†…å¤–è¡¨ç°åˆ†æ")
        train_data, test_data = self.split_data_temporal(df, 0.7)
        
        # åŸå§‹å‚æ•°è¡¨ç°
        original_train = self.simulate_strategy(train_data, self.original_config)
        original_test = self.simulate_strategy(test_data, self.original_config)
        
        # ä¼˜åŒ–å‚æ•°è¡¨ç°
        optimized_train = self.simulate_strategy(train_data, self.optimized_config)
        optimized_test = self.simulate_strategy(test_data, self.optimized_config)
        
        # 2. å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        logger.info("ğŸ“Š Phase 2: å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_analysis = self.test_parameter_sensitivity(test_data)
        
        # 3. å‰å‘éªŒè¯
        logger.info("ğŸ“Š Phase 3: å‰å‘éªŒè¯åˆ†æ")
        forward_validation = self.forward_validation(df)
        
        # 4. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        logger.info("ğŸ“Š Phase 4: ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ")
        
        # æ¯”è¾ƒåŸå§‹vsä¼˜åŒ–å‚æ•°çš„æ˜¾è‘—æ€§
        if original_test['total_trades'] > 30 and optimized_test['total_trades'] > 30:
            # ä½¿ç”¨èƒœç‡å·®å¼‚è¿›è¡Œtæ£€éªŒï¼ˆç®€åŒ–ï¼‰
            original_wins = [1 if t['win'] else 0 for t in original_test['trades']]
            optimized_wins = [1 if t['win'] else 0 for t in optimized_test['trades']]
            
            if len(original_wins) > 10 and len(optimized_wins) > 10:
                t_stat, p_value = stats.ttest_ind(original_wins, optimized_wins)
            else:
                t_stat, p_value = 0, 1.0
        else:
            t_stat, p_value = 0, 1.0
        
        # 5. è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°
        risk_factors = []
        overfitting_score = 0
        
        # æ ·æœ¬å†…å¤–å·®å¼‚æ£€æŸ¥
        train_test_diff = optimized_train['win_rate'] - optimized_test['win_rate']
        if train_test_diff > 10:  # å·®å¼‚è¶…è¿‡10%
            risk_factors.append("æ ·æœ¬å†…å¤–è¡¨ç°å·®å¼‚è¿‡å¤§")
            overfitting_score += 30
        elif train_test_diff > 5:
            risk_factors.append("æ ·æœ¬å†…å¤–è¡¨ç°å­˜åœ¨å·®å¼‚")
            overfitting_score += 15
        
        # å‚æ•°æ•æ„Ÿæ€§æ£€æŸ¥
        rsi_win_rates = [r['win_rate'] for r in sensitivity_analysis.get('rsi_sensitivity', [])]
        if rsi_win_rates and max(rsi_win_rates) - min(rsi_win_rates) > 15:
            risk_factors.append("å‚æ•°å¯¹RSIèŒƒå›´è¿‡åº¦æ•æ„Ÿ")
            overfitting_score += 25
        
        # å‰å‘éªŒè¯æ£€æŸ¥
        if forward_validation and forward_validation.get('avg_performance_degradation', 0) > 8:
            risk_factors.append("å‰å‘éªŒè¯æ˜¾ç¤ºæ€§èƒ½æ˜¾è‘—è¡°å‡")
            overfitting_score += 35
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€æŸ¥
        if p_value > 0.05:
            risk_factors.append("å‚æ•°æ”¹è¿›ç¼ºä¹ç»Ÿè®¡æ˜¾è‘—æ€§")
            overfitting_score += 20
        
        # ç¡®å®šé£é™©ç­‰çº§
        if overfitting_score >= 70:
            risk_level = "CRITICAL"
        elif overfitting_score >= 50:
            risk_level = "HIGH"  
        elif overfitting_score >= 30:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"
        
        # ç»¼åˆç»“æœ
        comprehensive_results = {
            'symbol': symbol,
            'analysis_date': datetime.now().isoformat(),
            
            'sample_analysis': {
                'original_config': {
                    'train_win_rate': original_train['win_rate'],
                    'test_win_rate': original_test['win_rate'],
                    'performance_diff': original_train['win_rate'] - original_test['win_rate']
                },
                'optimized_config': {
                    'train_win_rate': optimized_train['win_rate'],
                    'test_win_rate': optimized_test['win_rate'],
                    'performance_diff': optimized_train['win_rate'] - optimized_test['win_rate']
                }
            },
            
            'sensitivity_analysis': sensitivity_analysis,
            'forward_validation': forward_validation,
            
            'statistical_test': {
                't_statistic': float(t_stat) if not np.isnan(t_stat) else 0,
                'p_value': float(p_value) if not np.isnan(p_value) else 1.0,
                'significant': p_value < 0.05 if not np.isnan(p_value) else False
            },
            
            'overfitting_assessment': {
                'risk_factors': risk_factors,
                'overfitting_score': overfitting_score,
                'risk_level': risk_level,
                'recommendation': self.get_recommendation(overfitting_score, risk_level)
            }
        }
        
        logger.info(f"âœ… è¿‡æ‹Ÿåˆæ£€æµ‹å®Œæˆ - é£é™©ç­‰çº§: {risk_level} (è¯„åˆ†: {overfitting_score}/100)")
        
        return comprehensive_results
    
    def get_recommendation(self, score: int, risk_level: str) -> str:
        """è·å–å»ºè®®"""
        
        recommendations = {
            "LOW": "ç­–ç•¥å‚æ•°ä¼˜åŒ–åˆç†ï¼Œè¿‡æ‹Ÿåˆé£é™©è¾ƒä½ã€‚å¯ä»¥è°¨æ…ä½¿ç”¨ä¼˜åŒ–åçš„å‚æ•°ï¼Œä½†å»ºè®®æŒç»­ç›‘æ§å®é™…è¡¨ç°ã€‚",
            "MEDIUM": "å­˜åœ¨ä¸­ç­‰ç¨‹åº¦çš„è¿‡æ‹Ÿåˆé£é™©ã€‚å»ºè®®ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°ï¼Œå¢åŠ æ ·æœ¬å¤–éªŒè¯ï¼Œå¹¶è€ƒè™‘å‚æ•°çš„é²æ£’æ€§ã€‚",
            "HIGH": "è¿‡æ‹Ÿåˆé£é™©è¾ƒé«˜ã€‚å»ºè®®é‡æ–°å®¡è§†å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ï¼Œä½¿ç”¨æ›´å¤§çš„éªŒè¯é›†ï¼Œå¹¶è€ƒè™‘ç®€åŒ–æ¨¡å‹å¤æ‚åº¦ã€‚",
            "CRITICAL": "ä¸¥é‡è¿‡æ‹Ÿåˆé£é™©ï¼å¼ºçƒˆå»ºè®®é‡æ–°ä¼˜åŒ–ï¼Œä½¿ç”¨äº¤å‰éªŒè¯ï¼Œå¢åŠ æ­£åˆ™åŒ–çº¦æŸï¼Œæˆ–å›åˆ°æ›´ä¿å®ˆçš„å‚æ•°è®¾ç½®ã€‚"
        }
        
        return recommendations.get(risk_level, "æœªçŸ¥é£é™©ç­‰çº§")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš¨ DipMaster Overfitting Detection Suite")
    print("=" * 80)
    
    detector = OverfittingDetector()
    
    # æ‰§è¡Œç»¼åˆè¿‡æ‹Ÿåˆæ£€æµ‹
    results = detector.detect_overfitting_comprehensive("ICPUSDT")
    
    if not results:
        print("âŒ æ£€æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"overfitting_analysis_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    # æ˜¾ç¤ºå…³é”®ç»“æœ
    print(f"\nâœ… è¿‡æ‹Ÿåˆæ£€æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜: {filename}")
    print("\nğŸ¯ å…³é”®å‘ç°:")
    
    sample_analysis = results['sample_analysis']
    optimized = sample_analysis['optimized_config']
    
    print(f"ğŸ“Š ä¼˜åŒ–å‚æ•°æ ·æœ¬å†…èƒœç‡: {optimized['train_win_rate']:.1f}%")
    print(f"ğŸ“Š ä¼˜åŒ–å‚æ•°æ ·æœ¬å¤–èƒœç‡: {optimized['test_win_rate']:.1f}%")
    print(f"ğŸ“‰ æ€§èƒ½è¡°å‡: {optimized['performance_diff']:+.1f}%")
    
    assessment = results['overfitting_assessment']
    print(f"\nğŸš¨ è¿‡æ‹Ÿåˆé£é™©è¯„ä¼°:")
    print(f"é£é™©ç­‰çº§: {assessment['risk_level']}")
    print(f"é£é™©è¯„åˆ†: {assessment['overfitting_score']}/100")
    
    if assessment['risk_factors']:
        print(f"\nâš ï¸ é£é™©å› ç´ :")
        for factor in assessment['risk_factors']:
            print(f"  â€¢ {factor}")
    
    print(f"\nğŸ’¡ å»ºè®®: {assessment['recommendation']}")

if __name__ == "__main__":
    main()