"""
DipMaster Enhanced Portfolio Optimization Demo
æ¼”ç¤ºæ™ºèƒ½ç»„åˆé£é™©ä¼˜åŒ–ç³»ç»Ÿ

è¿è¡Œæ­¤è„šæœ¬ç”Ÿæˆ:
1. å®Œæ•´çš„TargetPortfolio.jsoné…ç½®
2. è¯¦ç»†çš„é£é™©æŠ¥å‘Š
3. å‹åŠ›æµ‹è¯•ç»“æœ
4. å®æ—¶ç›‘æ§é¢æ¿æ•°æ®

ä½œè€…: DipMaster Trading System
ç‰ˆæœ¬: 5.0.0
åˆ›å»ºæ—¶é—´: 2025-08-17
"""

import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.enhanced_portfolio_optimizer import (
    create_enhanced_portfolio_optimizer, 
    MarketRegime,
    PositionMetrics
)

def generate_sample_data():
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""
    
    # 35ä¸ªå¸ç§çš„æ ·æœ¬æ•°æ®
    symbols = [
        # Tier 1: è¶…å¤§å¸‚å€¼
        "BTCUSDT", "ETHUSDT",
        # Tier 2: å¤§å¸‚å€¼
        "SOLUSDT", "ADAUSDT", "XRPUSDT", "BNBUSDT", "DOGEUSDT", 
        "LINKUSDT", "LTCUSDT", "MATICUSDT",
        # Tier 3: ä¸­å¸‚å€¼  
        "UNIUSDT", "AAVEUSDT", "DOTUSDT", "AVAXUSDT", "TRXUSDT",
        "ATOMUSDT", "NEARUSDT", "APTUSDT", "ARBUSDT", "OPUSDT",
        "FILUSDT", "VETUSDT", "ICPUSDT", "MKRUSDT", "COMPUSDT",
        "QNTUSDT", "XLMUSDT", "ALGOUSDT", "IOTAUSDT", "SUIUSDT"
    ]
    
    # ç”Ÿæˆæ—¶é—´åºåˆ—ï¼ˆè¿‡å»90å¤©ï¼Œ5åˆ†é’Ÿæ•°æ®ï¼‰
    end_time = datetime.now()
    start_time = end_time - timedelta(days=90)
    timestamps = pd.date_range(start_time, end_time, freq='5T')
    
    # ç”ŸæˆAlphaä¿¡å·æ•°æ®
    alpha_signals = []
    for symbol in symbols:
        # æ¨¡æ‹Ÿä¸åŒè´¨é‡çš„ä¿¡å·
        if symbol in ["BTCUSDT", "ETHUSDT"]:
            base_score = 0.8
            base_confidence = 0.9
            base_return = 0.012
        elif symbol in ["SOLUSDT", "ADAUSDT", "XRPUSDT", "BNBUSDT"]:
            base_score = 0.7
            base_confidence = 0.85
            base_return = 0.015
        else:
            base_score = 0.6
            base_confidence = 0.75
            base_return = 0.018
        
        # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–
        score = base_score + np.random.normal(0, 0.1)
        confidence = np.clip(base_confidence + np.random.normal(0, 0.05), 0.5, 1.0)
        predicted_return = base_return + np.random.normal(0, 0.005)
        
        alpha_signals.append({
            'timestamp': end_time,
            'symbol': symbol,
            'score': score,
            'confidence': confidence,
            'predicted_return': predicted_return
        })
    
    alpha_signals_df = pd.DataFrame(alpha_signals)
    
    # ç”Ÿæˆå¸‚åœºæ•°æ®
    market_data = []
    
    for symbol in symbols:
        # åŸºç¡€ä»·æ ¼å’Œæ³¢åŠ¨ç‡è®¾ç½®
        if symbol == "BTCUSDT":
            base_price = 65000
            base_vol = 0.15
        elif symbol == "ETHUSDT":
            base_price = 3500
            base_vol = 0.18
        elif symbol in ["SOLUSDT", "ADAUSDT", "XRPUSDT"]:
            base_price = np.random.uniform(50, 500)
            base_vol = 0.20
        else:
            base_price = np.random.uniform(5, 100)
            base_vol = 0.25
        
        # ç”Ÿæˆä»·æ ¼æ—¶é—´åºåˆ—ï¼ˆç®€åŒ–çš„å‡ ä½•å¸ƒæœ—è¿åŠ¨ï¼‰
        dt = 1/288  # 5åˆ†é’Ÿé—´éš”ï¼Œæ—¥åŒ–
        drift = 0.10 / 252  # å¹´åŒ–10%æ¼‚ç§»
        
        prices = [base_price]
        volumes = []
        
        for i in range(1, len(timestamps)):
            # ä»·æ ¼æ¼”åŒ–
            dW = np.random.normal(0, np.sqrt(dt))
            price_change = drift * dt + base_vol * dW
            new_price = prices[-1] * (1 + price_change)
            prices.append(max(new_price, 0.01))  # é¿å…è´Ÿä»·æ ¼
            
            # æˆäº¤é‡ï¼ˆä¸ä»·æ ¼å˜åŒ–ç›¸å…³ï¼‰
            volume_base = 1000000  # åŸºç¡€æˆäº¤é‡
            volume_multiplier = 1 + abs(price_change) * 5  # æ³¢åŠ¨è¶Šå¤§æˆäº¤é‡è¶Šå¤§
            volume = volume_base * volume_multiplier * np.random.uniform(0.5, 2.0)
            volumes.append(volume)
        
        # æ·»åŠ ç¬¬ä¸€ä¸ªæˆäº¤é‡
        volumes.insert(0, 1000000)
        
        # è®¡ç®—æ”¶ç›Šç‡
        price_series = pd.Series(prices)
        returns = price_series.pct_change().fillna(0)
        
        for i, timestamp in enumerate(timestamps):
            market_data.append({
                'timestamp': timestamp,
                'symbol': symbol,
                'close': prices[i],
                'volume': volumes[i],
                'returns': returns.iloc[i] if i > 0 else 0,
                'volatility': base_vol
            })
    
    market_data_df = pd.DataFrame(market_data)
    
    return alpha_signals_df, market_data_df

def generate_target_portfolio_demo():
    """ç”Ÿæˆå®Œæ•´çš„TargetPortfolioæ¼”ç¤º"""
    
    print("ğŸš€ å¯åŠ¨DipMaster Enhanced Portfolio Optimization V5...")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–ä¼˜åŒ–å™¨
    print("1ï¸âƒ£ åˆå§‹åŒ–å¢å¼ºç‰ˆç»„åˆä¼˜åŒ–å™¨...")
    try:
        optimizer = create_enhanced_portfolio_optimizer()
        print(f"   âœ… æˆåŠŸåŠ è½½35å¸ç§é…ç½®")
        print(f"   âœ… ç›®æ ‡å¤æ™®æ¯”ç‡: {optimizer.objectives['target_sharpe']}")
        print(f"   âœ… ç›®æ ‡æ³¢åŠ¨ç‡: {optimizer.objectives['target_volatility']:.1%}")
        print(f"   âœ… æœ€å¤§å›æ’¤é™åˆ¶: {optimizer.objectives['max_drawdown']:.1%}")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return None
    
    # 2. ç”Ÿæˆæ ·æœ¬æ•°æ®
    print("\\n2ï¸âƒ£ ç”Ÿæˆæ ·æœ¬å¸‚åœºæ•°æ®...")
    alpha_signals, market_data = generate_sample_data()
    print(f"   âœ… Alphaä¿¡å·: {len(alpha_signals)} ä¸ªå¸ç§")
    print(f"   âœ… å¸‚åœºæ•°æ®: {len(market_data)} æ¡è®°å½•")
    print(f"   âœ… æ—¶é—´èŒƒå›´: è¿‡å»90å¤©ï¼Œ5åˆ†é’Ÿé¢‘ç‡")
    
    # 3. è¿è¡Œç»„åˆä¼˜åŒ–
    print("\\n3ï¸âƒ£ æ‰§è¡Œæ™ºèƒ½ç»„åˆä¼˜åŒ–...")
    try:
        # æ¨¡æ‹Ÿå½“å‰æŒä»“
        current_positions = {
            "BTCUSDT": 0.15,
            "ETHUSDT": 0.10,
            "SOLUSDT": 0.05
        }
        
        target_portfolio = optimizer.optimize_portfolio(
            alpha_signals=alpha_signals,
            market_data=market_data,
            current_positions=current_positions,
            market_regime=MarketRegime.NORMAL_VOLATILITY
        )
        
        print(f"   âœ… ä¼˜åŒ–å®Œæˆ")
        print(f"   âœ… æœ€ç»ˆæŒä»“æ•°é‡: {target_portfolio['total_positions']}")
        print(f"   âœ… æ€»æ æ†: {target_portfolio['leverage']:.2f}x")
        print(f"   âœ… é¢„æœŸå¤æ™®æ¯”ç‡: {target_portfolio['risk']['sharpe']:.2f}")
        print(f"   âœ… å¹´åŒ–æ³¢åŠ¨ç‡: {target_portfolio['risk']['ann_vol']:.1%}")
        
    except Exception as e:
        print(f"   âŒ ä¼˜åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # 4. ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = "results/enhanced_portfolio_optimization"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜TargetPortfolio.json
    portfolio_file = f"{output_dir}/TargetPortfolio_Enhanced_V5_{timestamp}.json"
    with open(portfolio_file, 'w', encoding='utf-8') as f:
        json.dump(target_portfolio, f, indent=2, ensure_ascii=False)
    
    print(f"\\n4ï¸âƒ£ ä¿å­˜ç»“æœæ–‡ä»¶...")
    print(f"   âœ… ç›®æ ‡ç»„åˆ: {portfolio_file}")
    
    # 5. ç”Ÿæˆé£é™©æŠ¥å‘Š
    risk_report = generate_comprehensive_risk_report(target_portfolio, optimizer)
    
    report_file = f"{output_dir}/RiskReport_Enhanced_V5_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(risk_report, f, indent=2, ensure_ascii=False)
    
    print(f"   âœ… é£é™©æŠ¥å‘Š: {report_file}")
    
    # 6. æ‰“å°å…³é”®æŒ‡æ ‡æ‘˜è¦
    print("\\n" + "=" * 80)
    print("ğŸ“Š DipMaster Enhanced Portfolio V5 - å…³é”®æŒ‡æ ‡æ‘˜è¦")
    print("=" * 80)
    
    print("\\nğŸ¯ æŠ•èµ„ç›®æ ‡è¾¾æˆæƒ…å†µ:")
    constraints = target_portfolio['constraints_status']
    for constraint, status in constraints.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"   {status_icon} {constraint}: {status}")
    
    print("\\nğŸ’° æŒä»“é…ç½®:")
    for weight_info in target_portfolio['weights']:
        print(f"   â€¢ {weight_info['symbol']}: {weight_info['w']:.1%} "
              f"(${weight_info['usd_size']:,.0f}) - {weight_info['tier']}")
    
    print("\\nğŸ“ˆ é£é™©æŒ‡æ ‡:")
    risk = target_portfolio['risk']
    print(f"   â€¢ å¹´åŒ–æ³¢åŠ¨ç‡: {risk['ann_vol']:.1%}")
    print(f"   â€¢ Beta (vs BTC): {risk['beta']:.3f}")
    print(f"   â€¢ å¤æ™®æ¯”ç‡: {risk['sharpe']:.2f}")
    print(f"   â€¢ VaR (95%): {risk['VaR_95']:.1%}")
    print(f"   â€¢ æœŸæœ›æŸå¤± (95%): {risk['ES_95']:.1%}")
    print(f"   â€¢ æœ€å¤§å›æ’¤: {risk['maximum_drawdown']:.1%}")
    
    print("\\nğŸ¢ äº¤æ˜“æ‰€åˆ†é…:")
    for venue, allocation in target_portfolio['venue_allocation'].items():
        print(f"   â€¢ {venue.upper()}: {allocation:.1%}")
    
    print("\\nğŸ§® åˆ†å±‚é…ç½®:")
    for tier, info in target_portfolio['tier_allocation'].items():
        if info['total_weight'] > 0:
            print(f"   â€¢ {tier}: {info['total_weight']:.1%} "
                  f"({info['position_count']} ä¸ªå¸ç§) - {info['liquidity_tier']}")
    
    print("\\nâš ï¸  å‹åŠ›æµ‹è¯•ç»“æœ:")
    stress_results = target_portfolio['stress_test_results']
    for scenario, result in stress_results.items():
        var_breach = "âš ï¸ " if result.get('var_breach', False) else "âœ…"
        print(f"   {var_breach} {scenario}: "
              f"ç»„åˆæŸå¤± {result['portfolio_loss']:.1%}, "
              f"VaR {result['var_95']:.1%}")
    
    print("\\n" + "=" * 80)
    print("ğŸ‰ DipMaster Enhanced Portfolio Optimization V5 å®Œæˆ!")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {output_dir}/")
    print("=" * 80)
    
    return target_portfolio, risk_report

def generate_comprehensive_risk_report(target_portfolio: dict, optimizer) -> dict:
    """ç”Ÿæˆè¯¦ç»†é£é™©æŠ¥å‘Š"""
    
    risk_report = {
        "report_timestamp": datetime.now().isoformat(),
        "report_version": "DipMaster_Risk_Report_V5",
        "portfolio_summary": {
            "total_positions": target_portfolio['total_positions'],
            "gross_leverage": target_portfolio['leverage'],
            "net_leverage": sum([w['w'] for w in target_portfolio['weights']]),
            "largest_position": max([w['w'] for w in target_portfolio['weights']]) if target_portfolio['weights'] else 0,
            "market_regime": target_portfolio['market_regime']
        },
        
        "risk_metrics_detailed": {
            "volatility_analysis": {
                "annualized_volatility": target_portfolio['risk']['ann_vol'],
                "target_volatility": optimizer.objectives['target_volatility'],
                "volatility_deviation": abs(target_portfolio['risk']['ann_vol'] - optimizer.objectives['target_volatility']),
                "regime_adjusted_vol": target_portfolio['risk']['ann_vol'] * 1.2  # åˆ¶åº¦è°ƒæ•´
            },
            
            "beta_analysis": {
                "portfolio_beta": target_portfolio['risk']['beta'],
                "beta_target": 0.0,
                "market_neutrality": abs(target_portfolio['risk']['beta']) < 0.05,
                "systematic_risk_exposure": target_portfolio['risk']['beta'] * 0.15  # å‡è®¾å¸‚åœºæ³¢åŠ¨15%
            },
            
            "downside_risk": {
                "value_at_risk_95": target_portfolio['risk']['VaR_95'],
                "value_at_risk_99": target_portfolio['risk']['VaR_99'],
                "expected_shortfall_95": target_portfolio['risk']['ES_95'],
                "maximum_drawdown": target_portfolio['risk']['maximum_drawdown'],
                "downside_deviation": target_portfolio['risk']['ann_vol'] * 0.7  # å‡è®¾70%ä¸‹è¡Œåå·®
            },
            
            "performance_ratios": {
                "sharpe_ratio": target_portfolio['risk']['sharpe'],
                "information_ratio": target_portfolio['risk'].get('information_ratio', 0),
                "calmar_ratio": target_portfolio['risk'].get('calmar_ratio', 0),
                "sortino_ratio": target_portfolio['risk']['sharpe'] * 1.4  # ä¼°ç®—Sortino
            }
        },
        
        "concentration_analysis": {
            "position_concentration": {
                pos['symbol']: pos['w'] for pos in target_portfolio['weights']
            },
            "tier_concentration": target_portfolio['tier_allocation'],
            "herfindahl_index": sum([w['w']**2 for w in target_portfolio['weights']]),
            "effective_number_positions": 1 / sum([w['w']**2 for w in target_portfolio['weights']]) if target_portfolio['weights'] else 0
        },
        
        "correlation_analysis": {
            "risk_attribution": target_portfolio['risk_attribution'],
            "diversification_benefit": target_portfolio['risk_attribution'].get('diversification_ratio', 1.0),
            "correlation_risk": "Medium",  # ç®€åŒ–è¯„çº§
            "cluster_risk": "Low"
        },
        
        "stress_test_summary": {
            "scenarios_tested": len(target_portfolio['stress_test_results']),
            "worst_case_loss": min([r['portfolio_loss'] for r in target_portfolio['stress_test_results'].values()]),
            "var_breaches": sum([1 for r in target_portfolio['stress_test_results'].values() if r.get('var_breach', False)]),
            "stress_test_passed": all([not r.get('var_breach', False) for r in target_portfolio['stress_test_results'].values()])
        },
        
        "liquidity_analysis": {
            "tier_1_allocation": target_portfolio['tier_allocation'].get('tier_1_mega_cap', {}).get('total_weight', 0),
            "tier_2_allocation": target_portfolio['tier_allocation'].get('tier_2_large_cap', {}).get('total_weight', 0),
            "tier_3_allocation": target_portfolio['tier_allocation'].get('tier_3_mid_cap', {}).get('total_weight', 0),
            "liquidity_score": "High",  # ç®€åŒ–è¯„åˆ†
            "estimated_liquidation_time": "< 30 minutes"
        },
        
        "compliance_status": target_portfolio['constraints_status'],
        
        "recommendations": [
            {
                "priority": "High",
                "category": "Risk Management",
                "recommendation": "ç›‘æ§Betaä¸­æ€§çŠ¶æ€ï¼Œç¡®ä¿å¸‚åœºé£é™©æ•å£æ§åˆ¶åœ¨Â±5%ä»¥å†…",
                "action_required": target_portfolio['constraints_status']['beta_neutral']
            },
            {
                "priority": "Medium", 
                "category": "Position Sizing",
                "recommendation": "å®šæœŸè¯„ä¼°Kellyåˆ†æ•°æœ‰æ•ˆæ€§ï¼ŒåŸºäºæœ€æ–°ç»©æ•ˆæ•°æ®è°ƒæ•´",
                "action_required": True
            },
            {
                "priority": "Low",
                "category": "Diversification",
                "recommendation": "è€ƒè™‘å¢åŠ éç›¸å…³èµ„äº§ä»¥è¿›ä¸€æ­¥é™ä½ç»„åˆé£é™©",
                "action_required": False
            }
        ],
        
        "monitoring_alerts": {
            "real_time_alerts": [
                "Portfolio Beta exceeds Â±0.05",
                "Individual position exceeds 25%",
                "Daily loss exceeds 2%",
                "VaR breach detected",
                "Correlation spike above 0.8"
            ],
            "alert_thresholds": optimizer.config['monitoring_and_alerts']['alert_thresholds']
        }
    }
    
    return risk_report

if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´æ¼”ç¤º
    try:
        target_portfolio, risk_report = generate_target_portfolio_demo()
        
        if target_portfolio:
            print("\\nğŸ”— å¿«é€Ÿè®¿é—®é“¾æ¥:")
            print("   ğŸ“Š æŸ¥çœ‹ç»“æœ: results/enhanced_portfolio_optimization/")
            print("   ğŸ“ˆ å¯åŠ¨ç›‘æ§: python src/dashboard/start_dashboard.py")
            print("   ğŸ”„ é‡æ–°ä¼˜åŒ–: python run_enhanced_portfolio_optimization.py")
            
    except KeyboardInterrupt:
        print("\\n\\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\\n\\nâŒ æ¼”ç¤ºè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()