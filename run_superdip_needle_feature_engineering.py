#!/usr/bin/env python3
"""
SuperDip Needle Feature Engineering Execution Script
è¶…è·Œæ¥é’ˆç­–ç•¥ç‰¹å¾å·¥ç¨‹æ‰§è¡Œè„šæœ¬

æ‰§è¡ŒSuperDip Needleç­–ç•¥çš„å®Œæ•´ç‰¹å¾å·¥ç¨‹æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. ç‰¹å¾ç”Ÿæˆ
2. è´¨é‡éªŒè¯
3. é‡è¦æ€§åˆ†æ
4. æŠ¥å‘Šç”Ÿæˆ

Author: DipMaster Quant Team
Date: 2025-08-18
Version: 1.0.0
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

import pandas as pd
import numpy as np
import json
import logging
from pathlib import Path
from datetime import datetime
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any

from src.data.superdip_needle_feature_engineer import (
    SuperDipNeedleFeatureEngineer, 
    SuperDipNeedleConfig
)

# é…ç½®
warnings.filterwarnings('ignore')
plt.style.use('default')
sns.set_palette("husl")

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/superdip_needle_feature_engineering.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

def generate_feature_importance_report(results: Dict[str, Any], output_dir: Path) -> str:
    """ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š"""
    try:
        logger = logging.getLogger(__name__)
        logger.info("Generating feature importance analysis report...")
        
        # æ”¶é›†æ‰€æœ‰ç‰¹å¾é‡è¦æ€§æ•°æ®
        all_importance = {}
        symbol_count = {}
        
        for symbol, stats in results['processing_stats'].items():
            if 'feature_importance' in stats and stats['feature_importance']:
                for feature, importance in stats['feature_importance'].items():
                    if feature not in all_importance:
                        all_importance[feature] = []
                        symbol_count[feature] = 0
                    all_importance[feature].append(importance)
                    symbol_count[feature] += 1
        
        # è®¡ç®—å¹³å‡é‡è¦æ€§
        avg_importance = {}
        for feature, scores in all_importance.items():
            avg_importance[feature] = np.mean(scores)
        
        # æŒ‰é‡è¦æ€§æ’åº
        sorted_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)
        
        # ç”ŸæˆæŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = output_dir / f"SuperDipNeedle_FeatureImportance_Report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# SuperDip Needle Strategy - Feature Importance Analysis Report\n")
            f.write("# è¶…è·Œæ¥é’ˆç­–ç•¥ - ç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š\n\n")
            
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**å¤„ç†å¸ç§æ•°**: {len(results['processing_stats'])}\n")
            f.write(f"**æ€»ç‰¹å¾æ•°**: {len(sorted_features)}\n\n")
            
            # æ‰§è¡Œæ‘˜è¦
            f.write("## æ‰§è¡Œæ‘˜è¦\n\n")
            f.write("æœ¬æŠ¥å‘Šåˆ†æäº†SuperDip Needleç­–ç•¥ä¸­å„ç‰¹å¾çš„é¢„æµ‹é‡è¦æ€§ï¼Œ")
            f.write("åŸºäºäº’ä¿¡æ¯æ–¹æ³•è®¡ç®—ç‰¹å¾ä¸ç›®æ ‡æ”¶ç›Šä¹‹é—´çš„å…³è”åº¦ã€‚\n\n")
            
            # Top 20 é‡è¦ç‰¹å¾
            f.write("## ğŸ† Top 20 é‡è¦ç‰¹å¾\n\n")
            f.write("| æ’å | ç‰¹å¾åç§° | å¹³å‡é‡è¦æ€§ | å‡ºç°å¸ç§æ•° | ç‰¹å¾ç±»åˆ« |\n")
            f.write("|------|----------|------------|------------|----------|\n")
            
            for i, (feature, importance) in enumerate(sorted_features[:20]):
                rank = i + 1
                count = symbol_count[feature]
                category = classify_feature(feature)
                f.write(f"| {rank} | `{feature}` | {importance:.6f} | {count} | {category} |\n")
            
            # ç‰¹å¾ç±»åˆ«åˆ†æ
            f.write("\n## ğŸ“Š ç‰¹å¾ç±»åˆ«é‡è¦æ€§åˆ†æ\n\n")
            
            category_importance = {}
            for feature, importance in sorted_features:
                category = classify_feature(feature)
                if category not in category_importance:
                    category_importance[category] = []
                category_importance[category].append(importance)
            
            category_avg = {k: np.mean(v) for k, v in category_importance.items()}
            sorted_categories = sorted(category_avg.items(), key=lambda x: x[1], reverse=True)
            
            f.write("| ç‰¹å¾ç±»åˆ« | å¹³å‡é‡è¦æ€§ | ç‰¹å¾æ•°é‡ | æè¿° |\n")
            f.write("|----------|------------|----------|---------|\n")
            
            category_descriptions = {
                'RSIè¶…å–': 'RSIæŒ‡æ ‡åŠå…¶è¡ç”Ÿç‰¹å¾ï¼Œç”¨äºè¯†åˆ«è¶…å–çŠ¶æ€',
                'å¸ƒæ—å¸¦': 'å¸ƒæ—å¸¦ä½ç½®å’Œçªç ´ç‰¹å¾ï¼Œè¡¡é‡ä»·æ ¼åç¦»ç¨‹åº¦',
                'æˆäº¤é‡': 'æˆäº¤é‡ç›¸å…³ç‰¹å¾ï¼ŒåŒ…æ‹¬æ”¾å¤§ã€æ¯”ç‡å’ŒèƒŒç¦»',
                'ä»·æ ¼å½¢æ€': 'Kçº¿å½¢æ€ç‰¹å¾ï¼Œå¦‚é”¤å­çº¿ã€åå­—æ˜Ÿç­‰',
                'å¤šæ—¶é—´æ¡†æ¶': 'è·¨æ—¶é—´æ¡†æ¶çš„è¶‹åŠ¿å’Œä¿¡å·ä¸€è‡´æ€§',
                'å¾®ç»“æ„': 'å¸‚åœºå¾®ç»“æ„ç‰¹å¾ï¼Œå¦‚æµåŠ¨æ€§ã€ä¹°å–å‹åŠ›',
                'äº¤äº’ç‰¹å¾': 'å¤šä¸ªæŒ‡æ ‡çš„ç»„åˆå’Œäº¤äº’ç‰¹å¾',
                'è¶‹åŠ¿åŠ¨é‡': 'ä»·æ ¼è¶‹åŠ¿å’ŒåŠ¨é‡ç›¸å…³ç‰¹å¾',
                'æ³¢åŠ¨ç‡': 'ä»·æ ¼æ³¢åŠ¨ç‡å’Œå¸‚åœºçŠ¶æ€ç‰¹å¾',
                'å…¶ä»–': 'å…¶ä»–è¾…åŠ©ç‰¹å¾'
            }
            
            for category, avg_imp in sorted_categories:
                count = len(category_importance[category])
                desc = category_descriptions.get(category, 'æœªåˆ†ç±»ç‰¹å¾')
                f.write(f"| {category} | {avg_imp:.6f} | {count} | {desc} |\n")
            
            # å…³é”®å‘ç°
            f.write("\n## ğŸ” å…³é”®å‘ç°\n\n")
            
            # åˆ†ææœ€é‡è¦çš„ç‰¹å¾ç±»åˆ«
            top_category = sorted_categories[0][0]
            f.write(f"1. **æœ€é‡è¦ç‰¹å¾ç±»åˆ«**: {top_category}ï¼Œå¹³å‡é‡è¦æ€§ä¸º {sorted_categories[0][1]:.6f}\n")
            
            # åˆ†ææœ€é‡è¦çš„å•ä¸ªç‰¹å¾
            top_feature = sorted_features[0][0]
            f.write(f"2. **æœ€é‡è¦å•ä¸ªç‰¹å¾**: `{top_feature}`ï¼Œé‡è¦æ€§ä¸º {sorted_features[0][1]:.6f}\n")
            
            # ç‰¹å¾ä¸€è‡´æ€§åˆ†æ
            high_consistency = [f for f, c in symbol_count.items() if c >= len(results['processing_stats']) * 0.8]
            f.write(f"3. **é«˜ä¸€è‡´æ€§ç‰¹å¾**: {len(high_consistency)} ä¸ªç‰¹å¾åœ¨80%ä»¥ä¸Šçš„å¸ç§ä¸­è¡¨ç°é‡è¦\n")
            
            # æ¨èçš„ç‰¹å¾é€‰æ‹©ç­–ç•¥
            f.write("\n## ğŸ’¡ ç‰¹å¾é€‰æ‹©å»ºè®®\n\n")
            f.write("åŸºäºé‡è¦æ€§åˆ†æï¼Œæ¨èä»¥ä¸‹ç‰¹å¾é€‰æ‹©ç­–ç•¥ï¼š\n\n")
            
            # æ ¸å¿ƒç‰¹å¾é›†ï¼ˆTop 30ï¼‰
            f.write("### æ ¸å¿ƒç‰¹å¾é›† (Top 30)\n\n")
            core_features = [f[0] for f in sorted_features[:30]]
            for i, feature in enumerate(core_features, 1):
                f.write(f"{i}. `{feature}`\n")
            
            # æ‰©å±•ç‰¹å¾é›†ï¼ˆTop 50ï¼‰
            f.write("\n### æ‰©å±•ç‰¹å¾é›† (Top 31-50)\n\n")
            extended_features = [f[0] for f in sorted_features[30:50]]
            for i, feature in enumerate(extended_features, 31):
                f.write(f"{i}. `{feature}`\n")
            
            # ç‰¹å¾å·¥ç¨‹å»ºè®®
            f.write("\n## ğŸ› ï¸ ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–å»ºè®®\n\n")
            f.write("1. **é‡ç‚¹å…³æ³¨RSIå’Œå¸ƒæ—å¸¦ç‰¹å¾**: è¿™äº›ä¼ ç»ŸæŠ€æœ¯æŒ‡æ ‡åœ¨è¶…è·Œè¯†åˆ«ä¸­è¡¨ç°ä¼˜å¼‚\n")
            f.write("2. **æˆäº¤é‡ç¡®è®¤å¾ˆé‡è¦**: æˆäº¤é‡ç›¸å…³ç‰¹å¾èƒ½æœ‰æ•ˆç¡®è®¤ä»·æ ¼ä¿¡å·\n")
            f.write("3. **å¤šæ—¶é—´æ¡†æ¶èåˆ**: è·¨æ—¶é—´æ¡†æ¶ç‰¹å¾æä¾›é‡è¦çš„ç¡®è®¤ä¿¡æ¯\n")
            f.write("4. **äº¤äº’ç‰¹å¾æœ‰ä»·å€¼**: å¤šæŒ‡æ ‡ç»„åˆç‰¹å¾æä¾›é¢å¤–çš„é¢„æµ‹èƒ½åŠ›\n")
            f.write("5. **è€ƒè™‘ç‰¹å¾ç¨³å®šæ€§**: ä¼˜å…ˆé€‰æ‹©åœ¨å¤šä¸ªå¸ç§ä¸­éƒ½é‡è¦çš„ç‰¹å¾\n\n")
            
            # é£é™©æç¤º
            f.write("## âš ï¸ é£é™©æç¤º\n\n")
            f.write("1. ç‰¹å¾é‡è¦æ€§å¯èƒ½éšå¸‚åœºç¯å¢ƒå˜åŒ–ï¼Œéœ€è¦å®šæœŸé‡æ–°è¯„ä¼°\n")
            f.write("2. é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œä¸å»ºè®®ä½¿ç”¨è¿‡å¤šç›¸å…³æ€§å¼ºçš„ç‰¹å¾\n")
            f.write("3. å®ç›˜åº”ç”¨æ—¶éœ€è¦è€ƒè™‘ç‰¹å¾è®¡ç®—çš„å®æ—¶æ€§å’Œç¨³å®šæ€§\n")
            f.write("4. å»ºè®®ç»“åˆä¸šåŠ¡ç†è§£è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œä¸å®Œå…¨ä¾èµ–ç»Ÿè®¡æŒ‡æ ‡\n\n")
            
            f.write("---\n")
            f.write("*æŠ¥å‘Šç”±SuperDip Needle Feature Engineering Pipelineè‡ªåŠ¨ç”Ÿæˆ*\n")
        
        logger.info(f"Feature importance report saved to: {report_file}")
        return str(report_file)
        
    except Exception as e:
        logger.error(f"Failed to generate feature importance report: {e}")
        return ""

def classify_feature(feature_name: str) -> str:
    """æ ¹æ®ç‰¹å¾åç§°åˆ†ç±»"""
    feature_lower = feature_name.lower()
    
    if 'rsi' in feature_lower:
        return 'RSIè¶…å–'
    elif 'bb_' in feature_lower or 'bollinger' in feature_lower:
        return 'å¸ƒæ—å¸¦'
    elif 'volume' in feature_lower or 'money_flow' in feature_lower or 'vwap' in feature_lower:
        return 'æˆäº¤é‡'
    elif any(pattern in feature_lower for pattern in ['hammer', 'doji', 'candle', 'shadow', 'body']):
        return 'ä»·æ ¼å½¢æ€'
    elif 'htf_' in feature_lower or 'hf_' in feature_lower or 'consensus' in feature_lower:
        return 'å¤šæ—¶é—´æ¡†æ¶'
    elif any(pattern in feature_lower for pattern in ['illiquidity', 'spread', 'flow']):
        return 'å¾®ç»“æ„'
    elif any(pattern in feature_lower for pattern in ['combo', 'interaction', 'product']):
        return 'äº¤äº’ç‰¹å¾'
    elif any(pattern in feature_lower for pattern in ['trend', 'momentum', 'acceleration']):
        return 'è¶‹åŠ¿åŠ¨é‡'
    elif any(pattern in feature_lower for pattern in ['volatility', 'regime', 'state']):
        return 'æ³¢åŠ¨ç‡'
    else:
        return 'å…¶ä»–'

def generate_data_quality_report(results: Dict[str, Any], output_dir: Path) -> str:
    """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
    try:
        logger = logging.getLogger(__name__)
        logger.info("Generating data quality report...")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = output_dir / f"SuperDipNeedle_DataQuality_Report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# SuperDip Needle Strategy - Data Quality Report\n")
            f.write("# è¶…è·Œæ¥é’ˆç­–ç•¥ - æ•°æ®è´¨é‡æŠ¥å‘Š\n\n")
            
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**å¤„ç†å¸ç§æ•°**: {len(results['processing_stats'])}\n\n")
            
            # æ•°æ®è´¨é‡æ¦‚è§ˆ
            f.write("## ğŸ“Š æ•°æ®è´¨é‡æ¦‚è§ˆ\n\n")
            
            total_symbols = len(results['processing_stats'])
            passed_symbols = 0
            warning_symbols = 0
            critical_symbols = 0
            
            for symbol, stats in results['processing_stats'].items():
                if 'data_quality' in stats:
                    quality = stats['data_quality']
                    missing_analysis = quality.get('missing_data_analysis', {})
                    
                    # ç»Ÿè®¡è´¨é‡çŠ¶æ€
                    has_critical = any(info.get('status') == 'CRITICAL' for info in missing_analysis.values())
                    has_warning = any(info.get('status') == 'WARNING' for info in missing_analysis.values())
                    
                    if has_critical:
                        critical_symbols += 1
                    elif has_warning:
                        warning_symbols += 1
                    else:
                        passed_symbols += 1
            
            f.write(f"- âœ… **é€šè¿‡æ£€æŸ¥**: {passed_symbols} ä¸ªå¸ç§ ({passed_symbols/total_symbols*100:.1f}%)\n")
            f.write(f"- âš ï¸ **å­˜åœ¨è­¦å‘Š**: {warning_symbols} ä¸ªå¸ç§ ({warning_symbols/total_symbols*100:.1f}%)\n")
            f.write(f"- âŒ **ä¸¥é‡é—®é¢˜**: {critical_symbols} ä¸ªå¸ç§ ({critical_symbols/total_symbols*100:.1f}%)\n\n")
            
            # è¯¦ç»†è´¨é‡åˆ†æ
            f.write("## ğŸ” è¯¦ç»†è´¨é‡åˆ†æ\n\n")
            
            for symbol, stats in results['processing_stats'].items():
                if 'data_quality' in stats:
                    quality = stats['data_quality']
                    f.write(f"### {symbol}\n\n")
                    
                    # åŸºæœ¬ä¿¡æ¯
                    f.write(f"- **æ•°æ®è¡Œæ•°**: {quality.get('total_rows', 'N/A')}\n")
                    f.write(f"- **ç‰¹å¾åˆ—æ•°**: {quality.get('total_features', 'N/A')}\n")
                    
                    # æ•°æ®æ³„éœ²æ£€æŸ¥
                    leakage_check = quality.get('data_leakage_check', {})
                    if leakage_check.get('status') == 'PASSED':
                        f.write("- **æ•°æ®æ³„éœ²æ£€æŸ¥**: âœ… é€šè¿‡\n")
                    else:
                        f.write("- **æ•°æ®æ³„éœ²æ£€æŸ¥**: âš ï¸ å‘ç°æ½œåœ¨é—®é¢˜\n")
                    
                    # ç¼ºå¤±å€¼åˆ†æ
                    missing_analysis = quality.get('missing_data_analysis', {})
                    if missing_analysis:
                        critical_missing = sum(1 for info in missing_analysis.values() if info.get('status') == 'CRITICAL')
                        warning_missing = sum(1 for info in missing_analysis.values() if info.get('status') == 'WARNING')
                        f.write(f"- **ç¼ºå¤±å€¼çŠ¶æ€**: {critical_missing} ä¸¥é‡, {warning_missing} è­¦å‘Š\n")
                    
                    # å¼‚å¸¸å€¼åˆ†æ
                    outlier_analysis = quality.get('outlier_analysis', {})
                    if outlier_analysis:
                        high_outliers = sum(1 for info in outlier_analysis.values() if info.get('status') == 'WARNING')
                        f.write(f"- **å¼‚å¸¸å€¼çŠ¶æ€**: {high_outliers} ä¸ªç‰¹å¾å¼‚å¸¸å€¼è¾ƒå¤š\n")
                    
                    # ç‰¹å¾ç¨³å®šæ€§
                    stability = quality.get('feature_stability', {})
                    if stability:
                        unstable_features = sum(1 for info in stability.values() if info.get('stability') == 'UNSTABLE')
                        f.write(f"- **ç‰¹å¾ç¨³å®šæ€§**: {unstable_features} ä¸ªç‰¹å¾ä¸ç¨³å®š\n")
                    
                    # å»ºè®®
                    recommendations = quality.get('recommendations', [])
                    if recommendations:
                        f.write("- **æ”¹è¿›å»ºè®®**:\n")
                        for rec in recommendations:
                            f.write(f"  - {rec}\n")
                    
                    f.write("\n")
            
            # æ€»ç»“å’Œå»ºè®®
            f.write("## ğŸ’¡ æ€»ç»“ä¸å»ºè®®\n\n")
            f.write("### æ•°æ®è´¨é‡æ€»ç»“\n\n")
            if critical_symbols == 0:
                f.write("âœ… **æ•´ä½“è´¨é‡è‰¯å¥½**: æ‰€æœ‰å¸ç§æ•°æ®éƒ½è¾¾åˆ°äº†åŸºæœ¬è´¨é‡è¦æ±‚\n\n")
            else:
                f.write(f"âš ï¸ **éœ€è¦å…³æ³¨**: {critical_symbols} ä¸ªå¸ç§å­˜åœ¨ä¸¥é‡æ•°æ®è´¨é‡é—®é¢˜ï¼Œå»ºè®®é‡ç‚¹æ£€æŸ¥\n\n")
            
            f.write("### æ”¹è¿›å»ºè®®\n\n")
            f.write("1. **æ•°æ®é¢„å¤„ç†**: åŠ å¼ºç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼çš„é¢„å¤„ç†\n")
            f.write("2. **ç¨³å®šæ€§ç›‘æ§**: å®šæœŸæ£€æŸ¥ç‰¹å¾ç¨³å®šæ€§ï¼ŒåŠæ—¶å‘ç°åˆ†å¸ƒæ¼‚ç§»\n")
            f.write("3. **è´¨é‡æµç¨‹**: å»ºç«‹è‡ªåŠ¨åŒ–çš„æ•°æ®è´¨é‡ç›‘æ§æµç¨‹\n")
            f.write("4. **éªŒè¯æœºåˆ¶**: å¢åŠ æ›´å¤šçš„æ•°æ®éªŒè¯è§„åˆ™\n\n")
            
            f.write("---\n")
            f.write("*æŠ¥å‘Šç”±SuperDip Needle Feature Engineering Pipelineè‡ªåŠ¨ç”Ÿæˆ*\n")
        
        logger.info(f"Data quality report saved to: {report_file}")
        return str(report_file)
        
    except Exception as e:
        logger.error(f"Failed to generate data quality report: {e}")
        return ""

def create_feature_visualization(results: Dict[str, Any], output_dir: Path) -> str:
    """åˆ›å»ºç‰¹å¾é‡è¦æ€§å¯è§†åŒ–"""
    try:
        logger = logging.getLogger(__name__)
        logger.info("Creating feature importance visualization...")
        
        # æ”¶é›†ç‰¹å¾é‡è¦æ€§æ•°æ®
        all_importance = {}
        for symbol, stats in results['processing_stats'].items():
            if 'feature_importance' in stats and stats['feature_importance']:
                for feature, importance in stats['feature_importance'].items():
                    if feature not in all_importance:
                        all_importance[feature] = []
                    all_importance[feature].append(importance)
        
        # è®¡ç®—å¹³å‡é‡è¦æ€§
        avg_importance = {feature: np.mean(scores) for feature, scores in all_importance.items()}
        sorted_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
        
        # Top 20 ç‰¹å¾é‡è¦æ€§
        top_20 = sorted_features[:20]
        features = [f[0] for f in top_20]
        importances = [f[1] for f in top_20]
        
        bars = ax1.barh(range(len(features)), importances)
        ax1.set_yticks(range(len(features)))
        ax1.set_yticklabels(features, fontsize=10)
        ax1.set_xlabel('Feature Importance (Mutual Information)')
        ax1.set_title('Top 20 Most Important Features - SuperDip Needle Strategy')
        ax1.invert_yaxis()
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width, bar.get_y() + bar.get_height()/2, 
                    f'{width:.4f}', ha='left', va='center', fontsize=8)
        
        # ç‰¹å¾ç±»åˆ«é‡è¦æ€§åˆ†å¸ƒ
        category_importance = {}
        for feature, importance in sorted_features:
            category = classify_feature(feature)
            if category not in category_importance:
                category_importance[category] = []
            category_importance[category].append(importance)
        
        categories = list(category_importance.keys())
        avg_by_category = [np.mean(category_importance[cat]) for cat in categories]
        
        bars2 = ax2.bar(categories, avg_by_category)
        ax2.set_xlabel('Feature Category')
        ax2.set_ylabel('Average Importance')
        ax2.set_title('Feature Importance by Category')
        ax2.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.4f}', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        plot_file = output_dir / f"SuperDipNeedle_FeatureImportance_{timestamp}.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Feature importance visualization saved to: {plot_file}")
        return str(plot_file)
        
    except Exception as e:
        logger.error(f"Failed to create feature visualization: {e}")
        return ""

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    os.makedirs('logs', exist_ok=True)
    logger = setup_logging()
    
    try:
        logger.info("=== SuperDip Needle Feature Engineering Started ===")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        bundle_path = "data/MarketDataBundle_Top30_Enhanced_Final.json"
        if not Path(bundle_path).exists():
            logger.error(f"Market data bundle not found: {bundle_path}")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("data/superdip_needle_features")
        output_dir.mkdir(exist_ok=True)
        results_dir = Path("results/superdip_needle")
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºé…ç½®
        config = SuperDipNeedleConfig(
            symbols=[
                'ADAUSDT', 'APTUSDT', 'ARBUSDT', 'ATOMUSDT', 'AVAXUSDT',
                'BNBUSDT', 'DOGEUSDT', 'DOTUSDT', 'FILUSDT', 'LINKUSDT',
                'LTCUSDT', 'NEARUSDT', 'OPUSDT', 'SOLUSDT', 'TONUSDT',
                'TRXUSDT', 'UNIUSDT', 'XLMUSDT', 'XRPUSDT', 'MATICUSDT'
            ],
            timeframes=['1m', '5m', '15m', '1h'],
            primary_timeframe='5m',
            prediction_horizons=[15, 30, 60, 240],
            profit_targets=[0.008, 0.015, 0.025, 0.040],
            enable_cross_timeframe=True,
            enable_microstructure=True,
            enable_advanced_labels=True,
            enable_interaction_features=True,
            enable_regime_features=True
        )
        
        # åˆ›å»ºç‰¹å¾å·¥ç¨‹å™¨
        feature_engineer = SuperDipNeedleFeatureEngineer(config)
        
        # æ‰§è¡Œç‰¹å¾å·¥ç¨‹
        logger.info("Starting feature engineering pipeline...")
        results = feature_engineer.generate_feature_set(bundle_path, str(output_dir))
        
        # ç”ŸæˆæŠ¥å‘Š
        logger.info("Generating analysis reports...")
        
        # ç‰¹å¾é‡è¦æ€§æŠ¥å‘Š
        importance_report = generate_feature_importance_report(results, results_dir)
        
        # æ•°æ®è´¨é‡æŠ¥å‘Š
        quality_report = generate_data_quality_report(results, results_dir)
        
        # ç‰¹å¾å¯è§†åŒ–
        visualization_file = create_feature_visualization(results, results_dir)
        
        # æ‰“å°æ€»ç»“
        logger.info("=== Feature Engineering Completed Successfully ===")
        print("\n" + "="*80)
        print("ğŸ‰ SuperDip Needle Feature Engineering å®Œæˆ!")
        print("="*80)
        print(f"âœ… ç‰¹å¾é›†æ–‡ä»¶: {results['feature_set_file']}")
        print(f"âœ… æ ‡ç­¾é›†æ–‡ä»¶: {results['label_set_file']}")
        print(f"âœ… å¤„ç†å¸ç§æ•°: {results['summary']['results_summary']['total_symbols_processed']}")
        print(f"âœ… æˆåŠŸç‡: {results['summary']['results_summary']['success_rate']:.1%}")
        print(f"âœ… å¹³å‡ç‰¹å¾æ•°: {results['summary']['results_summary']['average_features_per_symbol']:.0f}")
        
        if importance_report:
            print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§æŠ¥å‘Š: {importance_report}")
        if quality_report:
            print(f"ğŸ“‹ æ•°æ®è´¨é‡æŠ¥å‘Š: {quality_report}")
        if visualization_file:
            print(f"ğŸ“ˆ ç‰¹å¾å¯è§†åŒ–: {visualization_file}")
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. æŸ¥çœ‹ç”Ÿæˆçš„ç‰¹å¾é‡è¦æ€§æŠ¥å‘Šï¼Œé€‰æ‹©æ ¸å¿ƒç‰¹å¾é›†")
        print("2. æ£€æŸ¥æ•°æ®è´¨é‡æŠ¥å‘Šï¼Œç¡®ä¿æ•°æ®è´¨é‡ç¬¦åˆè¦æ±‚")
        print("3. ä½¿ç”¨ç”Ÿæˆçš„ç‰¹å¾æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œå›æµ‹")
        print("4. æ ¹æ®å®ç›˜è¡¨ç°è°ƒæ•´ç‰¹å¾å·¥ç¨‹ç­–ç•¥")
        
        print("\n" + "="*80)
        
    except Exception as e:
        logger.error(f"Feature engineering pipeline failed: {e}")
        print(f"âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()