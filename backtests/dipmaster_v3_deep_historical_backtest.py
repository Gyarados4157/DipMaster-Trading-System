#!/usr/bin/env python3
"""
DipMaster V3 æ·±åº¦å†å²å›æµ‹
2å¹´æœŸå®Œæ•´å›æµ‹ï¼Œé‡ç‚¹éªŒè¯DIPç­–ç•¥å¤åˆ»å’Œå¤§é¢äºæŸåˆ†æ

ç›®æ ‡ï¼š
1. éªŒè¯ç­–ç•¥æ˜¯å¦èƒ½å®Œæ•´å¤åˆ»DipMaster AIçš„é€¢è·Œä¹°å…¥æ“ä½œ
2. è¿›è¡Œ2å¹´æœŸæ·±åº¦å›æµ‹
3. é‡ç‚¹åˆ†æå¤§é¢äºæŸæƒ…å†µå’Œé£é™©æ§åˆ¶
4. ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å’Œé£é™©æŠ¥å‘Š
"""

import sys
import os
import json
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ srcè·¯å¾„
sys.path.append('src')
sys.path.append('src/core')

# å¯¼å…¥V3ç»„ä»¶
try:
    from src.core.comprehensive_backtest_v3 import ComprehensiveBacktestV3, BacktestConfig, BacktestMetrics
    from src.core.enhanced_signal_detector import EnhancedSignalDetector
    from src.core.asymmetric_risk_manager import AsymmetricRiskManager  
    from src.core.volatility_adaptive_sizing import VolatilityAdaptiveSizing
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'dipmaster_v3_deep_backtest_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class DipMasterDeepBacktest:
    """DipMaster V3 æ·±åº¦å†å²å›æµ‹å™¨"""
    
    def __init__(self):
        # æŒ‡å®šçš„9ä¸ªå¸å¯¹
        self.target_symbols = [
            'XRPUSDT', 'DOGEUSDT', 'ICPUSDT', 'IOTAUSDT', 
            'SOLUSDT', 'SUIUSDT', 'ALGOUSDT', 'BNBUSDT', 'ADAUSDT'
        ]
        
        # æ•°æ®æ˜ å°„ï¼ˆä¼˜å…ˆä½¿ç”¨æœ€é•¿æ—¶é—´æ•°æ®ï¼‰
        self.data_files = {
            'XRPUSDT': 'XRPUSDT_5m_2years.csv',       # 2å¹´æ•°æ® (æ–°)
            'DOGEUSDT': 'DOGEUSDT_5m_2years.csv',     # 2å¹´æ•°æ® (æ–°)
            'ICPUSDT': 'ICPUSDT_5m_2years.csv',       # 2å¹´æ•°æ®
            'IOTAUSDT': 'IOTAUSDT_5m_2years.csv',     # 2å¹´æ•°æ® (æ–°)
            'SOLUSDT': 'SOLUSDT_5m_2years.csv',       # 2å¹´æ•°æ® (æ–°)
            'ADAUSDT': 'ADAUSDT_5m_2years.csv',       # 2å¹´æ•°æ® (æ–°)
            'SUIUSDT': 'SUIUSDT_5m_2years.csv',       # 2å¹´æ•°æ® (æ–°)
            'ALGOUSDT': 'ALGOUSDT_5m_2years.csv',     # 2å¹´æ•°æ® (æ–°)
            'BNBUSDT': 'BNBUSDT_5m_2years.csv'        # 2å¹´æ•°æ® (æ–°)
        }
        
        self.data_path = Path("data/market_data")
        self.results_path = Path("results/deep_backtest")
        self.results_path.mkdir(exist_ok=True)
        
        # æ·±åº¦åˆ†æé…ç½®
        self.analysis_config = {
            'max_drawdown_alert': 0.05,      # 5%å›æ’¤è­¦æŠ¥
            'large_loss_threshold': 100,     # å•ç¬”å¤§é¢äºæŸé˜ˆå€¼ï¼ˆUSDï¼‰
            'consecutive_loss_limit': 5,     # è¿ç»­äºæŸç¬”æ•°é™åˆ¶
            'daily_loss_limit': 300,         # æ—¥äºæŸé™åˆ¶ï¼ˆUSDï¼‰
            'monthly_loss_limit': 1000       # æœˆäºæŸé™åˆ¶ï¼ˆUSDï¼‰
        }
        
    def load_and_prepare_data(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½å’Œå‡†å¤‡å¸‚åœºæ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹åŠ è½½å¸‚åœºæ•°æ®...")
        
        market_data = {}
        
        for symbol in self.target_symbols:
            if symbol in self.data_files:
                file_path = self.data_path / self.data_files[symbol]
                
                if file_path.exists():
                    logger.info(f"ğŸ“Š åŠ è½½ {symbol} æ•°æ®: {file_path}")
                    
                    try:
                        df = pd.read_csv(file_path)
                        
                        # æ•°æ®æ ‡å‡†åŒ–å¤„ç†
                        if 'datetime' in df.columns:
                            df['timestamp'] = pd.to_datetime(df['datetime'])
                        else:
                            df['timestamp'] = pd.to_datetime(df['timestamp'])
                        
                        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                        required_cols = ['open', 'high', 'low', 'close', 'volume']
                        if all(col in df.columns for col in required_cols):
                            df = df[['timestamp'] + required_cols].copy()
                            df.set_index('timestamp', inplace=True)
                            df.sort_index(inplace=True)
                            
                            # æ•°æ®è´¨é‡æ£€æŸ¥
                            df = self._clean_data(df)
                            
                            if len(df) > 1000:  # è‡³å°‘1000æ¡æ•°æ®
                                market_data[symbol] = df
                                logger.info(f"âœ… {symbol}: {len(df)}æ¡æ•°æ®, æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
                            else:
                                logger.warning(f"âš ï¸ {symbol}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                        else:
                            logger.error(f"âŒ {symbol}: ç¼ºå°‘å¿…è¦åˆ—")
                            
                    except Exception as e:
                        logger.error(f"âŒ åŠ è½½{symbol}æ•°æ®å¤±è´¥: {e}")
                else:
                    logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            else:
                logger.warning(f"âš ï¸ æœªé…ç½®{symbol}çš„æ•°æ®æ–‡ä»¶")
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(market_data)} ä¸ªå¸ç§æ•°æ®")
        return market_data
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†æ•°æ®"""
        # ç§»é™¤ç©ºå€¼
        df = df.dropna()
        
        # ç§»é™¤ä»·æ ¼ä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®
        price_cols = ['open', 'high', 'low', 'close']
        for col in price_cols:
            df = df[df[col] > 0]
        
        # ç§»é™¤å¼‚å¸¸ä»·æ ¼ï¼ˆä»·æ ¼è·³å˜è¶…è¿‡50%ï¼‰
        for col in price_cols:
            price_change = df[col].pct_change().abs()
            df = df[price_change < 0.5]
        
        # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
        df = df[(df['high'] >= df['low']) & 
                (df['high'] >= df['open']) & 
                (df['high'] >= df['close']) &
                (df['low'] <= df['open']) & 
                (df['low'] <= df['close'])]
        
        return df
    
    def analyze_dip_replication(self, backtest_results: List, market_data: Dict) -> Dict:
        """åˆ†æDIPç­–ç•¥å¤åˆ»æ•ˆæœ"""
        logger.info("ğŸ” åˆ†æDIPç­–ç•¥å¤åˆ»æ•ˆæœ...")
        
        dip_analysis = {
            'total_entries': 0,
            'dip_entries': 0,
            'dip_entry_rate': 0.0,
            'price_below_ma20_rate': 0.0,
            'rsi_in_range_rate': 0.0,
            'volume_surge_rate': 0.0,
            'boundary_exit_rate': 0.0,
            'avg_holding_minutes': 0.0,
            'dip_characteristics': {}
        }
        
        if not backtest_results:
            return dip_analysis
        
        # åˆ†ææ¯ç¬”äº¤æ˜“çš„DIPç‰¹å¾
        dip_entries = 0
        ma20_below_count = 0
        rsi_range_count = 0
        volume_surge_count = 0
        boundary_exits = 0
        total_holding_time = 0
        
        for trade in backtest_results:
            dip_analysis['total_entries'] += 1
            
            # è·å–å…¥åœºæ—¶çš„å¸‚åœºæ•°æ®
            symbol = trade.symbol
            entry_time = trade.entry_time
            
            if symbol in market_data:
                df = market_data[symbol]
                
                # æ‰¾åˆ°å…¥åœºæ—¶é—´ç‚¹çš„æ•°æ®
                entry_data = df[df.index <= entry_time]
                if len(entry_data) >= 20:
                    current_data = entry_data.iloc[-1]
                    ma20 = entry_data['close'].rolling(20).mean().iloc[-1]
                    
                    # æ£€æŸ¥DIPç‰¹å¾
                    # 1. ä»·æ ¼ä½äºMA20
                    if current_data['close'] < ma20:
                        ma20_below_count += 1
                    
                    # 2. æ£€æŸ¥RSIï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                    if len(entry_data) >= 14:
                        rsi = self._calculate_simple_rsi(entry_data['close'], 14)
                        if 30 <= rsi <= 50:  # DipMasterçš„RSIèŒƒå›´
                            rsi_range_count += 1
                    
                    # 3. æ£€æŸ¥æˆäº¤é‡æ”¾å¤§
                    if len(entry_data) >= 10:
                        vol_ma = entry_data['volume'].rolling(10).mean().iloc[-2]
                        current_vol = current_data['volume']
                        if current_vol > vol_ma * 1.5:  # 1.5å€æˆäº¤é‡
                            volume_surge_count += 1
                    
                    # 4. æ£€æŸ¥æ˜¯å¦ä¸ºé€¢è·Œä¹°å…¥
                    if current_data['close'] < current_data['open']:
                        dip_entries += 1
            
            # æ£€æŸ¥å‡ºåœºç‰¹å¾
            if hasattr(trade, 'exit_reason'):
                if 'boundary' in trade.exit_reason.lower():
                    boundary_exits += 1
            
            # ç´¯è®¡æŒä»“æ—¶é—´
            if hasattr(trade, 'holding_minutes'):
                total_holding_time += trade.holding_minutes
        
        # è®¡ç®—æ¯”ç‡
        total = dip_analysis['total_entries']
        if total > 0:
            dip_analysis['dip_entries'] = dip_entries
            dip_analysis['dip_entry_rate'] = dip_entries / total * 100
            dip_analysis['price_below_ma20_rate'] = ma20_below_count / total * 100
            dip_analysis['rsi_in_range_rate'] = rsi_range_count / total * 100
            dip_analysis['volume_surge_rate'] = volume_surge_count / total * 100
            dip_analysis['boundary_exit_rate'] = boundary_exits / total * 100
            dip_analysis['avg_holding_minutes'] = total_holding_time / total
        
        logger.info(f"âœ… DIPç­–ç•¥åˆ†æå®Œæˆ:")
        logger.info(f"   é€¢è·Œä¹°å…¥ç‡: {dip_analysis['dip_entry_rate']:.1f}%")
        logger.info(f"   MA20ä¸‹æ–¹ç‡: {dip_analysis['price_below_ma20_rate']:.1f}%")
        logger.info(f"   è¾¹ç•Œå‡ºåœºç‡: {dip_analysis['boundary_exit_rate']:.1f}%")
        
        return dip_analysis
    
    def analyze_large_losses(self, backtest_results: List) -> Dict:
        """æ·±åº¦åˆ†æå¤§é¢äºæŸæƒ…å†µ"""
        logger.info("ğŸ” æ·±åº¦åˆ†æå¤§é¢äºæŸæƒ…å†µ...")
        
        loss_analysis = {
            'total_trades': len(backtest_results),
            'losing_trades': 0,
            'large_losses': [],
            'consecutive_losses': [],
            'max_consecutive_losses': 0,
            'daily_losses': {},
            'monthly_losses': {},
            'worst_periods': [],
            'loss_distribution': {},
            'risk_metrics': {}
        }
        
        if not backtest_results:
            return loss_analysis
        
        # åˆ†ææ¯ç¬”äº¤æ˜“
        consecutive_count = 0
        max_consecutive = 0
        current_streak = []
        
        for i, trade in enumerate(backtest_results):
            pnl_usd = trade.pnl_usd if hasattr(trade, 'pnl_usd') else 0
            
            if pnl_usd < 0:
                loss_analysis['losing_trades'] += 1
                consecutive_count += 1
                current_streak.append(trade)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¤§é¢äºæŸ
                if abs(pnl_usd) >= self.analysis_config['large_loss_threshold']:
                    loss_analysis['large_losses'].append({
                        'trade_id': i + 1,
                        'symbol': trade.symbol,
                        'loss_usd': pnl_usd,
                        'loss_percent': trade.pnl_percent if hasattr(trade, 'pnl_percent') else 0,
                        'entry_time': trade.entry_time,
                        'exit_time': trade.exit_time,
                        'holding_minutes': trade.holding_minutes if hasattr(trade, 'holding_minutes') else 0
                    })
                
                # è®°å½•æ—¥æŸå¤±
                trade_date = trade.entry_time.date()
                if trade_date not in loss_analysis['daily_losses']:
                    loss_analysis['daily_losses'][trade_date] = 0
                loss_analysis['daily_losses'][trade_date] += pnl_usd
                
                # è®°å½•æœˆæŸå¤±
                month_key = f"{trade_date.year}-{trade_date.month:02d}"
                if month_key not in loss_analysis['monthly_losses']:
                    loss_analysis['monthly_losses'][month_key] = 0
                loss_analysis['monthly_losses'][month_key] += pnl_usd
                
            else:
                # ç›ˆåˆ©äº¤æ˜“ï¼Œé‡ç½®è¿ç»­äºæŸè®¡æ•°
                if consecutive_count > 0:
                    loss_analysis['consecutive_losses'].append({
                        'count': consecutive_count,
                        'trades': current_streak.copy(),
                        'total_loss': sum(t.pnl_usd for t in current_streak),
                        'period': f"{current_streak[0].entry_time} åˆ° {current_streak[-1].exit_time}"
                    })
                    max_consecutive = max(max_consecutive, consecutive_count)
                    consecutive_count = 0
                    current_streak = []
        
        # å¤„ç†æœ€åçš„è¿ç»­äºæŸ
        if consecutive_count > 0:
            loss_analysis['consecutive_losses'].append({
                'count': consecutive_count,
                'trades': current_streak.copy(),
                'total_loss': sum(t.pnl_usd for t in current_streak),
                'period': f"{current_streak[0].entry_time} åˆ° {current_streak[-1].exit_time}"
            })
            max_consecutive = max(max_consecutive, consecutive_count)
        
        loss_analysis['max_consecutive_losses'] = max_consecutive
        
        # æ‰¾å‡ºæœ€ç³Ÿç³•çš„æ—¶æœŸ
        worst_days = sorted(loss_analysis['daily_losses'].items(), key=lambda x: x[1])[:5]
        worst_months = sorted(loss_analysis['monthly_losses'].items(), key=lambda x: x[1])[:3]
        
        loss_analysis['worst_periods'] = {
            'worst_days': [{'date': str(d), 'loss_usd': l} for d, l in worst_days],
            'worst_months': [{'month': m, 'loss_usd': l} for m, l in worst_months]
        }
        
        # äºæŸåˆ†å¸ƒç»Ÿè®¡
        all_losses = [t.pnl_usd for t in backtest_results if t.pnl_usd < 0]
        if all_losses:
            loss_analysis['loss_distribution'] = {
                'min_loss': min(all_losses),
                'max_loss': max(all_losses),
                'avg_loss': np.mean(all_losses),
                'median_loss': np.median(all_losses),
                'std_loss': np.std(all_losses),
                'percentiles': {
                    '95th': np.percentile(all_losses, 5),  # æœ€ç³Ÿç³•çš„5%
                    '90th': np.percentile(all_losses, 10),
                    '75th': np.percentile(all_losses, 25)
                }
            }
        
        # é£é™©æŒ‡æ ‡
        total_pnl = sum(t.pnl_usd for t in backtest_results)
        losing_trades_pnl = sum(t.pnl_usd for t in backtest_results if t.pnl_usd < 0)
        
        loss_analysis['risk_metrics'] = {
            'win_rate': (loss_analysis['total_trades'] - loss_analysis['losing_trades']) / loss_analysis['total_trades'] * 100,
            'loss_rate': loss_analysis['losing_trades'] / loss_analysis['total_trades'] * 100,
            'avg_loss_per_losing_trade': losing_trades_pnl / loss_analysis['losing_trades'] if loss_analysis['losing_trades'] > 0 else 0,
            'total_losses_usd': losing_trades_pnl,
            'largest_drawdown_trade': min(all_losses) if all_losses else 0,
            'risk_of_ruin': self._calculate_risk_of_ruin(backtest_results)
        }
        
        logger.info(f"âœ… äºæŸåˆ†æå®Œæˆ:")
        logger.info(f"   æ€»äº¤æ˜“æ•°: {loss_analysis['total_trades']}")
        logger.info(f"   äºæŸäº¤æ˜“æ•°: {loss_analysis['losing_trades']}")
        logger.info(f"   å¤§é¢äºæŸæ•°: {len(loss_analysis['large_losses'])}")
        logger.info(f"   æœ€å¤§è¿ç»­äºæŸ: {loss_analysis['max_consecutive_losses']}ç¬”")
        
        return loss_analysis
    
    def _calculate_simple_rsi(self, prices: pd.Series, period: int = 14) -> float:
        """ç®€åŒ–RSIè®¡ç®—"""
        if len(prices) < period + 1:
            return 50  # é»˜è®¤ä¸­æ€§å€¼
        
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else 50
    
    def _calculate_risk_of_ruin(self, trades: List) -> float:
        """è®¡ç®—ç ´äº§é£é™©"""
        if not trades:
            return 0.0
        
        wins = [t.pnl_usd for t in trades if t.pnl_usd > 0]
        losses = [abs(t.pnl_usd) for t in trades if t.pnl_usd < 0]
        
        if not wins or not losses:
            return 0.0
        
        win_rate = len(wins) / len(trades)
        avg_win = np.mean(wins)
        avg_loss = np.mean(losses)
        
        if avg_win <= avg_loss:
            return 100.0  # å¦‚æœå¹³å‡äºæŸå¤§äºç­‰äºå¹³å‡ç›ˆåˆ©ï¼Œç ´äº§é£é™©æé«˜
        
        # ç®€åŒ–çš„ç ´äº§é£é™©è®¡ç®—
        advantage = (win_rate * avg_win) - ((1 - win_rate) * avg_loss)
        if advantage <= 0:
            return 100.0
        
        # Kellyå…¬å¼
        kelly = (win_rate * avg_win - (1 - win_rate) * avg_loss) / avg_win
        
        if kelly <= 0:
            return 100.0
        
        # ç®€åŒ–çš„ç ´äº§é£é™©ä¼°ç®—
        return max(0, min(100, (1 - kelly) * 100))
    
    def run_comprehensive_backtest(self) -> Dict:
        """è¿è¡Œç»¼åˆæ·±åº¦å›æµ‹"""
        logger.info("ğŸš€ å¼€å§‹DipMaster V3æ·±åº¦å†å²å›æµ‹...")
        
        # åŠ è½½æ•°æ®
        market_data = self.load_and_prepare_data()
        if not market_data:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„å¸‚åœºæ•°æ®")
            return {}
        
        # ç¡®å®šå›æµ‹æ—¶é—´èŒƒå›´
        all_start_dates = [df.index[0] for df in market_data.values()]
        all_end_dates = [df.index[-1] for df in market_data.values()]
        
        # ä½¿ç”¨æ‰€æœ‰æ•°æ®çš„é‡å æ—¶é—´æ®µ
        backtest_start = max(all_start_dates)
        backtest_end = min(all_end_dates)
        
        logger.info(f"ğŸ“… å›æµ‹æ—¶é—´èŒƒå›´: {backtest_start} åˆ° {backtest_end}")
        logger.info(f"ğŸ“Š å›æµ‹å¸ç§: {list(market_data.keys())}")
        
        # é…ç½®å›æµ‹å‚æ•°
        config = BacktestConfig(
            start_date=backtest_start.strftime("%Y-%m-%d"),
            end_date=backtest_end.strftime("%Y-%m-%d"),
            initial_capital=10000,
            symbols=list(market_data.keys()),
            commission_rate=0.0004,  # 0.04%æ‰‹ç»­è´¹
            slippage_bps=2.0,        # 2BPæ»‘ç‚¹
            max_positions=3,
            use_enhanced_signals=True,
            use_asymmetric_risk=True,
            use_adaptive_sizing=True,
            use_symbol_scoring=False,  # ç®€åŒ–æµ‹è¯•
            use_time_filtering=False   # ç®€åŒ–æµ‹è¯•
        )
        
        # åˆ›å»ºå›æµ‹å®ä¾‹
        backtest = ComprehensiveBacktestV3(config)
        
        # åŠ è½½æ•°æ®åˆ°å›æµ‹å™¨
        for symbol, df in market_data.items():
            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            filtered_df = df[(df.index >= backtest_start) & (df.index <= backtest_end)]
            if len(filtered_df) > 100:
                backtest.price_data[symbol] = filtered_df
                logger.info(f"âœ… {symbol}: åŠ è½½{len(filtered_df)}æ¡æ•°æ®")
        
        # è¿è¡Œå›æµ‹
        try:
            logger.info("â³ æ­£åœ¨è¿è¡Œæ·±åº¦å›æµ‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
            metrics = backtest.run_backtest()
            
            # æ·±åº¦åˆ†æ
            logger.info("ğŸ” å¼€å§‹æ·±åº¦åˆ†æ...")
            
            # DIPç­–ç•¥å¤åˆ»åˆ†æ
            dip_analysis = self.analyze_dip_replication(backtest.trade_history, market_data)
            
            # å¤§é¢äºæŸåˆ†æ
            loss_analysis = self.analyze_large_losses(backtest.trade_history)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            comprehensive_report = {
                'backtest_info': {
                    'strategy_version': 'DipMaster V3 Deep Backtest',
                    'start_date': config.start_date,
                    'end_date': config.end_date,
                    'symbols_tested': config.symbols,
                    'total_days': (backtest_end - backtest_start).days,
                    'data_points': sum(len(df) for df in backtest.price_data.values())
                },
                'performance_metrics': {
                    'total_trades': metrics.total_trades,
                    'winning_trades': metrics.winning_trades,
                    'losing_trades': metrics.losing_trades,
                    'win_rate': metrics.win_rate,
                    'total_return': metrics.total_return,
                    'profit_factor': metrics.profit_factor,
                    'max_drawdown_percent': metrics.max_drawdown_percent,
                    'sharpe_ratio': metrics.sharpe_ratio,
                    'avg_holding_minutes': metrics.avg_holding_minutes
                },
                'dip_strategy_analysis': dip_analysis,
                'loss_risk_analysis': loss_analysis,
                'risk_assessment': self._generate_risk_assessment(metrics, loss_analysis),
                'timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            report_file = self.results_path / f"dipmaster_v3_deep_backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
            return comprehensive_report
            
        except Exception as e:
            logger.error(f"âŒ å›æµ‹æ‰§è¡Œå¤±è´¥: {e}")
            return {}
    
    def _generate_risk_assessment(self, metrics, loss_analysis: Dict) -> Dict:
        """ç”Ÿæˆé£é™©è¯„ä¼°"""
        risk_level = "LOW"
        warnings = []
        recommendations = []
        
        # æ£€æŸ¥å„é¡¹é£é™©æŒ‡æ ‡
        if metrics.max_drawdown_percent > 5:
            risk_level = "HIGH"
            warnings.append(f"æœ€å¤§å›æ’¤è¿‡é«˜: {metrics.max_drawdown_percent:.1f}%")
        elif metrics.max_drawdown_percent > 3:
            risk_level = "MEDIUM"
            warnings.append(f"å›æ’¤åé«˜: {metrics.max_drawdown_percent:.1f}%")
        
        if loss_analysis['max_consecutive_losses'] > 5:
            risk_level = "HIGH"
            warnings.append(f"è¿ç»­äºæŸè¿‡å¤š: {loss_analysis['max_consecutive_losses']}ç¬”")
        
        if len(loss_analysis['large_losses']) > 0:
            warnings.append(f"å‘ç°{len(loss_analysis['large_losses'])}ç¬”å¤§é¢äºæŸ")
        
        if metrics.win_rate < 70:
            warnings.append(f"èƒœç‡åä½: {metrics.win_rate:.1f}%")
        
        # ç”Ÿæˆå»ºè®®
        if risk_level == "HIGH":
            recommendations.extend([
                "å»ºè®®é™ä½ä»“ä½å¤§å°",
                "åŠ å¼ºé£é™©æ§åˆ¶å‚æ•°",
                "è€ƒè™‘å¢åŠ æ­¢æŸæœºåˆ¶"
            ])
        elif risk_level == "MEDIUM":
            recommendations.extend([
                "ç›‘æ§é£é™©æŒ‡æ ‡å˜åŒ–",
                "è€ƒè™‘ä¼˜åŒ–å…¥åœºæ¡ä»¶"
            ])
        else:
            recommendations.append("é£é™©æ§åˆ¶è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å®ç›˜æµ‹è¯•")
        
        return {
            'risk_level': risk_level,
            'warnings': warnings,
            'recommendations': recommendations,
            'overall_assessment': self._get_overall_assessment(metrics, loss_analysis)
        }
    
    def _get_overall_assessment(self, metrics, loss_analysis: Dict) -> str:
        """ç»¼åˆè¯„ä¼°"""
        if metrics.win_rate >= 75 and metrics.max_drawdown_percent <= 3 and loss_analysis['max_consecutive_losses'] <= 3:
            return "ç­–ç•¥è¡¨ç°ä¼˜ç§€ï¼Œé£é™©æ§åˆ¶è‰¯å¥½ï¼Œå»ºè®®è¿›å…¥çº¸é¢äº¤æ˜“æµ‹è¯•é˜¶æ®µ"
        elif metrics.win_rate >= 65 and metrics.max_drawdown_percent <= 5:
            return "ç­–ç•¥è¡¨ç°è‰¯å¥½ï¼Œä½†éœ€è¦å…³æ³¨é£é™©æ§åˆ¶ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–"
        else:
            return "ç­–ç•¥å­˜åœ¨è¾ƒå¤§é£é™©ï¼Œéœ€è¦é‡æ–°ä¼˜åŒ–å‚æ•°æˆ–è°ƒæ•´ç­–ç•¥é€»è¾‘"

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ DipMaster V3 æ·±åº¦å†å²å›æµ‹")
    print("=" * 60)
    
    # åˆ›å»ºå›æµ‹å™¨
    backtest_runner = DipMasterDeepBacktest()
    
    # è¿è¡Œæ·±åº¦å›æµ‹
    results = backtest_runner.run_comprehensive_backtest()
    
    if results:
        print("\nğŸ“Š å›æµ‹ç»“æœæ‘˜è¦:")
        print("=" * 60)
        
        perf = results.get('performance_metrics', {})
        dip = results.get('dip_strategy_analysis', {})
        loss = results.get('loss_risk_analysis', {})
        risk = results.get('risk_assessment', {})
        
        print(f"æ€»äº¤æ˜“æ•°: {perf.get('total_trades', 0)}")
        print(f"èƒœç‡: {perf.get('win_rate', 0):.1f}%")
        print(f"æ€»æ”¶ç›Š: {perf.get('total_return', 0):.1f}%")
        print(f"æœ€å¤§å›æ’¤: {perf.get('max_drawdown_percent', 0):.1f}%")
        print(f"å¤æ™®ç‡: {perf.get('sharpe_ratio', 0):.2f}")
        
        print(f"\nğŸ¯ DIPç­–ç•¥å¤åˆ»æ•ˆæœ:")
        print(f"é€¢è·Œä¹°å…¥ç‡: {dip.get('dip_entry_rate', 0):.1f}%")
        print(f"MA20ä¸‹æ–¹ç‡: {dip.get('price_below_ma20_rate', 0):.1f}%")
        print(f"è¾¹ç•Œå‡ºåœºç‡: {dip.get('boundary_exit_rate', 0):.1f}%")
        
        print(f"\nâš ï¸ é£é™©åˆ†æ:")
        print(f"äºæŸäº¤æ˜“æ•°: {loss.get('losing_trades', 0)}")
        print(f"å¤§é¢äºæŸæ•°: {len(loss.get('large_losses', []))}")
        print(f"æœ€å¤§è¿ç»­äºæŸ: {loss.get('max_consecutive_losses', 0)}ç¬”")
        print(f"é£é™©ç­‰çº§: {risk.get('risk_level', 'UNKNOWN')}")
        
        print(f"\nğŸ“ ç»¼åˆè¯„ä¼°:")
        print(f"{risk.get('overall_assessment', 'N/A')}")
        
        if risk.get('warnings'):
            print(f"\nâš ï¸ é£é™©è­¦å‘Š:")
            for warning in risk.get('warnings', []):
                print(f"  - {warning}")
        
        if risk.get('recommendations'):
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in risk.get('recommendations', []):
                print(f"  - {rec}")
        
        print("\nğŸ‰ æ·±åº¦å›æµ‹å®Œæˆ!")
        return 0
    else:
        print("âŒ å›æµ‹å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)