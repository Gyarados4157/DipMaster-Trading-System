"""
DipMaster Enhanced V4 - å®æ—¶é£é™©ç®¡ç†ç³»ç»Ÿ
å¤šå±‚çº§é£é™©æ§åˆ¶å’Œç›‘æ§æ¡†æ¶

ä½œè€…: DipMaster Trading System  
ç‰ˆæœ¬: 4.0.0
åˆ›å»ºæ—¶é—´: 2025-08-16
"""

import numpy as np
import pandas as pd
from scipy import stats
from typing import Dict, List, Tuple, Optional, Any
import json
from datetime import datetime, timedelta
import warnings
from dataclasses import dataclass
warnings.filterwarnings('ignore')

@dataclass
class RiskMetrics:
    """é£é™©æŒ‡æ ‡æ•°æ®ç±»"""
    portfolio_var_95: float
    portfolio_var_99: float
    portfolio_es_95: float
    portfolio_volatility: float
    beta: float
    max_drawdown: float
    sharpe_ratio: float
    calmar_ratio: float
    correlation_risk: float
    concentration_risk: float

@dataclass
class StressTestResult:
    """å‹åŠ›æµ‹è¯•ç»“æœ"""
    scenario_name: str
    portfolio_change: float
    worst_position_change: float
    correlation_breakdown: bool
    liquidity_impact: float

class RealTimeRiskManager:
    """
    å®æ—¶é£é™©ç®¡ç†ç³»ç»Ÿ
    
    åŠŸèƒ½ç‰¹æ€§:
    1. å®æ—¶VaRå’ŒESè®¡ç®—
    2. åŠ¨æ€ç›¸å…³æ€§ç›‘æ§
    3. å‹åŠ›æµ‹è¯•å’Œæƒ…æ™¯åˆ†æ
    4. æµåŠ¨æ€§é£é™©è¯„ä¼°
    5. é›†ä¸­åº¦é£é™©æ§åˆ¶
    6. å¤šçº§é¢„è­¦ç³»ç»Ÿ
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # é£é™©é™åˆ¶å‚æ•°
        self.max_portfolio_var = config.get('max_portfolio_var', 0.02)  # 2%æ—¥VaR
        self.max_concentration = config.get('max_concentration', 0.30)  # 30%æœ€å¤§é›†ä¸­åº¦
        self.max_correlation_exposure = config.get('max_correlation_exposure', 0.70)  # 70%ç›¸å…³æ€§é™åˆ¶
        self.max_drawdown_threshold = config.get('max_drawdown_threshold', 0.03)  # 3%æœ€å¤§å›æ’¤
        
        # é¢„è­¦é˜ˆå€¼
        self.warning_var_threshold = self.max_portfolio_var * 0.8  # 80%è­¦å‘Šçº¿
        self.critical_var_threshold = self.max_portfolio_var * 0.95  # 95%ä¸´ç•Œçº¿
        
        # å†å²æ•°æ®çª—å£
        self.var_window = config.get('var_window', 252)  # VaRè®¡ç®—çª—å£
        self.correlation_window = config.get('correlation_window', 30)  # ç›¸å…³æ€§çª—å£
        self.stress_scenarios = self._define_stress_scenarios()
        
        # ç¼“å­˜
        self._risk_cache = {}
        self._last_update = None
        
    def calculate_real_time_risk(self, 
                                portfolio_weights: Dict[str, float],
                                market_data: pd.DataFrame,
                                returns_data: pd.DataFrame) -> RiskMetrics:
        """
        è®¡ç®—å®æ—¶é£é™©æŒ‡æ ‡
        
        å‚æ•°:
        - portfolio_weights: ç»„åˆæƒé‡ {symbol: weight}
        - market_data: æœ€æ–°å¸‚åœºæ•°æ®
        - returns_data: å†å²æ”¶ç›Šç‡æ•°æ®
        
        è¿”å›:
        - RiskMetricså¯¹è±¡
        """
        
        if not portfolio_weights:
            return self._empty_risk_metrics()
        
        # æ•°æ®å‡†å¤‡
        symbols = list(portfolio_weights.keys())
        weights = np.array([portfolio_weights[symbol] for symbol in symbols])
        
        # è·å–æ”¶ç›Šç‡å­é›†
        returns_subset = returns_data[symbols].dropna()
        
        if len(returns_subset) < 30:
            raise ValueError("å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—é£é™©æŒ‡æ ‡")
        
        # 1. VaRå’ŒESè®¡ç®—
        var_95, var_99, es_95 = self._calculate_var_es(weights, returns_subset)
        
        # 2. ç»„åˆæ³¢åŠ¨ç‡
        portfolio_vol = self._calculate_portfolio_volatility(weights, returns_subset)
        
        # 3. Betaè®¡ç®—
        portfolio_beta = self._calculate_portfolio_beta(weights, returns_subset, symbols)
        
        # 4. æœ€å¤§å›æ’¤
        portfolio_returns = self._calculate_portfolio_returns(weights, returns_subset)
        max_dd = self._calculate_max_drawdown(portfolio_returns)
        
        # 5. å¤æ™®æ¯”ç‡å’Œå¡å°”ç›æ¯”ç‡
        sharpe = self._calculate_sharpe_ratio(portfolio_returns)
        calmar = self._calculate_calmar_ratio(portfolio_returns, max_dd)
        
        # 6. ç›¸å…³æ€§é£é™©
        correlation_risk = self._calculate_correlation_risk(weights, returns_subset)
        
        # 7. é›†ä¸­åº¦é£é™©
        concentration_risk = self._calculate_concentration_risk(weights)
        
        return RiskMetrics(
            portfolio_var_95=var_95,
            portfolio_var_99=var_99,
            portfolio_es_95=es_95,
            portfolio_volatility=portfolio_vol,
            beta=portfolio_beta,
            max_drawdown=max_dd,
            sharpe_ratio=sharpe,
            calmar_ratio=calmar,
            correlation_risk=correlation_risk,
            concentration_risk=concentration_risk
        )
    
    def perform_stress_test(self, 
                           portfolio_weights: Dict[str, float],
                           returns_data: pd.DataFrame) -> List[StressTestResult]:
        """
        æ‰§è¡Œå‹åŠ›æµ‹è¯•
        
        å‚æ•°:
        - portfolio_weights: å½“å‰ç»„åˆæƒé‡
        - returns_data: å†å²æ”¶ç›Šç‡æ•°æ®
        
        è¿”å›:
        - å‹åŠ›æµ‹è¯•ç»“æœåˆ—è¡¨
        """
        
        results = []
        symbols = list(portfolio_weights.keys())
        weights = np.array([portfolio_weights[symbol] for symbol in symbols])
        returns_subset = returns_data[symbols].dropna()
        
        for scenario in self.stress_scenarios:
            result = self._run_stress_scenario(scenario, weights, returns_subset, symbols)
            results.append(result)
        
        return results
    
    def monitor_risk_limits(self, risk_metrics: RiskMetrics) -> Dict[str, Any]:
        """
        ç›‘æ§é£é™©é™åˆ¶
        
        å‚æ•°:
        - risk_metrics: å½“å‰é£é™©æŒ‡æ ‡
        
        è¿”å›:
        - é£é™©ç›‘æ§ç»“æœ
        """
        
        alerts = []
        risk_level = "LOW"
        
        # VaRæ£€æŸ¥
        if risk_metrics.portfolio_var_95 > self.critical_var_threshold:
            alerts.append({
                "type": "CRITICAL",
                "metric": "VaR_95",
                "value": risk_metrics.portfolio_var_95,
                "threshold": self.critical_var_threshold,
                "message": "ç»„åˆVaRè¶…è¿‡ä¸´ç•Œé˜ˆå€¼ï¼Œéœ€è¦ç«‹å³å‡ä»“"
            })
            risk_level = "CRITICAL"
        elif risk_metrics.portfolio_var_95 > self.warning_var_threshold:
            alerts.append({
                "type": "WARNING", 
                "metric": "VaR_95",
                "value": risk_metrics.portfolio_var_95,
                "threshold": self.warning_var_threshold,
                "message": "ç»„åˆVaRæ¥è¿‘è­¦å‘Šçº¿ï¼Œå»ºè®®è°ƒæ•´ä»“ä½"
            })
            risk_level = max(risk_level, "MEDIUM")
        
        # å›æ’¤æ£€æŸ¥
        if risk_metrics.max_drawdown > self.max_drawdown_threshold:
            alerts.append({
                "type": "CRITICAL",
                "metric": "max_drawdown", 
                "value": risk_metrics.max_drawdown,
                "threshold": self.max_drawdown_threshold,
                "message": "æœ€å¤§å›æ’¤è¶…é™ï¼Œè§¦å‘é£é™©æ§åˆ¶"
            })
            risk_level = "CRITICAL"
        
        # é›†ä¸­åº¦æ£€æŸ¥
        if risk_metrics.concentration_risk > self.max_concentration:
            alerts.append({
                "type": "WARNING",
                "metric": "concentration_risk",
                "value": risk_metrics.concentration_risk, 
                "threshold": self.max_concentration,
                "message": "ä»“ä½è¿‡åº¦é›†ä¸­ï¼Œå»ºè®®åˆ†æ•£åŒ–"
            })
            risk_level = max(risk_level, "MEDIUM")
        
        # ç›¸å…³æ€§æ£€æŸ¥
        if risk_metrics.correlation_risk > self.max_correlation_exposure:
            alerts.append({
                "type": "WARNING",
                "metric": "correlation_risk",
                "value": risk_metrics.correlation_risk,
                "threshold": self.max_correlation_exposure,
                "message": "ç›¸å…³æ€§é£é™©è¿‡é«˜ï¼Œå»ºè®®è°ƒæ•´ç»„åˆ"
            })
            risk_level = max(risk_level, "MEDIUM")
        
        return {
            "risk_level": risk_level,
            "alerts": alerts,
            "total_alerts": len(alerts),
            "critical_alerts": len([a for a in alerts if a["type"] == "CRITICAL"]),
            "warning_alerts": len([a for a in alerts if a["type"] == "WARNING"]),
            "timestamp": datetime.now().isoformat()
        }
    
    def generate_risk_report(self, 
                           portfolio_weights: Dict[str, float],
                           market_data: pd.DataFrame,
                           returns_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´é£é™©æŠ¥å‘Š
        
        å‚æ•°:
        - portfolio_weights: ç»„åˆæƒé‡
        - market_data: å¸‚åœºæ•°æ®
        - returns_data: æ”¶ç›Šç‡æ•°æ®
        
        è¿”å›:
        - å®Œæ•´é£é™©æŠ¥å‘Š
        """
        
        # 1. åŸºç¡€é£é™©æŒ‡æ ‡
        risk_metrics = self.calculate_real_time_risk(portfolio_weights, market_data, returns_data)
        
        # 2. é£é™©é™åˆ¶ç›‘æ§
        risk_monitoring = self.monitor_risk_limits(risk_metrics)
        
        # 3. å‹åŠ›æµ‹è¯•
        stress_results = self.perform_stress_test(portfolio_weights, returns_data)
        
        # 4. ç›¸å…³æ€§çŸ©é˜µ
        symbols = list(portfolio_weights.keys())
        correlation_matrix = self._calculate_correlation_matrix(returns_data[symbols])
        
        # 5. VaRåˆ†è§£
        var_attribution = self._calculate_var_attribution(portfolio_weights, returns_data)
        
        # 6. æµåŠ¨æ€§åˆ†æ
        liquidity_analysis = self._analyze_liquidity_risk(portfolio_weights, market_data)
        
        # 7. å†å²VaRå›æµ‹
        var_backtest = self._backtest_var_model(portfolio_weights, returns_data)
        
        risk_report = {
            "timestamp": datetime.now().isoformat(),
            "portfolio_summary": {
                "total_positions": len([w for w in portfolio_weights.values() if w > 1e-6]),
                "gross_exposure": sum(abs(w) for w in portfolio_weights.values()),
                "net_exposure": sum(portfolio_weights.values()),
                "largest_position": max(portfolio_weights.values()) if portfolio_weights else 0
            },
            "risk_metrics": {
                "VaR_95_daily": risk_metrics.portfolio_var_95,
                "VaR_99_daily": risk_metrics.portfolio_var_99,
                "ES_95_daily": risk_metrics.portfolio_es_95,
                "annualized_volatility": risk_metrics.portfolio_volatility,
                "portfolio_beta": risk_metrics.beta,
                "max_drawdown": risk_metrics.max_drawdown,
                "sharpe_ratio": risk_metrics.sharpe_ratio,
                "calmar_ratio": risk_metrics.calmar_ratio
            },
            "risk_monitoring": risk_monitoring,
            "stress_test_results": [
                {
                    "scenario": result.scenario_name,
                    "portfolio_pnl": result.portfolio_change,
                    "worst_position": result.worst_position_change,
                    "correlation_breakdown": result.correlation_breakdown,
                    "liquidity_impact": result.liquidity_impact
                }
                for result in stress_results
            ],
            "correlation_analysis": {
                "correlation_matrix": correlation_matrix.to_dict(),
                "average_correlation": correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean(),
                "max_correlation": correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].max(),
                "correlation_risk_score": risk_metrics.correlation_risk
            },
            "var_attribution": var_attribution,
            "liquidity_analysis": liquidity_analysis,
            "var_backtest": var_backtest,
            "recommendations": self._generate_risk_recommendations(risk_metrics, risk_monitoring)
        }
        
        return risk_report
    
    def _calculate_var_es(self, weights: np.ndarray, returns: pd.DataFrame) -> Tuple[float, float, float]:
        """è®¡ç®—VaRå’ŒæœŸæœ›æŸå¤±(ES)"""
        
        # ç»„åˆæ”¶ç›Šç‡
        portfolio_returns = (returns.values @ weights).flatten()
        
        # VaRè®¡ç®— (å†å²æ¨¡æ‹Ÿæ³•)
        var_95 = np.percentile(portfolio_returns, 5)  # 5%åˆ†ä½æ•°
        var_99 = np.percentile(portfolio_returns, 1)  # 1%åˆ†ä½æ•°
        
        # æœŸæœ›æŸå¤± (ES) - è¶…è¿‡VaRçš„å¹³å‡æŸå¤±
        es_95 = portfolio_returns[portfolio_returns <= var_95].mean()
        
        return abs(var_95), abs(var_99), abs(es_95)
    
    def _calculate_portfolio_volatility(self, weights: np.ndarray, returns: pd.DataFrame) -> float:
        """è®¡ç®—ç»„åˆæ³¢åŠ¨ç‡"""
        
        cov_matrix = returns.cov().values
        portfolio_variance = weights.T @ cov_matrix @ weights
        # å¹´åŒ–æ³¢åŠ¨ç‡
        return np.sqrt(portfolio_variance * 252)
    
    def _calculate_portfolio_beta(self, weights: np.ndarray, returns: pd.DataFrame, symbols: List[str]) -> float:
        """è®¡ç®—ç»„åˆBeta"""
        
        # å‡è®¾BTCä¸ºå¸‚åœºåŸºå‡†
        if 'BTCUSDT' in symbols:
            market_returns = returns['BTCUSDT']
            portfolio_returns = (returns.values @ weights).flatten()
            
            # Beta = Cov(portfolio, market) / Var(market)
            covariance = np.cov(portfolio_returns, market_returns)[0, 1]
            market_variance = np.var(market_returns)
            
            return covariance / market_variance if market_variance > 0 else 0.0
        else:
            # ä½¿ç”¨ç­‰æƒé‡å¸‚åœºæŒ‡æ•°
            market_returns = returns.mean(axis=1)
            portfolio_returns = (returns.values @ weights).flatten()
            
            covariance = np.cov(portfolio_returns, market_returns)[0, 1]
            market_variance = np.var(market_returns)
            
            return covariance / market_variance if market_variance > 0 else 0.0
    
    def _calculate_portfolio_returns(self, weights: np.ndarray, returns: pd.DataFrame) -> pd.Series:
        """è®¡ç®—ç»„åˆå†å²æ”¶ç›Šç‡"""
        
        portfolio_returns = (returns.values @ weights).flatten()
        return pd.Series(portfolio_returns, index=returns.index)
    
    def _calculate_max_drawdown(self, returns: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        
        return abs(drawdown.min())
    
    def _calculate_sharpe_ratio(self, returns: pd.Series) -> float:
        """è®¡ç®—å¤æ™®æ¯”ç‡"""
        
        if len(returns) == 0:
            return 0.0
        
        excess_returns = returns - 0.03/252  # å‡è®¾3%æ— é£é™©åˆ©ç‡
        
        if excess_returns.std() == 0:
            return 0.0
        
        return (excess_returns.mean() / excess_returns.std()) * np.sqrt(252)
    
    def _calculate_calmar_ratio(self, returns: pd.Series, max_drawdown: float) -> float:
        """è®¡ç®—å¡å°”ç›æ¯”ç‡"""
        
        if max_drawdown == 0:
            return 0.0
        
        annual_return = (1 + returns.mean()) ** 252 - 1
        return annual_return / max_drawdown
    
    def _calculate_correlation_risk(self, weights: np.ndarray, returns: pd.DataFrame) -> float:
        """è®¡ç®—ç›¸å…³æ€§é£é™©åˆ†æ•°"""
        
        correlation_matrix = returns.corr().values
        
        # åŠ æƒå¹³å‡ç›¸å…³æ€§
        weighted_correlations = []
        n = len(weights)
        
        for i in range(n):
            for j in range(i+1, n):
                corr = correlation_matrix[i, j]
                weight_product = weights[i] * weights[j]
                weighted_correlations.append(abs(corr) * weight_product)
        
        return sum(weighted_correlations) if weighted_correlations else 0.0
    
    def _calculate_concentration_risk(self, weights: np.ndarray) -> float:
        """è®¡ç®—é›†ä¸­åº¦é£é™©ï¼ˆHHIæŒ‡æ•°ï¼‰"""
        
        # Herfindahl-Hirschman Index
        return sum(w**2 for w in weights)
    
    def _define_stress_scenarios(self) -> List[Dict[str, Any]]:
        """å®šä¹‰å‹åŠ›æµ‹è¯•åœºæ™¯"""
        
        return [
            {
                "name": "å¸‚åœºæš´è·Œ5%",
                "type": "market_shock",
                "market_change": -0.05,
                "volatility_spike": 2.0
            },
            {
                "name": "å¸‚åœºæš´è·Œ10%", 
                "type": "market_shock",
                "market_change": -0.10,
                "volatility_spike": 3.0
            },
            {
                "name": "æ³¢åŠ¨ç‡é£™å‡",
                "type": "volatility_shock",
                "market_change": 0.0,
                "volatility_spike": 5.0
            },
            {
                "name": "æµåŠ¨æ€§æ¯ç«­",
                "type": "liquidity_shock",
                "liquidity_impact": 0.8,
                "spread_widening": 3.0
            },
            {
                "name": "ç›¸å…³æ€§å´©æºƒ",
                "type": "correlation_shock",
                "correlation_increase": 0.9,
                "market_change": -0.03
            }
        ]
    
    def _run_stress_scenario(self, scenario: Dict[str, Any], 
                           weights: np.ndarray, 
                           returns: pd.DataFrame,
                           symbols: List[str]) -> StressTestResult:
        """è¿è¡Œå•ä¸ªå‹åŠ›æµ‹è¯•åœºæ™¯"""
        
        scenario_name = scenario["name"]
        
        if scenario["type"] == "market_shock":
            # å¸‚åœºå†²å‡»
            market_change = scenario["market_change"]
            portfolio_change = market_change * weights.sum()  # ç®€åŒ–å‡è®¾
            worst_position_change = market_change * max(weights)
            correlation_breakdown = False
            liquidity_impact = 0.0
            
        elif scenario["type"] == "volatility_shock":
            # æ³¢åŠ¨ç‡å†²å‡»
            vol_spike = scenario["volatility_spike"]
            current_vol = returns.std().mean()
            new_vol = current_vol * vol_spike
            # ä¼°ç®—ç»„åˆå½±å“
            portfolio_change = -new_vol * 2  # ç®€åŒ–ä¼°ç®—
            worst_position_change = portfolio_change * max(weights) / weights.sum()
            correlation_breakdown = False
            liquidity_impact = 0.0
            
        elif scenario["type"] == "liquidity_shock":
            # æµåŠ¨æ€§å†²å‡»
            liquidity_impact = scenario["liquidity_impact"]
            spread_impact = scenario.get("spread_widening", 1.0)
            portfolio_change = -liquidity_impact * 0.02  # 2%æµåŠ¨æ€§æˆæœ¬
            worst_position_change = portfolio_change * max(weights) / weights.sum()
            correlation_breakdown = False
            
        elif scenario["type"] == "correlation_shock":
            # ç›¸å…³æ€§å†²å‡»
            correlation_increase = scenario["correlation_increase"]
            market_change = scenario.get("market_change", -0.03)
            
            # é«˜ç›¸å…³æ€§æ”¾å¤§æŸå¤±
            correlation_multiplier = 1 + correlation_increase
            portfolio_change = market_change * correlation_multiplier
            worst_position_change = portfolio_change * max(weights) / weights.sum()
            correlation_breakdown = True
            liquidity_impact = 0.0
            
        else:
            # é»˜è®¤åœºæ™¯
            portfolio_change = 0.0
            worst_position_change = 0.0
            correlation_breakdown = False
            liquidity_impact = 0.0
        
        return StressTestResult(
            scenario_name=scenario_name,
            portfolio_change=portfolio_change,
            worst_position_change=worst_position_change,
            correlation_breakdown=correlation_breakdown,
            liquidity_impact=liquidity_impact
        )
    
    def _calculate_correlation_matrix(self, returns: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ"""
        
        return returns.corr()
    
    def _calculate_var_attribution(self, portfolio_weights: Dict[str, float], 
                                  returns_data: pd.DataFrame) -> Dict[str, float]:
        """è®¡ç®—VaRå½’å› """
        
        symbols = list(portfolio_weights.keys())
        weights = np.array([portfolio_weights[symbol] for symbol in symbols])
        returns_subset = returns_data[symbols].dropna()
        
        # ç»„åˆVaR
        portfolio_returns = (returns_subset.values @ weights).flatten()
        portfolio_var = abs(np.percentile(portfolio_returns, 5))
        
        # è¾¹é™…VaRè®¡ç®—
        marginal_vars = {}
        for i, symbol in enumerate(symbols):
            # å¾®å°æ‰°åŠ¨
            perturbed_weights = weights.copy()
            perturbed_weights[i] += 0.001
            perturbed_weights = perturbed_weights / perturbed_weights.sum()  # é‡æ–°å½’ä¸€åŒ–
            
            perturbed_returns = (returns_subset.values @ perturbed_weights).flatten()
            perturbed_var = abs(np.percentile(perturbed_returns, 5))
            
            marginal_var = (perturbed_var - portfolio_var) / 0.001
            marginal_vars[symbol] = marginal_var
        
        return marginal_vars
    
    def _analyze_liquidity_risk(self, portfolio_weights: Dict[str, float], 
                               market_data: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææµåŠ¨æ€§é£é™©"""
        
        # ç®€åŒ–çš„æµåŠ¨æ€§åˆ†æ
        liquidity_scores = {}
        
        for symbol in portfolio_weights.keys():
            # åŸºäºäº¤æ˜“é‡çš„æµåŠ¨æ€§è¯„åˆ†
            if symbol in market_data.columns:
                avg_volume = market_data[symbol].mean() if symbol in market_data.columns else 1000000
                liquidity_score = min(avg_volume / 10000000, 1.0)  # æ ‡å‡†åŒ–åˆ°0-1
            else:
                liquidity_score = 0.5  # é»˜è®¤ä¸­ç­‰æµåŠ¨æ€§
            
            liquidity_scores[symbol] = liquidity_score
        
        # ç»„åˆåŠ æƒæµåŠ¨æ€§åˆ†æ•°
        weighted_liquidity = sum(
            portfolio_weights[symbol] * liquidity_scores[symbol] 
            for symbol in portfolio_weights.keys()
        )
        
        return {
            "individual_scores": liquidity_scores,
            "portfolio_liquidity_score": weighted_liquidity,
            "liquidity_risk_level": "LOW" if weighted_liquidity > 0.7 else "MEDIUM" if weighted_liquidity > 0.4 else "HIGH"
        }
    
    def _backtest_var_model(self, portfolio_weights: Dict[str, float],
                           returns_data: pd.DataFrame) -> Dict[str, Any]:
        """VaRæ¨¡å‹å›æµ‹"""
        
        symbols = list(portfolio_weights.keys())
        weights = np.array([portfolio_weights[symbol] for symbol in symbols])
        returns_subset = returns_data[symbols].dropna()
        
        # æ»šåŠ¨VaRé¢„æµ‹
        window_size = 252  # 1å¹´çª—å£
        var_forecasts = []
        actual_returns = []
        
        for i in range(window_size, len(returns_subset)):
            # å†å²çª—å£
            hist_window = returns_subset.iloc[i-window_size:i]
            portfolio_hist_returns = (hist_window.values @ weights).flatten()
            
            # VaRé¢„æµ‹
            var_forecast = abs(np.percentile(portfolio_hist_returns, 5))
            var_forecasts.append(var_forecast)
            
            # å®é™…æ”¶ç›Š
            actual_return = abs((returns_subset.iloc[i].values @ weights))
            actual_returns.append(actual_return)
        
        if len(var_forecasts) > 0:
            # VaRè¿çº¦ç‡
            violations = sum(1 for i in range(len(var_forecasts)) if actual_returns[i] > var_forecasts[i])
            violation_rate = violations / len(var_forecasts)
            
            # Kupiecæ£€éªŒ (é¢„æœŸè¿çº¦ç‡5%)
            expected_violations = len(var_forecasts) * 0.05
            kupiec_stat = 2 * np.log((violation_rate ** violations) * ((1-violation_rate) ** (len(var_forecasts)-violations)) / 
                                   (0.05 ** expected_violations) * (0.95 ** (len(var_forecasts)-expected_violations)))
            kupiec_pvalue = 1 - stats.chi2.cdf(kupiec_stat, 1)
            
            return {
                "backtest_period_days": len(var_forecasts),
                "total_violations": violations,
                "violation_rate": violation_rate,
                "expected_violation_rate": 0.05,
                "kupiec_test_statistic": kupiec_stat,
                "kupiec_p_value": kupiec_pvalue,
                "model_valid": kupiec_pvalue > 0.05
            }
        else:
            return {
                "backtest_period_days": 0,
                "total_violations": 0,
                "violation_rate": 0.0,
                "model_valid": False
            }
    
    def _generate_risk_recommendations(self, risk_metrics: RiskMetrics, 
                                     risk_monitoring: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé£é™©ç®¡ç†å»ºè®®"""
        
        recommendations = []
        
        if risk_monitoring["risk_level"] == "CRITICAL":
            recommendations.append("ğŸš¨ ç«‹å³å‡ä»“ï¼šé£é™©æŒ‡æ ‡è¶…è¿‡ä¸´ç•Œé˜ˆå€¼ï¼Œå»ºè®®å‡å°‘50%ä»“ä½")
        
        if risk_metrics.portfolio_var_95 > self.warning_var_threshold:
            recommendations.append("âš ï¸ VaRé¢„è­¦ï¼šè€ƒè™‘é™ä½æ æ†æˆ–å¢åŠ å¯¹å†²ä»“ä½")
        
        if risk_metrics.concentration_risk > 0.25:
            recommendations.append("ğŸ“Š åˆ†æ•£åŒ–ï¼šä»“ä½è¿‡åº¦é›†ä¸­ï¼Œå»ºè®®å¢åŠ å¸ç§å¤šæ ·åŒ–")
        
        if risk_metrics.correlation_risk > 0.6:
            recommendations.append("ğŸ”— ç›¸å…³æ€§é£é™©ï¼šæŒä»“å¸ç§ç›¸å…³æ€§è¿‡é«˜ï¼Œè€ƒè™‘è°ƒæ•´ç»„åˆ")
        
        if risk_metrics.max_drawdown > 0.02:
            recommendations.append("ğŸ“‰ å›æ’¤æ§åˆ¶ï¼šå½“å‰å›æ’¤è¾ƒå¤§ï¼Œå»ºè®®åŠ å¼ºæ­¢æŸçºªå¾‹")
        
        if risk_metrics.sharpe_ratio < 1.0:
            recommendations.append("ğŸ“ˆ æ”¶ç›Šä¼˜åŒ–ï¼šé£é™©è°ƒæ•´æ”¶ç›Šè¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–äº¤æ˜“ç­–ç•¥")
        
        if not recommendations:
            recommendations.append("âœ… é£é™©çŠ¶å†µè‰¯å¥½ï¼šå½“å‰é£é™©æ°´å¹³åœ¨å¯æ¥å—èŒƒå›´å†…")
        
        return recommendations
    
    def _empty_risk_metrics(self) -> RiskMetrics:
        """è¿”å›ç©ºçš„é£é™©æŒ‡æ ‡"""
        
        return RiskMetrics(
            portfolio_var_95=0.0,
            portfolio_var_99=0.0,
            portfolio_es_95=0.0,
            portfolio_volatility=0.0,
            beta=0.0,
            max_drawdown=0.0,
            sharpe_ratio=0.0,
            calmar_ratio=0.0,
            correlation_risk=0.0,
            concentration_risk=0.0
        )


def create_risk_manager(config: Dict[str, Any]) -> RealTimeRiskManager:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé£é™©ç®¡ç†å™¨"""
    
    default_config = {
        'max_portfolio_var': 0.02,
        'max_concentration': 0.30,
        'max_correlation_exposure': 0.70,
        'max_drawdown_threshold': 0.03,
        'var_window': 252,
        'correlation_window': 30
    }
    
    # åˆå¹¶é…ç½®
    merged_config = {**default_config, **config}
    
    return RealTimeRiskManager(merged_config)


if __name__ == "__main__":
    # æµ‹è¯•é£é™©ç®¡ç†å™¨
    test_config = {
        'max_portfolio_var': 0.02,
        'max_concentration': 0.30,
        'max_correlation_exposure': 0.70
    }
    
    risk_manager = create_risk_manager(test_config)
    print("DipMaster V4 é£é™©ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    print(f"æœ€å¤§æ—¥VaRé™åˆ¶: {risk_manager.max_portfolio_var:.1%}")
    print(f"æœ€å¤§é›†ä¸­åº¦: {risk_manager.max_concentration:.1%}")
    print(f"ç›¸å…³æ€§é˜ˆå€¼: {risk_manager.max_correlation_exposure:.1%}")