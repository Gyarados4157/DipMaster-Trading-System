#!/usr/bin/env python3
"""
ç»Ÿè®¡éªŒè¯å™¨ - ä¸¥æ ¼çš„ç­–ç•¥ç»Ÿè®¡æ£€éªŒ
Statistical Validator - Rigorous Strategy Statistical Testing

æ ¸å¿ƒåŠŸèƒ½:
1. è’™ç‰¹å¡æ´›éšæœºåŒ–æµ‹è¯•
2. å¤šé‡å‡è®¾æ£€éªŒæ ¡æ­£
3. ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯
4. æ—¶é—´ç¨³å®šæ€§åˆ†æ

Author: DipMaster Trading Team
Date: 2025-08-15
Version: 1.0.0
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    test_name: str
    p_value: float
    is_significant: bool
    effect_size: float
    confidence_interval: Tuple[float, float]
    interpretation: str
    warning_level: str  # 'safe', 'caution', 'danger'

@dataclass
class MonteCarloResult:
    """è’™ç‰¹å¡æ´›æµ‹è¯•ç»“æœ"""
    original_metric: float
    random_mean: float
    random_std: float
    p_value: float
    percentile_rank: float
    is_significant: bool
    interpretation: str

class StatisticalValidator:
    """
    ç»Ÿè®¡éªŒè¯å™¨
    
    æä¾›ä¸¥æ ¼çš„ç»Ÿè®¡æ£€éªŒæ¥éªŒè¯ç­–ç•¥çš„çœŸå®æ€§èƒ½
    """
    
    def __init__(self, significance_level: float = 0.05):
        self.significance_level = significance_level
        self.results_dir = Path("results/validation")
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    def monte_carlo_randomization_test(self, 
                                     trades_df: pd.DataFrame,
                                     metric: str = 'pnl',
                                     n_simulations: int = 10000) -> MonteCarloResult:
        """
        è’™ç‰¹å¡æ´›éšæœºåŒ–æµ‹è¯•
        
        æ ¸å¿ƒåŸç†: å¦‚æœç­–ç•¥æœ‰çœŸå®é¢„æµ‹èƒ½åŠ›ï¼Œå…¶è¡¨ç°åº”è¯¥æ˜¾è‘—ä¼˜äºéšæœºäº¤æ˜“
        
        Args:
            trades_df: äº¤æ˜“è®°å½•DataFrame
            metric: æµ‹è¯•æŒ‡æ ‡ ('pnl', 'win_rate', 'sharpe')
            n_simulations: æ¨¡æ‹Ÿæ¬¡æ•°
            
        Returns:
            MonteCarloResult: æµ‹è¯•ç»“æœ
        """
        logger.info(f"å¼€å§‹è’™ç‰¹å¡æ´›éšæœºåŒ–æµ‹è¯• - æŒ‡æ ‡: {metric}")
        
        # è®¡ç®—åŸå§‹æŒ‡æ ‡
        original_value = self._calculate_metric(trades_df, metric)
        
        # éšæœºåŒ–æ¨¡æ‹Ÿ
        random_values = []
        for i in range(n_simulations):
            if i % 1000 == 0:
                logger.info(f"è’™ç‰¹å¡æ´›è¿›åº¦: {i}/{n_simulations}")
            
            # éšæœºåŒ–äº¤æ˜“ç»“æœ
            randomized_df = self._randomize_trades(trades_df)
            random_value = self._calculate_metric(randomized_df, metric)
            random_values.append(random_value)
        
        random_values = np.array(random_values)
        
        # è®¡ç®—ç»Ÿè®¡é‡
        random_mean = np.mean(random_values)
        random_std = np.std(random_values)
        
        # è®¡ç®—På€¼ (åŒå°¾æ£€éªŒ)
        if original_value >= random_mean:
            p_value = np.mean(random_values >= original_value) * 2
        else:
            p_value = np.mean(random_values <= original_value) * 2
        
        p_value = min(p_value, 1.0)  # ç¡®ä¿På€¼ä¸è¶…è¿‡1
        
        # è®¡ç®—ç™¾åˆ†ä½æ•°
        percentile_rank = stats.percentileofscore(random_values, original_value)
        
        # åˆ¤æ–­æ˜¾è‘—æ€§
        is_significant = p_value < self.significance_level
        
        # ç”Ÿæˆè§£é‡Š
        interpretation = self._interpret_monte_carlo(
            original_value, random_mean, p_value, is_significant, metric
        )
        
        result = MonteCarloResult(
            original_metric=original_value,
            random_mean=random_mean,
            random_std=random_std,
            p_value=p_value,
            percentile_rank=percentile_rank,
            is_significant=is_significant,
            interpretation=interpretation
        )
        
        logger.info(f"è’™ç‰¹å¡æ´›æµ‹è¯•å®Œæˆ: På€¼={p_value:.4f}, æ˜¾è‘—æ€§={is_significant}")
        return result
    
    def multiple_testing_correction(self, p_values: List[float], 
                                  method: str = 'bonferroni') -> List[float]:
        """
        å¤šé‡å‡è®¾æ£€éªŒæ ¡æ­£
        
        Args:
            p_values: På€¼åˆ—è¡¨
            method: æ ¡æ­£æ–¹æ³• ('bonferroni', 'holm', 'fdr_bh')
            
        Returns:
            List[float]: æ ¡æ­£åçš„På€¼
        """
        p_values = np.array(p_values)
        n_tests = len(p_values)
        
        if method == 'bonferroni':
            # Bonferroniæ ¡æ­£
            corrected_p = p_values * n_tests
            corrected_p = np.minimum(corrected_p, 1.0)
        
        elif method == 'holm':
            # Holm-Bonferroniæ ¡æ­£
            sorted_indices = np.argsort(p_values)
            sorted_p = p_values[sorted_indices]
            corrected_p = np.zeros_like(p_values)
            
            for i, idx in enumerate(sorted_indices):
                correction_factor = n_tests - i
                corrected_p[idx] = min(sorted_p[i] * correction_factor, 1.0)
        
        elif method == 'fdr_bh':
            # Benjamini-Hochberg FDRæ ¡æ­£
            sorted_indices = np.argsort(p_values)
            sorted_p = p_values[sorted_indices]
            corrected_p = np.zeros_like(p_values)
            
            for i, idx in enumerate(sorted_indices):
                correction_factor = n_tests / (i + 1)
                corrected_p[idx] = min(sorted_p[i] * correction_factor, 1.0)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¡æ­£æ–¹æ³•: {method}")
        
        logger.info(f"å¤šé‡æ£€éªŒæ ¡æ­£å®Œæˆ: {method}, åŸå§‹På€¼æ•°é‡: {n_tests}")
        return corrected_p.tolist()
    
    def time_stability_test(self, trades_df: pd.DataFrame, 
                          window_size: str = '30D') -> Dict:
        """
        æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
        
        Args:
            trades_df: äº¤æ˜“è®°å½•
            window_size: æ»šåŠ¨çª—å£å¤§å°
            
        Returns:
            Dict: ç¨³å®šæ€§æµ‹è¯•ç»“æœ
        """
        logger.info(f"å¼€å§‹æ—¶é—´ç¨³å®šæ€§æµ‹è¯• - çª—å£: {window_size}")
        
        # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨
        if 'timestamp' not in trades_df.columns:
            raise ValueError("äº¤æ˜“æ•°æ®ç¼ºå°‘timestampåˆ—")
        
        trades_df = trades_df.copy()
        trades_df['timestamp'] = pd.to_datetime(trades_df['timestamp'])
        trades_df = trades_df.sort_values('timestamp')
        
        # æ»šåŠ¨çª—å£åˆ†æ
        window_metrics = []
        
        # è®¾ç½®æ—¶é—´èŒƒå›´
        start_date = trades_df['timestamp'].min()
        end_date = trades_df['timestamp'].max()
        
        # æ»šåŠ¨è®¡ç®—
        current_date = start_date
        while current_date <= end_date:
            window_end = current_date + pd.Timedelta(window_size)
            
            window_trades = trades_df[
                (trades_df['timestamp'] >= current_date) & 
                (trades_df['timestamp'] < window_end)
            ]
            
            if len(window_trades) >= 10:  # æœ€å°‘10ç¬”äº¤æ˜“
                metrics = {
                    'period_start': current_date,
                    'period_end': window_end,
                    'trade_count': len(window_trades),
                    'win_rate': (window_trades['pnl'] > 0).mean(),
                    'total_pnl': window_trades['pnl'].sum(),
                    'avg_pnl': window_trades['pnl'].mean(),
                    'sharpe_ratio': self._calculate_sharpe(window_trades['pnl'])
                }
                window_metrics.append(metrics)
            
            current_date += pd.Timedelta(days=7)  # æ¯å‘¨æ»šåŠ¨
        
        if not window_metrics:
            return {"error": "æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œæ—¶é—´ç¨³å®šæ€§åˆ†æ"}
        
        # è½¬æ¢ä¸ºDataFrame
        metrics_df = pd.DataFrame(window_metrics)
        
        # è®¡ç®—ç¨³å®šæ€§ç»Ÿè®¡é‡
        stability_stats = {
            'win_rate': {
                'mean': metrics_df['win_rate'].mean(),
                'std': metrics_df['win_rate'].std(),
                'cv': metrics_df['win_rate'].std() / metrics_df['win_rate'].mean(),
                'min': metrics_df['win_rate'].min(),
                'max': metrics_df['win_rate'].max()
            },
            'pnl': {
                'mean': metrics_df['total_pnl'].mean(),
                'std': metrics_df['total_pnl'].std(),
                'cv': abs(metrics_df['total_pnl'].std() / metrics_df['total_pnl'].mean()),
                'min': metrics_df['total_pnl'].min(),
                'max': metrics_df['total_pnl'].max()
            },
            'sharpe': {
                'mean': metrics_df['sharpe_ratio'].mean(),
                'std': metrics_df['sharpe_ratio'].std(),
                'cv': abs(metrics_df['sharpe_ratio'].std() / metrics_df['sharpe_ratio'].mean()),
                'min': metrics_df['sharpe_ratio'].min(),
                'max': metrics_df['sharpe_ratio'].max()
            }
        }
        
        # è¶‹åŠ¿æµ‹è¯• (Mann-Kendall)
        trend_test = self._mann_kendall_trend_test(metrics_df['win_rate'])
        
        # è¯„ä¼°ç¨³å®šæ€§
        stability_score = self._calculate_stability_score(stability_stats)
        
        result = {
            'window_count': len(window_metrics),
            'stability_stats': stability_stats,
            'trend_test': trend_test,
            'stability_score': stability_score,
            'interpretation': self._interpret_stability(stability_score),
            'raw_metrics': window_metrics
        }
        
        logger.info(f"æ—¶é—´ç¨³å®šæ€§æµ‹è¯•å®Œæˆ: ç¨³å®šæ€§å¾—åˆ†={stability_score:.2f}")
        return result
    
    def cross_asset_consistency_test(self, 
                                   results_by_symbol: Dict[str, pd.DataFrame]) -> Dict:
        """
        è·¨èµ„äº§ä¸€è‡´æ€§æµ‹è¯•
        
        Args:
            results_by_symbol: å„å¸ç§çš„äº¤æ˜“ç»“æœ
            
        Returns:
            Dict: ä¸€è‡´æ€§æµ‹è¯•ç»“æœ
        """
        logger.info("å¼€å§‹è·¨èµ„äº§ä¸€è‡´æ€§æµ‹è¯•...")
        
        symbol_metrics = {}
        
        # è®¡ç®—å„å¸ç§æŒ‡æ ‡
        for symbol, trades_df in results_by_symbol.items():
            if len(trades_df) == 0:
                continue
                
            metrics = {
                'win_rate': (trades_df['pnl'] > 0).mean(),
                'total_pnl': trades_df['pnl'].sum(),
                'avg_pnl': trades_df['pnl'].mean(),
                'sharpe_ratio': self._calculate_sharpe(trades_df['pnl']),
                'max_drawdown': self._calculate_max_drawdown(trades_df['pnl']),
                'trade_count': len(trades_df)
            }
            symbol_metrics[symbol] = metrics
        
        if len(symbol_metrics) < 2:
            return {"error": "éœ€è¦è‡³å°‘2ä¸ªå¸ç§è¿›è¡Œä¸€è‡´æ€§æµ‹è¯•"}
        
        # è½¬æ¢ä¸ºDataFrame
        metrics_df = pd.DataFrame(symbol_metrics).T
        
        # è®¡ç®—ä¸€è‡´æ€§ç»Ÿè®¡é‡
        consistency_stats = {}
        for metric in ['win_rate', 'sharpe_ratio', 'avg_pnl']:
            values = metrics_df[metric].dropna()
            consistency_stats[metric] = {
                'mean': values.mean(),
                'std': values.std(),
                'cv': abs(values.std() / values.mean()) if values.mean() != 0 else float('inf'),
                'range': values.max() - values.min(),
                'iqr': values.quantile(0.75) - values.quantile(0.25)
            }
        
        # ä¸€è‡´æ€§æ£€éªŒ (Friedmanæ£€éªŒ)
        available_metrics = [col for col in ['win_rate', 'sharpe_ratio', 'avg_pnl'] if col in metrics_df.columns]
        
        if len(available_metrics) >= 3:
            friedman_stat, friedman_p = stats.friedmanchisquare(
                *[metrics_df[col].values for col in available_metrics]
            )
        else:
            # å¦‚æœæŒ‡æ ‡ä¸è¶³3ä¸ªï¼Œä½¿ç”¨ç®€åŒ–çš„æ–¹å·®åˆ†æ
            friedman_stat = 0.0
            friedman_p = 1.0
        
        # è®¡ç®—ä¸€è‡´æ€§å¾—åˆ†
        consistency_score = self._calculate_consistency_score(consistency_stats)
        
        result = {
            'symbol_count': len(symbol_metrics),
            'symbol_metrics': symbol_metrics,
            'consistency_stats': consistency_stats,
            'friedman_test': {
                'statistic': friedman_stat,
                'p_value': friedman_p,
                'is_significant': friedman_p < self.significance_level
            },
            'consistency_score': consistency_score,
            'interpretation': self._interpret_consistency(consistency_score)
        }
        
        logger.info(f"è·¨èµ„äº§ä¸€è‡´æ€§æµ‹è¯•å®Œæˆ: ä¸€è‡´æ€§å¾—åˆ†={consistency_score:.2f}")
        return result
    
    def comprehensive_validation(self, 
                               trades_df: pd.DataFrame,
                               results_by_symbol: Dict[str, pd.DataFrame] = None) -> Dict:
        """
        ç»¼åˆéªŒè¯æµ‹è¯•
        
        Args:
            trades_df: æ€»ä½“äº¤æ˜“è®°å½•
            results_by_symbol: å„å¸ç§äº¤æ˜“è®°å½•
            
        Returns:
            Dict: ç»¼åˆéªŒè¯ç»“æœ
        """
        logger.info("å¼€å§‹ç»¼åˆç­–ç•¥éªŒè¯...")
        
        validation_results = {}
        
        # 1. è’™ç‰¹å¡æ´›æµ‹è¯•
        mc_pnl = self.monte_carlo_randomization_test(trades_df, 'pnl')
        mc_winrate = self.monte_carlo_randomization_test(trades_df, 'win_rate')
        
        validation_results['monte_carlo'] = {
            'pnl_test': mc_pnl,
            'win_rate_test': mc_winrate
        }
        
        # 2. æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
        stability_result = self.time_stability_test(trades_df)
        validation_results['time_stability'] = stability_result
        
        # 3. è·¨èµ„äº§ä¸€è‡´æ€§æµ‹è¯•
        if results_by_symbol:
            consistency_result = self.cross_asset_consistency_test(results_by_symbol)
            validation_results['cross_asset_consistency'] = consistency_result
        
        # 4. å¤šé‡æ£€éªŒæ ¡æ­£
        all_p_values = [
            mc_pnl.p_value,
            mc_winrate.p_value
        ]
        
        corrected_p_values = self.multiple_testing_correction(all_p_values)
        validation_results['corrected_p_values'] = {
            'original': all_p_values,
            'bonferroni_corrected': corrected_p_values
        }
        
        # 5. ç»¼åˆè¯„ä¼°
        overall_assessment = self._generate_overall_assessment(validation_results)
        validation_results['overall_assessment'] = overall_assessment
        
        # ä¿å­˜ç»“æœ
        self._save_validation_results(validation_results)
        
        logger.info("ç»¼åˆç­–ç•¥éªŒè¯å®Œæˆ")
        return validation_results
    
    def _calculate_metric(self, trades_df: pd.DataFrame, metric: str) -> float:
        """è®¡ç®—æŒ‡æ ‡å€¼"""
        if metric == 'pnl':
            return trades_df['pnl'].sum()
        elif metric == 'win_rate':
            return (trades_df['pnl'] > 0).mean()
        elif metric == 'sharpe':
            return self._calculate_sharpe(trades_df['pnl'])
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŒ‡æ ‡: {metric}")
    
    def _randomize_trades(self, trades_df: pd.DataFrame) -> pd.DataFrame:
        """
        éšæœºåŒ–äº¤æ˜“ç»“æœ - ç”ŸæˆçœŸæ­£çš„éšæœºäº¤æ˜“
        
        æ¨¡æ‹Ÿéšæœºäº¤æ˜“çš„çœŸå®åˆ†å¸ƒï¼Œè€Œä¸æ˜¯ç®€å•é‡æ’ç°æœ‰ç»“æœ
        """
        randomized_df = trades_df.copy()
        
        # åŸºäºå†å²æ”¶ç›Šç‡åˆ†å¸ƒç”ŸæˆçœŸæ­£çš„éšæœºäº¤æ˜“
        n_trades = len(trades_df)
        
        # ä¼°ç®—åˆç†çš„éšæœºäº¤æ˜“å‚æ•° (åŸºäºå¸‚åœºç»Ÿè®¡)
        # åŠ å¯†è´§å¸5åˆ†é’ŸKçº¿æ”¶ç›Šç‡å¤§çº¦ï¼šå‡å€¼=0, æ ‡å‡†å·®=0.01-0.02
        typical_return_std = 0.015  # 1.5%æ ‡å‡†å·®
        
        # ç”Ÿæˆç¬¦åˆå¸‚åœºç‰¹å¾çš„éšæœºæ”¶ç›Šç‡
        random_returns = np.random.normal(0, typical_return_std, n_trades)
        
        # è½¬æ¢ä¸ºPnL (å‡è®¾å›ºå®šä»“ä½å¤§å°1000)
        position_size = 1000
        randomized_df['pnl'] = random_returns * position_size
        
        return randomized_df
    
    def _calculate_sharpe(self, returns: pd.Series) -> float:
        """è®¡ç®—å¤æ™®æ¯”ç‡"""
        if len(returns) == 0 or returns.std() == 0:
            return 0.0
        return returns.mean() / returns.std() * np.sqrt(252 * 24 * 12)  # 5åˆ†é’Ÿæ•°æ®å¹´åŒ–
    
    def _calculate_max_drawdown(self, pnl_series: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        cumulative = pnl_series.cumsum()
        running_max = cumulative.expanding().max()
        drawdown = cumulative - running_max
        return drawdown.min()
    
    def _mann_kendall_trend_test(self, data: pd.Series) -> Dict:
        """Mann-Kendallè¶‹åŠ¿æ£€éªŒ"""
        n = len(data)
        if n < 3:
            return {"error": "æ•°æ®é‡ä¸è¶³"}
        
        # è®¡ç®—Sç»Ÿè®¡é‡
        s = 0
        for i in range(n-1):
            for j in range(i+1, n):
                s += np.sign(data.iloc[j] - data.iloc[i])
        
        # è®¡ç®—æ–¹å·®
        var_s = n * (n-1) * (2*n+5) / 18
        
        # è®¡ç®—Zç»Ÿè®¡é‡
        if s > 0:
            z = (s - 1) / np.sqrt(var_s)
        elif s < 0:
            z = (s + 1) / np.sqrt(var_s)
        else:
            z = 0
        
        # è®¡ç®—På€¼
        p_value = 2 * (1 - stats.norm.cdf(abs(z)))
        
        return {
            'statistic': s,
            'z_score': z,
            'p_value': p_value,
            'has_trend': p_value < self.significance_level,
            'trend_direction': 'increasing' if s > 0 else 'decreasing' if s < 0 else 'no_trend'
        }
    
    def _calculate_stability_score(self, stability_stats: Dict) -> float:
        """è®¡ç®—ç¨³å®šæ€§å¾—åˆ† (0-100)"""
        # åŸºäºå˜å¼‚ç³»æ•°è®¡ç®—ç¨³å®šæ€§
        cv_winrate = stability_stats['win_rate']['cv']
        cv_pnl = stability_stats['pnl']['cv']
        cv_sharpe = stability_stats['sharpe']['cv']
        
        # å˜å¼‚ç³»æ•°è¶Šå°ï¼Œç¨³å®šæ€§è¶Šé«˜
        stability_score = 100 / (1 + cv_winrate + cv_pnl + cv_sharpe)
        return min(max(stability_score, 0), 100)
    
    def _calculate_consistency_score(self, consistency_stats: Dict) -> float:
        """è®¡ç®—ä¸€è‡´æ€§å¾—åˆ† (0-100)"""
        avg_cv = np.mean([stats['cv'] for stats in consistency_stats.values() 
                         if not np.isinf(stats['cv'])])
        consistency_score = 100 / (1 + avg_cv)
        return min(max(consistency_score, 0), 100)
    
    def _interpret_monte_carlo(self, original: float, random_mean: float, 
                              p_value: float, is_significant: bool, metric: str) -> str:
        """è§£é‡Šè’™ç‰¹å¡æ´›ç»“æœ"""
        if p_value < 0.001:
            significance_text = "æå…¶æ˜¾è‘—"
        elif p_value < 0.01:
            significance_text = "é«˜åº¦æ˜¾è‘—"
        elif p_value < 0.05:
            significance_text = "æ˜¾è‘—"
        else:
            significance_text = "ä¸æ˜¾è‘—"
        
        if is_significant:
            if original > random_mean:
                return f"ç­–ç•¥åœ¨{metric}ä¸Šè¡¨ç°{significance_text}ä¼˜äºéšæœºäº¤æ˜“ (P={p_value:.4f})"
            else:
                return f"ç­–ç•¥åœ¨{metric}ä¸Šè¡¨ç°{significance_text}åŠ£äºéšæœºäº¤æ˜“ (P={p_value:.4f})"
        else:
            return f"ç­–ç•¥åœ¨{metric}ä¸Šçš„è¡¨ç°ä¸éšæœºäº¤æ˜“æ— æ˜¾è‘—å·®å¼‚ (P={p_value:.4f}) - ç–‘ä¼¼è¿‡æ‹Ÿåˆ"
    
    def _interpret_stability(self, score: float) -> str:
        """è§£é‡Šç¨³å®šæ€§å¾—åˆ†"""
        if score >= 80:
            return "ç­–ç•¥è¡¨ç°æå…¶ç¨³å®š"
        elif score >= 60:
            return "ç­–ç•¥è¡¨ç°è¾ƒä¸ºç¨³å®š"
        elif score >= 40:
            return "ç­–ç•¥è¡¨ç°ä¸­ç­‰ç¨³å®š"
        elif score >= 20:
            return "ç­–ç•¥è¡¨ç°ä¸å¤ªç¨³å®š"
        else:
            return "ç­–ç•¥è¡¨ç°æä¸ç¨³å®š - é«˜è¿‡æ‹Ÿåˆé£é™©"
    
    def _interpret_consistency(self, score: float) -> str:
        """è§£é‡Šä¸€è‡´æ€§å¾—åˆ†"""
        if score >= 80:
            return "è·¨èµ„äº§è¡¨ç°é«˜åº¦ä¸€è‡´"
        elif score >= 60:
            return "è·¨èµ„äº§è¡¨ç°è¾ƒä¸ºä¸€è‡´"
        elif score >= 40:
            return "è·¨èµ„äº§è¡¨ç°ä¸­ç­‰ä¸€è‡´"
        elif score >= 20:
            return "è·¨èµ„äº§è¡¨ç°ä¸å¤ªä¸€è‡´"
        else:
            return "è·¨èµ„äº§è¡¨ç°æä¸ä¸€è‡´ - é€‰æ‹©åå·®é£é™©"
    
    def _generate_overall_assessment(self, results: Dict) -> Dict:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°"""
        warnings = []
        risk_level = "LOW"
        
        # æ£€æŸ¥è’™ç‰¹å¡æ´›ç»“æœ
        mc_results = results['monte_carlo']
        if not mc_results['pnl_test'].is_significant:
            warnings.append("PnLè¡¨ç°ä¸éšæœºäº¤æ˜“æ— æ˜¾è‘—å·®å¼‚")
            risk_level = "HIGH"
        
        if not mc_results['win_rate_test'].is_significant:
            warnings.append("èƒœç‡ä¸éšæœºäº¤æ˜“æ— æ˜¾è‘—å·®å¼‚")
            risk_level = "HIGH"
        
        # æ£€æŸ¥ç¨³å®šæ€§
        if 'time_stability' in results:
            stability_score = results['time_stability'].get('stability_score', 0)
            if stability_score < 40:
                warnings.append("æ—¶é—´ç¨³å®šæ€§å·®")
                risk_level = "MEDIUM" if risk_level == "LOW" else "HIGH"
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        if 'cross_asset_consistency' in results:
            consistency_score = results['cross_asset_consistency'].get('consistency_score', 0)
            if consistency_score < 40:
                warnings.append("è·¨èµ„äº§ä¸€è‡´æ€§å·®")
                risk_level = "MEDIUM" if risk_level == "LOW" else "HIGH"
        
        # ç”Ÿæˆå»ºè®®
        if risk_level == "HIGH":
            recommendation = "ğŸš¨ ä¸¥é‡è¿‡æ‹Ÿåˆé£é™© - ç¦æ­¢å®ç›˜äº¤æ˜“"
        elif risk_level == "MEDIUM":
            recommendation = "âš ï¸  ä¸­ç­‰è¿‡æ‹Ÿåˆé£é™© - éœ€è¦è¿›ä¸€æ­¥éªŒè¯"
        else:
            recommendation = "âœ… ä½è¿‡æ‹Ÿåˆé£é™© - å¯è€ƒè™‘è°¨æ…å®ç›˜"
        
        return {
            'risk_level': risk_level,
            'warnings': warnings,
            'recommendation': recommendation,
            'overall_pass': risk_level == "LOW"
        }
    
    def _save_validation_results(self, results: Dict) -> None:
        """ä¿å­˜éªŒè¯ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"statistical_validation_{timestamp}.json"
        filepath = self.results_dir / filename
        
        # è½¬æ¢ç‰¹æ®Šå¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        serializable_results = self._make_serializable(results)
        
        with open(filepath, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        
        logger.info(f"éªŒè¯ç»“æœå·²ä¿å­˜: {filepath}")
    
    def _make_serializable(self, obj):
        """è½¬æ¢å¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(v) for v in obj]
        elif isinstance(obj, (MonteCarloResult, ValidationResult)):
            return obj.__dict__
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        else:
            return obj