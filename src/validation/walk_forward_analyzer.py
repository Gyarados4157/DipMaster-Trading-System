#!/usr/bin/env python3
"""
Walk-Forwardåˆ†æå™¨ - æ—¶é—´ç¨³å®šæ€§éªŒè¯
Walk-Forward Analyzer - Time Stability Validation

æ ¸å¿ƒåŠŸèƒ½:
1. æ»šåŠ¨çª—å£éªŒè¯
2. å‚æ•°ç¨³å®šæ€§æµ‹è¯•
3. æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
4. å‰å‘æ€§èƒ½è¡°å‡åˆ†æ

Author: DipMaster Trading Team
Date: 2025-08-15
Version: 1.0.0
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Callable
import logging
from dataclasses import dataclass
import json
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

logger = logging.getLogger(__name__)

@dataclass
class WalkForwardConfig:
    """Walk-Forwardé…ç½®"""
    train_window_months: int = 6      # è®­ç»ƒçª—å£é•¿åº¦
    test_window_months: int = 1       # æµ‹è¯•çª—å£é•¿åº¦
    step_size_months: int = 1         # æ­¥è¿›å¤§å°
    min_trades_per_window: int = 50   # æ¯çª—å£æœ€å°‘äº¤æ˜“æ•°
    refit_parameters: bool = True     # æ˜¯å¦é‡æ–°æ‹Ÿåˆå‚æ•°

@dataclass
class WindowResult:
    """å•ä¸ªçª—å£ç»“æœ"""
    window_id: int
    train_start: datetime
    train_end: datetime
    test_start: datetime
    test_end: datetime
    train_trades: int
    test_trades: int
    test_metrics: Dict
    optimal_parameters: Dict
    parameter_stability: float

class WalkForwardAnalyzer:
    """
    Walk-Forwardåˆ†æå™¨
    
    å®ç°ä¸¥æ ¼çš„æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼ŒéªŒè¯ç­–ç•¥çš„æ—¶é—´ç¨³å®šæ€§
    """
    
    def __init__(self, config: WalkForwardConfig = None):
        self.config = config or WalkForwardConfig()
        self.results_dir = Path("results/walk_forward")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
    def run_walk_forward_analysis(self, 
                                 data: pd.DataFrame,
                                 strategy_func: Callable,
                                 parameter_ranges: Dict,
                                 symbols: List[str] = None) -> Dict:
        """
        è¿è¡ŒWalk-Forwardåˆ†æ
        
        Args:
            data: å¸‚åœºæ•°æ®
            strategy_func: ç­–ç•¥å‡½æ•°
            parameter_ranges: å‚æ•°æœç´¢èŒƒå›´
            symbols: å¸ç§åˆ—è¡¨
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        logger.info("å¼€å§‹Walk-Forwardåˆ†æ...")
        
        # å‡†å¤‡æ•°æ®
        data = data.copy()
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        data = data.sort_values('timestamp')
        
        # ç”Ÿæˆæ—¶é—´çª—å£
        windows = self._generate_time_windows(data)
        logger.info(f"ç”Ÿæˆäº† {len(windows)} ä¸ªæ—¶é—´çª—å£")
        
        # é€çª—å£åˆ†æ
        window_results = []
        baseline_parameters = None
        
        for i, (train_start, train_end, test_start, test_end) in enumerate(windows):
            logger.info(f"å¤„ç†çª—å£ {i+1}/{len(windows)}: {test_start.date()} - {test_end.date()}")
            
            # åˆ†å‰²æ•°æ®
            train_data = data[(data['timestamp'] >= train_start) & 
                            (data['timestamp'] <= train_end)]
            test_data = data[(data['timestamp'] >= test_start) & 
                           (data['timestamp'] <= test_end)]
            
            # æ£€æŸ¥æ•°æ®å……è¶³æ€§
            if len(train_data) < 1000 or len(test_data) < 100:
                logger.warning(f"çª—å£ {i+1} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                continue
            
            try:
                # å‚æ•°ä¼˜åŒ–
                if self.config.refit_parameters:
                    optimal_params = self._optimize_parameters(
                        train_data, strategy_func, parameter_ranges
                    )
                else:
                    optimal_params = baseline_parameters or self._get_default_parameters()
                
                if baseline_parameters is None:
                    baseline_parameters = optimal_params
                
                # æ ·æœ¬å¤–æµ‹è¯•
                test_results = self._run_strategy_test(test_data, strategy_func, optimal_params)
                
                # è®¡ç®—å‚æ•°ç¨³å®šæ€§
                param_stability = self._calculate_parameter_stability(
                    optimal_params, baseline_parameters
                )
                
                # åˆ›å»ºçª—å£ç»“æœ
                window_result = WindowResult(
                    window_id=i+1,
                    train_start=train_start,
                    train_end=train_end,
                    test_start=test_start,
                    test_end=test_end,
                    train_trades=len(train_data),
                    test_trades=len(test_data),
                    test_metrics=test_results,
                    optimal_parameters=optimal_params,
                    parameter_stability=param_stability
                )
                
                window_results.append(window_result)
                
            except Exception as e:
                logger.error(f"çª—å£ {i+1} å¤„ç†å¤±è´¥: {e}")
                continue
        
        if not window_results:
            raise ValueError("æ²¡æœ‰æˆåŠŸçš„çª—å£ç»“æœ")
        
        # åˆ†æç»“æœ
        analysis_results = self._analyze_walk_forward_results(window_results)
        
        # ä¿å­˜ç»“æœ
        self._save_walk_forward_results(window_results, analysis_results)
        
        logger.info("Walk-Forwardåˆ†æå®Œæˆ")
        return analysis_results
    
    def _generate_time_windows(self, data: pd.DataFrame) -> List[Tuple]:
        """ç”Ÿæˆæ—¶é—´çª—å£"""
        windows = []
        
        start_date = data['timestamp'].min()
        end_date = data['timestamp'].max()
        
        current_date = start_date
        
        while current_date < end_date:
            # è®­ç»ƒçª—å£
            train_start = current_date
            train_end = train_start + pd.DateOffset(months=self.config.train_window_months)
            
            # æµ‹è¯•çª—å£
            test_start = train_end + pd.Timedelta(days=1)
            test_end = test_start + pd.DateOffset(months=self.config.test_window_months)
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºæ•°æ®èŒƒå›´
            if test_end > end_date:
                break
            
            windows.append((train_start, train_end, test_start, test_end))
            
            # æ­¥è¿›
            current_date += pd.DateOffset(months=self.config.step_size_months)
        
        return windows
    
    def _optimize_parameters(self, 
                           train_data: pd.DataFrame, 
                           strategy_func: Callable,
                           parameter_ranges: Dict) -> Dict:
        """
        å‚æ•°ä¼˜åŒ–
        
        ä½¿ç”¨ç½‘æ ¼æœç´¢åœ¨è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–å‚æ•°
        """
        best_params = {}
        best_score = -np.inf
        
        # ç”Ÿæˆå‚æ•°ç»„åˆ
        param_combinations = self._generate_parameter_combinations(parameter_ranges)
        
        logger.info(f"æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        for i, params in enumerate(param_combinations):
            if i % 10 == 0:
                logger.info(f"å‚æ•°ä¼˜åŒ–è¿›åº¦: {i}/{len(param_combinations)}")
            
            try:
                # è¿è¡Œç­–ç•¥
                results = self._run_strategy_test(train_data, strategy_func, params)
                
                # è®¡ç®—ä¼˜åŒ–ç›®æ ‡ (è¿™é‡Œä½¿ç”¨é£é™©è°ƒæ•´æ”¶ç›Š)
                if results['trade_count'] < self.config.min_trades_per_window:
                    continue
                
                score = self._calculate_optimization_score(results)
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    
            except Exception as e:
                logger.debug(f"å‚æ•°ç»„åˆå¤±è´¥: {params}, é”™è¯¯: {e}")
                continue
        
        if not best_params:
            logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            return self._get_default_parameters()
        
        logger.info(f"æœ€ä¼˜å‚æ•°: {best_params}, å¾—åˆ†: {best_score:.4f}")
        return best_params
    
    def _generate_parameter_combinations(self, parameter_ranges: Dict) -> List[Dict]:
        """ç”Ÿæˆå‚æ•°ç»„åˆ"""
        import itertools
        
        keys = list(parameter_ranges.keys())
        values = list(parameter_ranges.values())
        
        combinations = []
        for combination in itertools.product(*values):
            param_dict = dict(zip(keys, combination))
            combinations.append(param_dict)
        
        return combinations
    
    def _run_strategy_test(self, 
                          data: pd.DataFrame, 
                          strategy_func: Callable, 
                          parameters: Dict) -> Dict:
        """
        è¿è¡Œç­–ç•¥æµ‹è¯•
        
        è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç­–ç•¥å‡½æ•°å®ç°
        """
        # è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå®ç°ï¼Œå®é™…éœ€è¦è°ƒç”¨çœŸå®çš„ç­–ç•¥å‡½æ•°
        
        # æ¨¡æ‹Ÿäº¤æ˜“ç»“æœ
        np.random.seed(42)  # ä¸ºäº†å¯é‡å¤æ€§
        
        trade_count = len(data) // 100  # å‡è®¾æ¯100ä¸ªæ•°æ®ç‚¹ä¸€ç¬”äº¤æ˜“
        trade_count = max(trade_count, 1)
        
        # ç”Ÿæˆæ¨¡æ‹ŸPnL
        win_rate = parameters.get('expected_win_rate', 0.55)
        avg_win = parameters.get('avg_win', 10)
        avg_loss = parameters.get('avg_loss', -8)
        
        pnl_list = []
        for _ in range(trade_count):
            if np.random.random() < win_rate:
                pnl = np.random.normal(avg_win, avg_win * 0.3)
            else:
                pnl = np.random.normal(avg_loss, abs(avg_loss) * 0.3)
            pnl_list.append(pnl)
        
        pnl_series = pd.Series(pnl_list)
        
        # è®¡ç®—æŒ‡æ ‡
        total_pnl = pnl_series.sum()
        actual_win_rate = (pnl_series > 0).mean()
        sharpe_ratio = pnl_series.mean() / pnl_series.std() if pnl_series.std() > 0 else 0
        max_drawdown = self._calculate_max_drawdown(pnl_series)
        
        return {
            'total_pnl': total_pnl,
            'win_rate': actual_win_rate,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'trade_count': trade_count,
            'avg_pnl_per_trade': total_pnl / trade_count if trade_count > 0 else 0
        }
    
    def _calculate_optimization_score(self, results: Dict) -> float:
        """è®¡ç®—ä¼˜åŒ–ç›®æ ‡å¾—åˆ†"""
        # é£é™©è°ƒæ•´æ”¶ç›Š
        pnl = results.get('total_pnl', 0)
        max_dd = abs(results.get('max_drawdown', 1))
        win_rate = results.get('win_rate', 0)
        trade_count = results.get('trade_count', 0)
        
        # é¿å…é™¤é›¶
        if max_dd == 0:
            max_dd = 0.01
        
        # ç»¼åˆå¾—åˆ†
        score = (pnl / max_dd) * win_rate * np.log(1 + trade_count)
        return score
    
    def _calculate_max_drawdown(self, pnl_series: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        cumulative = pnl_series.cumsum()
        running_max = cumulative.expanding().max()
        drawdown = cumulative - running_max
        return drawdown.min()
    
    def _calculate_parameter_stability(self, 
                                     current_params: Dict, 
                                     baseline_params: Dict) -> float:
        """è®¡ç®—å‚æ•°ç¨³å®šæ€§"""
        if not baseline_params:
            return 1.0
        
        stability_scores = []
        
        for key in current_params:
            if key in baseline_params:
                current_val = current_params[key]
                baseline_val = baseline_params[key]
                
                if isinstance(current_val, (int, float)) and isinstance(baseline_val, (int, float)):
                    if baseline_val != 0:
                        relative_change = abs(current_val - baseline_val) / abs(baseline_val)
                        stability = 1 / (1 + relative_change)
                        stability_scores.append(stability)
                    else:
                        stability_scores.append(1.0 if current_val == baseline_val else 0.0)
                else:
                    stability_scores.append(1.0 if current_val == baseline_val else 0.0)
        
        return np.mean(stability_scores) if stability_scores else 1.0
    
    def _get_default_parameters(self) -> Dict:
        """è·å–é»˜è®¤å‚æ•°"""
        return {
            'rsi_lower': 30,
            'rsi_upper': 70,
            'ma_period': 20,
            'volume_threshold': 1.5,
            'expected_win_rate': 0.55,
            'avg_win': 10,
            'avg_loss': -8
        }
    
    def _analyze_walk_forward_results(self, window_results: List[WindowResult]) -> Dict:
        """åˆ†æWalk-Forwardç»“æœ"""
        logger.info("åˆ†æWalk-Forwardç»“æœ...")
        
        # æå–æŒ‡æ ‡
        metrics_data = []
        for result in window_results:
            metrics = result.test_metrics.copy()
            metrics['window_id'] = result.window_id
            metrics['test_start'] = result.test_start
            metrics['parameter_stability'] = result.parameter_stability
            metrics_data.append(metrics)
        
        metrics_df = pd.DataFrame(metrics_data)
        
        # æ—¶é—´åºåˆ—åˆ†æ
        time_analysis = self._analyze_time_series_performance(metrics_df)
        
        # å‚æ•°ç¨³å®šæ€§åˆ†æ
        parameter_analysis = self._analyze_parameter_stability(window_results)
        
        # æ€§èƒ½è¡°å‡åˆ†æ
        performance_decay = self._analyze_performance_decay(metrics_df)
        
        # ç¨³å®šæ€§è¯„ä¼°
        stability_assessment = self._assess_overall_stability(metrics_df)
        
        # ç»¼åˆè¯„ä¼°
        overall_assessment = {
            'total_windows': len(window_results),
            'avg_win_rate': metrics_df['win_rate'].mean(),
            'win_rate_std': metrics_df['win_rate'].std(),
            'avg_sharpe': metrics_df['sharpe_ratio'].mean(),
            'sharpe_std': metrics_df['sharpe_ratio'].std(),
            'parameter_stability_avg': metrics_df['parameter_stability'].mean(),
            'performance_consistency': self._calculate_performance_consistency(metrics_df),
            'time_stability_score': time_analysis.get('stability_score', 0),
            'overall_pass': stability_assessment['overall_pass']
        }
        
        return {
            'window_results': [self._window_result_to_dict(wr) for wr in window_results],
            'time_analysis': time_analysis,
            'parameter_analysis': parameter_analysis,
            'performance_decay': performance_decay,
            'stability_assessment': stability_assessment,
            'overall_assessment': overall_assessment,
            'recommendations': self._generate_recommendations(overall_assessment)
        }
    
    def _analyze_time_series_performance(self, metrics_df: pd.DataFrame) -> Dict:
        """æ—¶é—´åºåˆ—æ€§èƒ½åˆ†æ"""
        
        # è¶‹åŠ¿åˆ†æ
        from scipy import stats
        
        window_numbers = metrics_df['window_id'].values
        win_rates = metrics_df['win_rate'].values
        sharpe_ratios = metrics_df['sharpe_ratio'].values
        
        # çº¿æ€§å›å½’æ£€æµ‹è¶‹åŠ¿
        win_rate_slope, win_rate_intercept, win_rate_r, win_rate_p, _ = stats.linregress(window_numbers, win_rates)
        sharpe_slope, sharpe_intercept, sharpe_r, sharpe_p, _ = stats.linregress(window_numbers, sharpe_ratios)
        
        # ç¨³å®šæ€§å¾—åˆ†
        win_rate_cv = metrics_df['win_rate'].std() / metrics_df['win_rate'].mean()
        sharpe_cv = abs(metrics_df['sharpe_ratio'].std() / metrics_df['sharpe_ratio'].mean())
        
        stability_score = 100 / (1 + win_rate_cv + sharpe_cv)
        
        return {
            'win_rate_trend': {
                'slope': win_rate_slope,
                'p_value': win_rate_p,
                'has_significant_trend': win_rate_p < 0.05,
                'direction': 'declining' if win_rate_slope < 0 else 'improving'
            },
            'sharpe_trend': {
                'slope': sharpe_slope,
                'p_value': sharpe_p,
                'has_significant_trend': sharpe_p < 0.05,
                'direction': 'declining' if sharpe_slope < 0 else 'improving'
            },
            'stability_score': stability_score,
            'win_rate_cv': win_rate_cv,
            'sharpe_cv': sharpe_cv
        }
    
    def _analyze_parameter_stability(self, window_results: List[WindowResult]) -> Dict:
        """å‚æ•°ç¨³å®šæ€§åˆ†æ"""
        
        if len(window_results) < 2:
            return {"error": "éœ€è¦è‡³å°‘2ä¸ªçª—å£è¿›è¡Œå‚æ•°ç¨³å®šæ€§åˆ†æ"}
        
        # æ”¶é›†æ‰€æœ‰å‚æ•°
        all_parameters = {}
        for result in window_results:
            for param_name, param_value in result.optimal_parameters.items():
                if param_name not in all_parameters:
                    all_parameters[param_name] = []
                all_parameters[param_name].append(param_value)
        
        # åˆ†ææ¯ä¸ªå‚æ•°çš„ç¨³å®šæ€§
        parameter_stability = {}
        for param_name, values in all_parameters.items():
            if all(isinstance(v, (int, float)) for v in values):
                param_stability = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'cv': np.std(values) / np.mean(values) if np.mean(values) != 0 else float('inf'),
                    'range': max(values) - min(values),
                    'stability_score': 100 / (1 + np.std(values) / (abs(np.mean(values)) + 0.001))
                }
            else:
                # åˆ†ç±»å‚æ•°
                unique_values = len(set(values))
                param_stability = {
                    'unique_count': unique_values,
                    'most_common': max(set(values), key=values.count),
                    'stability_score': 100 * (values.count(max(set(values), key=values.count)) / len(values))
                }
            
            parameter_stability[param_name] = param_stability
        
        # æ•´ä½“å‚æ•°ç¨³å®šæ€§
        overall_stability = np.mean([
            result.parameter_stability for result in window_results
        ])
        
        return {
            'parameter_details': parameter_stability,
            'overall_parameter_stability': overall_stability,
            'parameter_drift_detected': overall_stability < 0.8
        }
    
    def _analyze_performance_decay(self, metrics_df: pd.DataFrame) -> Dict:
        """æ€§èƒ½è¡°å‡åˆ†æ"""
        
        # è®¡ç®—æ»šåŠ¨æ€§èƒ½
        window_size = min(5, len(metrics_df) // 2)
        if window_size < 2:
            return {"error": "æ•°æ®ä¸è¶³è¿›è¡Œæ€§èƒ½è¡°å‡åˆ†æ"}
        
        rolling_win_rate = metrics_df['win_rate'].rolling(window_size).mean()
        rolling_sharpe = metrics_df['sharpe_ratio'].rolling(window_size).mean()
        
        # æ£€æµ‹è¡°å‡
        recent_performance = rolling_win_rate.iloc[-3:].mean()
        early_performance = rolling_win_rate.iloc[:3].mean()
        
        win_rate_decay = (early_performance - recent_performance) / early_performance if early_performance != 0 else 0
        
        recent_sharpe = rolling_sharpe.iloc[-3:].mean()
        early_sharpe = rolling_sharpe.iloc[:3].mean()
        
        sharpe_decay = (early_sharpe - recent_sharpe) / abs(early_sharpe) if early_sharpe != 0 else 0
        
        return {
            'win_rate_decay_pct': win_rate_decay * 100,
            'sharpe_decay_pct': sharpe_decay * 100,
            'significant_decay_detected': win_rate_decay > 0.1 or sharpe_decay > 0.1,
            'early_vs_recent': {
                'early_win_rate': early_performance,
                'recent_win_rate': recent_performance,
                'early_sharpe': early_sharpe,
                'recent_sharpe': recent_sharpe
            }
        }
    
    def _assess_overall_stability(self, metrics_df: pd.DataFrame) -> Dict:
        """æ•´ä½“ç¨³å®šæ€§è¯„ä¼°"""
        
        # ç¨³å®šæ€§æŒ‡æ ‡
        win_rate_cv = metrics_df['win_rate'].std() / metrics_df['win_rate'].mean()
        sharpe_cv = abs(metrics_df['sharpe_ratio'].std() / metrics_df['sharpe_ratio'].mean())
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        positive_windows = (metrics_df['total_pnl'] > 0).sum()
        consistency_ratio = positive_windows / len(metrics_df)
        
        # ç»¼åˆè¯„ä¼°
        stability_factors = {
            'win_rate_stability': 1 / (1 + win_rate_cv),
            'sharpe_stability': 1 / (1 + sharpe_cv),
            'consistency_ratio': consistency_ratio,
            'parameter_stability': metrics_df['parameter_stability'].mean()
        }
        
        overall_stability = np.mean(list(stability_factors.values()))
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        overall_pass = (
            overall_stability > 0.7 and
            consistency_ratio > 0.6 and
            win_rate_cv < 0.3 and
            sharpe_cv < 0.5
        )
        
        return {
            'stability_factors': stability_factors,
            'overall_stability_score': overall_stability,
            'overall_pass': overall_pass,
            'warnings': self._generate_stability_warnings(stability_factors)
        }
    
    def _calculate_performance_consistency(self, metrics_df: pd.DataFrame) -> float:
        """è®¡ç®—æ€§èƒ½ä¸€è‡´æ€§"""
        win_rate_consistency = 1 - (metrics_df['win_rate'].std() / metrics_df['win_rate'].mean())
        pnl_consistency = 1 - abs(metrics_df['total_pnl'].std() / metrics_df['total_pnl'].mean())
        
        return np.mean([win_rate_consistency, pnl_consistency])
    
    def _generate_stability_warnings(self, stability_factors: Dict) -> List[str]:
        """ç”Ÿæˆç¨³å®šæ€§è­¦å‘Š"""
        warnings = []
        
        if stability_factors['win_rate_stability'] < 0.7:
            warnings.append("èƒœç‡ç¨³å®šæ€§å·®")
        
        if stability_factors['sharpe_stability'] < 0.7:
            warnings.append("å¤æ™®æ¯”ç‡ç¨³å®šæ€§å·®")
        
        if stability_factors['consistency_ratio'] < 0.6:
            warnings.append("ç›ˆåˆ©ä¸€è‡´æ€§å·®")
        
        if stability_factors['parameter_stability'] < 0.8:
            warnings.append("å‚æ•°ç¨³å®šæ€§å·®ï¼Œå­˜åœ¨è¿‡æ‹Ÿåˆé£é™©")
        
        return warnings
    
    def _generate_recommendations(self, assessment: Dict) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if not assessment['overall_pass']:
            recommendations.append("ğŸš¨ ç­–ç•¥æœªé€šè¿‡Walk-ForwardéªŒè¯ï¼Œä¸å»ºè®®å®ç›˜äº¤æ˜“")
        
        if assessment['parameter_stability_avg'] < 0.8:
            recommendations.append("âš ï¸ å‚æ•°ä¸ç¨³å®šï¼Œå»ºè®®ç®€åŒ–ç­–ç•¥é€»è¾‘")
        
        if assessment['performance_consistency'] < 0.6:
            recommendations.append("âš ï¸ æ€§èƒ½ä¸€è‡´æ€§å·®ï¼Œå»ºè®®å¢åŠ æ•°æ®é‡æˆ–æ”¹è¿›ç­–ç•¥")
        
        if assessment['time_stability_score'] < 60:
            recommendations.append("âš ï¸ æ—¶é—´ç¨³å®šæ€§å·®ï¼Œç­–ç•¥å¯èƒ½è¿‡æ‹Ÿåˆ")
        
        if assessment['overall_pass']:
            recommendations.append("âœ… ç­–ç•¥é€šè¿‡Walk-ForwardéªŒè¯ï¼Œè¡¨ç°ç¨³å®š")
        
        return recommendations
    
    def _window_result_to_dict(self, window_result: WindowResult) -> Dict:
        """è½¬æ¢çª—å£ç»“æœä¸ºå­—å…¸"""
        return {
            'window_id': window_result.window_id,
            'train_start': window_result.train_start.isoformat(),
            'train_end': window_result.train_end.isoformat(),
            'test_start': window_result.test_start.isoformat(),
            'test_end': window_result.test_end.isoformat(),
            'train_trades': window_result.train_trades,
            'test_trades': window_result.test_trades,
            'test_metrics': window_result.test_metrics,
            'optimal_parameters': window_result.optimal_parameters,
            'parameter_stability': window_result.parameter_stability
        }
    
    def _save_walk_forward_results(self, window_results: List[WindowResult], analysis: Dict) -> None:
        """ä¿å­˜Walk-Forwardç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = self.results_dir / f"walk_forward_results_{timestamp}.json"
        with open(results_file, 'w') as f:
            json.dump(analysis, f, indent=2, default=str)
        
        # ä¿å­˜æ‘˜è¦
        summary = {
            'timestamp': timestamp,
            'total_windows': len(window_results),
            'overall_pass': analysis['overall_assessment']['overall_pass'],
            'stability_score': analysis['overall_assessment']['time_stability_score'],
            'avg_win_rate': analysis['overall_assessment']['avg_win_rate'],
            'recommendations': analysis['recommendations']
        }
        
        summary_file = self.results_dir / f"walk_forward_summary_{timestamp}.json"
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"Walk-Forwardç»“æœå·²ä¿å­˜: {results_file}")
        logger.info(f"Walk-Forwardæ‘˜è¦å·²ä¿å­˜: {summary_file}")