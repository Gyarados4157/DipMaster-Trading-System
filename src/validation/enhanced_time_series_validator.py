#!/usr/bin/env python3
"""
å¢å¼ºæ—¶åºéªŒè¯ç³»ç»Ÿ
å®æ–½ä¸¥æ ¼çš„Purged K-Foldäº¤å‰éªŒè¯å’ŒWalk-forwardåˆ†æ
"""

import os
import sys
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

from typing import Dict, List, Tuple, Optional, Generator
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
from pathlib import Path

import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# æœºå™¨å­¦ä¹ åº“
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, 
    precision_score, recall_score, f1_score, log_loss
)
from sklearn.model_selection import TimeSeriesSplit

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ValidationConfig:
    """éªŒè¯é…ç½®"""
    # Purged K-Foldå‚æ•°
    n_splits: int = 5
    embargo_hours: int = 2
    test_size_ratio: float = 0.2
    
    # Walk-forwardå‚æ•°
    min_train_size_months: int = 6  # æœ€å°è®­ç»ƒé›†å¤§å°ï¼ˆæœˆï¼‰
    rebalance_frequency_days: int = 30  # é‡æ–°å¹³è¡¡é¢‘ç‡ï¼ˆå¤©ï¼‰
    walk_forward_steps: int = 12  # Walk-forwardæ­¥æ•°
    
    # æ•°æ®æ³„æ¼æ£€æµ‹
    max_feature_correlation_threshold: float = 0.95
    max_ic_threshold: float = 0.3  # ä¿¡æ¯ç³»æ•°é˜ˆå€¼
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§
    min_sample_size: int = 100
    significance_level: float = 0.05
    bootstrap_samples: int = 1000

class EnhancedPurgedKFold:
    """å¢å¼ºçš„Purged K-Foldäº¤å‰éªŒè¯å™¨"""
    
    def __init__(self, n_splits: int = 5, embargo_hours: int = 2, test_size: float = 0.2):
        self.n_splits = n_splits
        self.embargo_td = timedelta(hours=embargo_hours)
        self.test_size = test_size
        
    def split(self, X: pd.DataFrame, y: pd.Series = None, groups=None) -> Generator:
        """ç”Ÿæˆæ—¶åºåˆ†å‰²ç´¢å¼•"""
        if 'timestamp' not in X.columns:
            # å¦‚æœæ²¡æœ‰timestampåˆ—ï¼Œåˆ›å»ºä¸€ä¸ªå‡çš„æ—¶é—´åºåˆ—
            timestamps = pd.date_range(start='2022-01-01', periods=len(X), freq='5min')
            X = X.copy()
            X['timestamp'] = timestamps
        
        timestamps = pd.to_datetime(X['timestamp'])
        indices = np.arange(len(X))
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_idx = timestamps.argsort()
        timestamps_sorted = timestamps.iloc[sorted_idx]
        
        n_samples = len(X)
        
        # ä¸ºæµ‹è¯•é›†é¢„ç•™æ•°æ®
        train_end_idx = int(n_samples * (1 - self.test_size))
        
        # è®¡ç®—æ¯ä¸ªfoldçš„å¤§å°
        fold_size = train_end_idx // self.n_splits
        
        for i in range(self.n_splits):
            # è®­ç»ƒé›†ç´¢å¼•èŒƒå›´
            train_start = i * (fold_size // 2) if i > 0 else 0  # é‡å è®­ç»ƒä»¥å¢åŠ æ ·æœ¬
            train_end = min((i + 1) * fold_size, train_end_idx)
            
            if train_end <= train_start:
                continue
                
            # åº”ç”¨embargoæœŸ
            train_end_time = timestamps_sorted.iloc[train_end - 1]
            val_start_time = train_end_time + self.embargo_td
            
            # æ‰¾åˆ°éªŒè¯é›†å¼€å§‹ç´¢å¼•
            val_mask = timestamps_sorted >= val_start_time
            if not val_mask.any():
                continue
                
            val_start_idx = timestamps_sorted[val_mask].index[0]
            val_end_idx = min(train_end + fold_size, train_end_idx)
            
            # è·å–åŸå§‹ç´¢å¼•
            train_indices = sorted_idx[train_start:train_end].values
            val_indices = sorted_idx[val_start_idx:val_end_idx].values
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
            if len(train_indices) >= 100 and len(val_indices) >= 20:
                yield train_indices, val_indices
    
    def get_n_splits(self, X=None, y=None, groups=None) -> int:
        return self.n_splits

class WalkForwardAnalyzer:
    """Walk-forwardåˆ†æå™¨"""
    
    def __init__(self, config: ValidationConfig):
        self.config = config
        
    def create_walk_forward_splits(self, X: pd.DataFrame, y: pd.Series) -> List[Tuple]:
        """åˆ›å»ºwalk-forwardåˆ†å‰²"""
        if 'timestamp' not in X.columns:
            timestamps = pd.date_range(start='2022-01-01', periods=len(X), freq='5min')
            X = X.copy()
            X['timestamp'] = timestamps
            
        timestamps = pd.to_datetime(X['timestamp'])
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_indices = timestamps.sort_values().index
        
        # è®¡ç®—æœ€å°è®­ç»ƒé›†å¤§å°
        min_train_samples = int(len(X) * 0.3)  # è‡³å°‘30%ç”¨äºè®­ç»ƒ
        
        # è®¡ç®—æ¯ä¸ªwalkæ­¥éª¤çš„å¤§å°
        remaining_samples = len(X) - min_train_samples
        step_size = remaining_samples // self.config.walk_forward_steps
        
        splits = []
        
        for i in range(self.config.walk_forward_steps):
            # è®­ç»ƒé›†ï¼šä»å¼€å§‹åˆ°å½“å‰æ­¥éª¤
            train_end = min_train_samples + i * step_size
            
            # æµ‹è¯•é›†ï¼šä¸‹ä¸€ä¸ªæ­¥éª¤çš„æ•°æ®
            test_start = train_end
            test_end = min(test_start + step_size, len(X))
            
            if test_end <= test_start:
                break
                
            train_indices = sorted_indices[:train_end].tolist()
            test_indices = sorted_indices[test_start:test_end].tolist()
            
            # åº”ç”¨embargo
            if len(train_indices) > 0 and len(test_indices) > 0:
                train_end_time = timestamps.loc[train_indices[-1]]
                embargo_end_time = train_end_time + timedelta(hours=self.config.embargo_hours)
                
                # è¿‡æ»¤æµ‹è¯•é›†ä¸­embargoæœŸå†…çš„æ•°æ®
                valid_test_indices = [
                    idx for idx in test_indices 
                    if timestamps.loc[idx] >= embargo_end_time
                ]
                
                if len(valid_test_indices) >= 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æµ‹è¯•æ ·æœ¬
                    splits.append((train_indices, valid_test_indices))
        
        logger.info(f"åˆ›å»ºäº† {len(splits)} ä¸ªwalk-forwardåˆ†å‰²")
        return splits
    
    def walk_forward_validation(self, X: pd.DataFrame, y: pd.Series, 
                              model_factory, fit_params: dict = None) -> Dict:
        """æ‰§è¡Œwalk-forwardéªŒè¯"""
        logger.info("å¼€å§‹walk-forwardéªŒè¯...")
        
        splits = self.create_walk_forward_splits(X, y)
        if not splits:
            return {'error': 'No valid splits created'}
        
        results = {
            'fold_results': [],
            'predictions': [],
            'actuals': [],
            'timestamps': [],
            'performance_over_time': []
        }
        
        for fold_idx, (train_indices, test_indices) in enumerate(splits):
            logger.info(f"Walk-forward fold {fold_idx + 1}/{len(splits)}")
            
            try:
                # å‡†å¤‡æ•°æ®
                X_train = X.iloc[train_indices].drop(columns=['timestamp'], errors='ignore')
                X_test = X.iloc[test_indices].drop(columns=['timestamp'], errors='ignore')
                y_train = y.iloc[train_indices]
                y_test = y.iloc[test_indices]
                
                # æ—¶é—´ä¿¡æ¯
                test_timestamps = X.iloc[test_indices]['timestamp'] if 'timestamp' in X.columns else None
                
                # è®­ç»ƒæ¨¡å‹
                model = model_factory()
                if fit_params:
                    model.fit(X_train, y_train, **fit_params)
                else:
                    model.fit(X_train, y_train)
                
                # é¢„æµ‹
                if hasattr(model, 'predict_proba'):
                    y_pred_proba = model.predict_proba(X_test)[:, 1]
                    y_pred = (y_pred_proba >= 0.5).astype(int)
                else:
                    y_pred = model.predict(X_test)
                    y_pred_proba = y_pred.astype(float)
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                fold_metrics = self._calculate_fold_metrics(y_test, y_pred, y_pred_proba)
                fold_metrics['fold'] = fold_idx
                fold_metrics['train_size'] = len(train_indices)
                fold_metrics['test_size'] = len(test_indices)
                
                results['fold_results'].append(fold_metrics)
                results['predictions'].extend(y_pred_proba)
                results['actuals'].extend(y_test)
                if test_timestamps is not None:
                    results['timestamps'].extend(test_timestamps)
                
                # è®°å½•æ—¶é—´åºåˆ—è¡¨ç°
                if test_timestamps is not None:
                    time_performance = {
                        'fold': fold_idx,
                        'start_date': test_timestamps.iloc[0],
                        'end_date': test_timestamps.iloc[-1],
                        'accuracy': fold_metrics['accuracy'],
                        'auc': fold_metrics['auc'],
                        'precision': fold_metrics['precision'],
                        'recall': fold_metrics['recall']
                    }
                    results['performance_over_time'].append(time_performance)
                
            except Exception as e:
                logger.error(f"Fold {fold_idx} å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—ç»¼åˆç»Ÿè®¡
        if results['fold_results']:
            results['summary_stats'] = self._calculate_summary_stats(results['fold_results'])
            results['stability_metrics'] = self._calculate_stability_metrics(results['fold_results'])
        
        return results
    
    def _calculate_fold_metrics(self, y_true: pd.Series, y_pred: np.ndarray, 
                               y_pred_proba: np.ndarray) -> Dict:
        """è®¡ç®—å•ä¸ªfoldçš„æ€§èƒ½æŒ‡æ ‡"""
        metrics = {}
        
        try:
            metrics['accuracy'] = (y_true == y_pred).mean()
            metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)
            metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)
            metrics['f1'] = f1_score(y_true, y_pred, zero_division=0)
            
            if len(np.unique(y_true)) > 1:
                metrics['auc'] = roc_auc_score(y_true, y_pred_proba)
                metrics['log_loss'] = log_loss(y_true, y_pred_proba)
            else:
                metrics['auc'] = 0.5
                metrics['log_loss'] = np.inf
                
        except Exception as e:
            logger.warning(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            metrics = {key: 0.0 for key in ['accuracy', 'precision', 'recall', 'f1', 'auc', 'log_loss']}
            
        return metrics
    
    def _calculate_summary_stats(self, fold_results: List[Dict]) -> Dict:
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']
        summary = {}
        
        for metric in metrics:
            values = [result[metric] for result in fold_results if metric in result]
            if values:
                summary[f'{metric}_mean'] = np.mean(values)
                summary[f'{metric}_std'] = np.std(values)
                summary[f'{metric}_min'] = np.min(values)
                summary[f'{metric}_max'] = np.max(values)
                
                # ç½®ä¿¡åŒºé—´
                ci_lower, ci_upper = stats.t.interval(
                    0.95, len(values)-1, 
                    loc=np.mean(values), 
                    scale=stats.sem(values)
                )
                summary[f'{metric}_ci_lower'] = ci_lower
                summary[f'{metric}_ci_upper'] = ci_upper
        
        return summary
    
    def _calculate_stability_metrics(self, fold_results: List[Dict]) -> Dict:
        """è®¡ç®—æ¨¡å‹ç¨³å®šæ€§æŒ‡æ ‡"""
        metrics = ['accuracy', 'auc', 'precision', 'recall']
        stability = {}
        
        for metric in metrics:
            values = [result[metric] for result in fold_results if metric in result]
            if len(values) > 1:
                # å˜å¼‚ç³»æ•°
                cv = np.std(values) / np.mean(values) if np.mean(values) != 0 else np.inf
                stability[f'{metric}_cv'] = cv
                
                # è¶‹åŠ¿æ£€æµ‹ï¼ˆSpearmanç›¸å…³æ€§ï¼‰
                fold_numbers = list(range(len(values)))
                correlation, p_value = stats.spearmanr(fold_numbers, values)
                stability[f'{metric}_trend_correlation'] = correlation
                stability[f'{metric}_trend_p_value'] = p_value
                
        return stability

class DataLeakageDetector:
    """æ•°æ®æ³„æ¼æ£€æµ‹å™¨"""
    
    def __init__(self, config: ValidationConfig):
        self.config = config
        
    def detect_feature_leakage(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """æ£€æµ‹ç‰¹å¾æ³„æ¼"""
        logger.info("æ£€æµ‹ç‰¹å¾æ•°æ®æ³„æ¼...")
        
        results = {
            'high_correlation_features': [],
            'future_information_features': [],
            'suspicious_ic_features': [],
            'leakage_score': 0.0
        }
        
        # 1. æ£€æµ‹é«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆå¯èƒ½æ˜¯æ ‡ç­¾æ³„æ¼ï¼‰
        feature_cols = [col for col in X.columns if col not in ['timestamp']]
        
        for feature in feature_cols:
            if X[feature].dtype in ['int64', 'float64']:
                # è®¡ç®—ä¸ç›®æ ‡çš„ç›¸å…³æ€§
                correlation = X[feature].corr(y)
                
                if abs(correlation) > self.config.max_feature_correlation_threshold:
                    results['high_correlation_features'].append({
                        'feature': feature,
                        'correlation': correlation
                    })
        
        # 2. æ£€æµ‹æœªæ¥ä¿¡æ¯æ³„æ¼
        if 'timestamp' in X.columns:
            results['future_information_features'] = self._detect_future_information(X, y)
        
        # 3. æ£€æµ‹å¯ç–‘çš„ä¿¡æ¯ç³»æ•°
        results['suspicious_ic_features'] = self._calculate_information_coefficients(X, y)
        
        # 4. è®¡ç®—ç»¼åˆæ³„æ¼åˆ†æ•°
        leakage_score = (
            len(results['high_correlation_features']) * 0.4 +
            len(results['future_information_features']) * 0.4 +
            len(results['suspicious_ic_features']) * 0.2
        )
        results['leakage_score'] = leakage_score / len(feature_cols) if feature_cols else 0
        
        return results
    
    def _detect_future_information(self, X: pd.DataFrame, y: pd.Series) -> List[Dict]:
        """æ£€æµ‹æœªæ¥ä¿¡æ¯æ³„æ¼"""
        suspicious_features = []
        
        if 'timestamp' not in X.columns:
            return suspicious_features
            
        timestamps = pd.to_datetime(X['timestamp'])
        feature_cols = [col for col in X.columns if col not in ['timestamp']]
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ…å«æœªæ¥ä¿¡æ¯
        for feature in feature_cols:
            if feature.lower() in ['target', 'return', 'profit', 'label', 'future']:
                suspicious_features.append({
                    'feature': feature,
                    'reason': 'Feature name suggests future information'
                })
                continue
                
            # æ£€æŸ¥ç‰¹å¾çš„æ—¶é—´ä¸€è‡´æ€§
            try:
                # è®¡ç®—ç‰¹å¾çš„æ»åç›¸å…³æ€§
                feature_values = X[feature].values
                
                # æ£€æŸ¥ç‰¹å¾æ˜¯å¦ä¸æœªæ¥ç›®æ ‡å€¼ç›¸å…³
                for lag in [1, 2, 3, 6, 12]:  # ä¸åŒçš„å‰ç»æœŸ
                    if len(feature_values) > lag:
                        future_target = y.shift(-lag).dropna()
                        aligned_feature = X[feature].iloc[:len(future_target)]
                        
                        if len(aligned_feature) > 0 and aligned_feature.std() > 0:
                            correlation = aligned_feature.corr(future_target)
                            
                            if abs(correlation) > 0.3:  # å¯ç–‘çš„é«˜ç›¸å…³æ€§
                                suspicious_features.append({
                                    'feature': feature,
                                    'reason': f'High correlation with future target (lag {lag})',
                                    'correlation': correlation,
                                    'lag': lag
                                })
                                break
                                
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç‰¹å¾ {feature} æ—¶å‡ºé”™: {e}")
                
        return suspicious_features
    
    def _calculate_information_coefficients(self, X: pd.DataFrame, y: pd.Series) -> List[Dict]:
        """è®¡ç®—ä¿¡æ¯ç³»æ•°"""
        suspicious_features = []
        feature_cols = [col for col in X.columns if col not in ['timestamp']]
        
        for feature in feature_cols:
            try:
                if X[feature].dtype in ['int64', 'float64'] and X[feature].std() > 0:
                    # è®¡ç®—ä¿¡æ¯ç³»æ•°ï¼ˆICï¼‰
                    ic = X[feature].corr(y)
                    
                    if abs(ic) > self.config.max_ic_threshold:
                        suspicious_features.append({
                            'feature': feature,
                            'ic': ic,
                            'reason': f'High information coefficient: {ic:.3f}'
                        })
                        
            except Exception as e:
                logger.warning(f"è®¡ç®—ICæ—¶å‡ºé”™ {feature}: {e}")
                
        return suspicious_features

class EnhancedTimeSeriesValidator:
    """å¢å¼ºæ—¶åºéªŒè¯ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, config: ValidationConfig = None):
        self.config = config or ValidationConfig()
        self.purged_kfold = EnhancedPurgedKFold(
            n_splits=self.config.n_splits,
            embargo_hours=self.config.embargo_hours,
            test_size=self.config.test_size_ratio
        )
        self.walk_forward_analyzer = WalkForwardAnalyzer(self.config)
        self.leakage_detector = DataLeakageDetector(self.config)
        
        # ç»“æœå­˜å‚¨
        self.validation_results = {}
        
    def comprehensive_validation(self, X: pd.DataFrame, y: pd.Series, 
                               model_factory, fit_params: dict = None) -> Dict:
        """æ‰§è¡Œç»¼åˆéªŒè¯"""
        logger.info("å¼€å§‹ç»¼åˆæ—¶åºéªŒè¯...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'data_summary': self._summarize_data(X, y),
            'leakage_detection': {},
            'purged_cv_results': {},
            'walk_forward_results': {},
            'stability_analysis': {},
            'recommendations': []
        }
        
        try:
            # 1. æ•°æ®æ³„æ¼æ£€æµ‹
            logger.info("1. æ‰§è¡Œæ•°æ®æ³„æ¼æ£€æµ‹...")
            results['leakage_detection'] = self.leakage_detector.detect_feature_leakage(X, y)
            
            # 2. Purged K-Foldäº¤å‰éªŒè¯
            logger.info("2. æ‰§è¡ŒPurged K-Foldäº¤å‰éªŒè¯...")
            results['purged_cv_results'] = self._purged_cv_validation(X, y, model_factory, fit_params)
            
            # 3. Walk-forwardéªŒè¯
            logger.info("3. æ‰§è¡ŒWalk-forwardéªŒè¯...")
            results['walk_forward_results'] = self.walk_forward_analyzer.walk_forward_validation(
                X, y, model_factory, fit_params
            )
            
            # 4. ç¨³å®šæ€§åˆ†æ
            logger.info("4. æ‰§è¡Œç¨³å®šæ€§åˆ†æ...")
            results['stability_analysis'] = self._analyze_stability(results)
            
            # 5. ç”Ÿæˆå»ºè®®
            results['recommendations'] = self._generate_recommendations(results)
            
        except Exception as e:
            logger.error(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            results['error'] = str(e)
            
        # ä¿å­˜ç»“æœ
        self.validation_results = results
        
        return results
    
    def _summarize_data(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """æ•°æ®æ‘˜è¦"""
        return {
            'n_samples': len(X),
            'n_features': len(X.columns),
            'target_distribution': {
                'positive_ratio': y.mean(),
                'negative_ratio': 1 - y.mean(),
                'total_positive': y.sum(),
                'total_negative': (1 - y).sum()
            },
            'time_span': {
                'start': X['timestamp'].min() if 'timestamp' in X.columns else None,
                'end': X['timestamp'].max() if 'timestamp' in X.columns else None,
                'duration_days': (X['timestamp'].max() - X['timestamp'].min()).days if 'timestamp' in X.columns else None
            },
            'data_quality': {
                'missing_values': X.isnull().sum().sum(),
                'duplicate_rows': X.duplicated().sum(),
                'infinite_values': np.isinf(X.select_dtypes(include=[np.number])).sum().sum()
            }
        }
    
    def _purged_cv_validation(self, X: pd.DataFrame, y: pd.Series, 
                             model_factory, fit_params: dict = None) -> Dict:
        """Purgedäº¤å‰éªŒè¯"""
        fold_results = []
        all_predictions = []
        all_actuals = []
        
        for fold_idx, (train_indices, val_indices) in enumerate(self.purged_kfold.split(X, y)):
            try:
                # å‡†å¤‡æ•°æ®
                X_train = X.iloc[train_indices].drop(columns=['timestamp'], errors='ignore')
                X_val = X.iloc[val_indices].drop(columns=['timestamp'], errors='ignore')
                y_train = y.iloc[train_indices]
                y_val = y.iloc[val_indices]
                
                # è®­ç»ƒæ¨¡å‹
                model = model_factory()
                if fit_params:
                    model.fit(X_train, y_train, **fit_params)
                else:
                    model.fit(X_train, y_train)
                
                # é¢„æµ‹
                if hasattr(model, 'predict_proba'):
                    y_pred_proba = model.predict_proba(X_val)[:, 1]
                    y_pred = (y_pred_proba >= 0.5).astype(int)
                else:
                    y_pred = model.predict(X_val)
                    y_pred_proba = y_pred.astype(float)
                
                # è®¡ç®—æŒ‡æ ‡
                fold_metrics = self.walk_forward_analyzer._calculate_fold_metrics(y_val, y_pred, y_pred_proba)
                fold_metrics['fold'] = fold_idx
                fold_metrics['train_size'] = len(train_indices)
                fold_metrics['val_size'] = len(val_indices)
                
                fold_results.append(fold_metrics)
                all_predictions.extend(y_pred_proba)
                all_actuals.extend(y_val)
                
            except Exception as e:
                logger.error(f"Purged CV fold {fold_idx} å¤±è´¥: {e}")
                
        # æ±‡æ€»ç»“æœ
        if fold_results:
            summary_stats = self.walk_forward_analyzer._calculate_summary_stats(fold_results)
            stability_metrics = self.walk_forward_analyzer._calculate_stability_metrics(fold_results)
            
            return {
                'fold_results': fold_results,
                'summary_stats': summary_stats,
                'stability_metrics': stability_metrics,
                'overall_predictions': all_predictions,
                'overall_actuals': all_actuals
            }
        else:
            return {'error': 'No successful folds in Purged CV'}
    
    def _analyze_stability(self, results: Dict) -> Dict:
        """åˆ†ææ¨¡å‹ç¨³å®šæ€§"""
        stability = {
            'cv_stability': {},
            'walk_forward_stability': {},
            'temporal_consistency': {},
            'overall_stability_score': 0.0
        }
        
        # CVç¨³å®šæ€§
        if 'purged_cv_results' in results and 'stability_metrics' in results['purged_cv_results']:
            stability['cv_stability'] = results['purged_cv_results']['stability_metrics']
        
        # Walk-forwardç¨³å®šæ€§
        if 'walk_forward_results' in results and 'stability_metrics' in results['walk_forward_results']:
            stability['walk_forward_stability'] = results['walk_forward_results']['stability_metrics']
        
        # æ—¶é—´ä¸€è‡´æ€§åˆ†æ
        if 'walk_forward_results' in results and 'performance_over_time' in results['walk_forward_results']:
            perf_over_time = results['walk_forward_results']['performance_over_time']
            if perf_over_time:
                accuracy_values = [p['accuracy'] for p in perf_over_time]
                auc_values = [p['auc'] for p in perf_over_time]
                
                stability['temporal_consistency'] = {
                    'accuracy_trend': np.corrcoef(range(len(accuracy_values)), accuracy_values)[0, 1] if len(accuracy_values) > 1 else 0,
                    'auc_trend': np.corrcoef(range(len(auc_values)), auc_values)[0, 1] if len(auc_values) > 1 else 0,
                    'accuracy_volatility': np.std(accuracy_values) if accuracy_values else 0,
                    'auc_volatility': np.std(auc_values) if auc_values else 0
                }
        
        # ç»¼åˆç¨³å®šæ€§åˆ†æ•°
        cv_acc_cv = stability['cv_stability'].get('accuracy_cv', 1)
        wf_acc_cv = stability['walk_forward_stability'].get('accuracy_cv', 1)
        temporal_vol = stability['temporal_consistency'].get('accuracy_volatility', 1)
        
        stability['overall_stability_score'] = 1 / (1 + cv_acc_cv + wf_acc_cv + temporal_vol)
        
        return stability
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """ç”ŸæˆéªŒè¯å»ºè®®"""
        recommendations = []
        
        # æ•°æ®æ³„æ¼å»ºè®®
        leakage = results.get('leakage_detection', {})
        if leakage.get('leakage_score', 0) > 0.1:
            recommendations.append(
                f"âš ï¸ æ£€æµ‹åˆ°æ•°æ®æ³„æ¼é£é™© (score: {leakage['leakage_score']:.3f})ï¼Œ"
                f"å»ºè®®æ£€æŸ¥ä»¥ä¸‹ç‰¹å¾: {[f['feature'] for f in leakage.get('high_correlation_features', [])]}"
            )
        
        # CVè¡¨ç°å»ºè®®
        cv_results = results.get('purged_cv_results', {})
        if 'summary_stats' in cv_results:
            cv_acc = cv_results['summary_stats'].get('accuracy_mean', 0)
            cv_std = cv_results['summary_stats'].get('accuracy_std', 1)
            
            if cv_acc < 0.6:
                recommendations.append("ğŸ”„ CVå‡†ç¡®ç‡è¾ƒä½ï¼Œå»ºè®®å¢åŠ ç‰¹å¾å·¥ç¨‹æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°")
            
            if cv_std > 0.1:
                recommendations.append("ğŸ“ˆ CVç»“æœæ–¹å·®è¾ƒå¤§ï¼Œå»ºè®®å¢åŠ æ•°æ®é‡æˆ–ä½¿ç”¨æ­£åˆ™åŒ–")
        
        # Walk-forwardå»ºè®®
        wf_results = results.get('walk_forward_results', {})
        if 'summary_stats' in wf_results:
            wf_acc = wf_results['summary_stats'].get('accuracy_mean', 0)
            
            if abs(cv_results.get('summary_stats', {}).get('accuracy_mean', 0) - wf_acc) > 0.05:
                recommendations.append("â° CVå’ŒWalk-forwardç»“æœå·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨æ—¶åºåå·®")
        
        # ç¨³å®šæ€§å»ºè®®
        stability = results.get('stability_analysis', {})
        if stability.get('overall_stability_score', 0) < 0.7:
            recommendations.append("ğŸ”§ æ¨¡å‹ç¨³å®šæ€§è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨é›†æˆæ–¹æ³•æˆ–å¢åŠ æ­£åˆ™åŒ–")
        
        # æ—¶é—´è¶‹åŠ¿å»ºè®®
        temporal = stability.get('temporal_consistency', {})
        if abs(temporal.get('accuracy_trend', 0)) > 0.5:
            recommendations.append("ğŸ“Š æ£€æµ‹åˆ°æ˜æ˜¾çš„æ—¶é—´è¶‹åŠ¿ï¼Œå»ºè®®è€ƒè™‘å¸‚åœºåˆ¶åº¦å˜åŒ–")
        
        return recommendations
    
    def save_validation_report(self, output_path: str = None):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        if not self.validation_results:
            logger.warning("æ²¡æœ‰éªŒè¯ç»“æœå¯ä¿å­˜")
            return
            
        if output_path is None:
            output_path = f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        import json
        
        def json_serializable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.int64, np.float64)):
                return obj.item()
            elif isinstance(obj, pd.Timestamp):
                return obj.isoformat()
            elif hasattr(obj, '__dict__'):
                return str(obj)
            else:
                return obj
        
        # æ¸…ç†ç»“æœä»¥ä¾¿JSONåºåˆ—åŒ–
        serializable_results = {}
        for key, value in self.validation_results.items():
            try:
                if key in ['overall_predictions', 'overall_actuals', 'predictions', 'actuals']:
                    # å¯¹äºå¤§æ•°ç»„ï¼Œåªä¿å­˜ç»Ÿè®¡ä¿¡æ¯
                    serializable_results[key + '_stats'] = {
                        'count': len(value),
                        'mean': np.mean(value),
                        'std': np.std(value),
                        'min': np.min(value),
                        'max': np.max(value)
                    }
                else:
                    serializable_results[key] = json_serializable(value)
            except Exception as e:
                logger.warning(f"æ— æ³•åºåˆ—åŒ– {key}: {e}")
                serializable_results[key] = str(value)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        
        return output_path

def create_model_factory(model_type: str = 'lgbm', **params):
    """åˆ›å»ºæ¨¡å‹å·¥å‚å‡½æ•°"""
    def model_factory():
        if model_type == 'lgbm':
            import lightgbm as lgb
            default_params = {
                'objective': 'binary',
                'metric': 'binary_logloss',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1
            }
            default_params.update(params)
            return lgb.LGBMClassifier(**default_params)
            
        elif model_type == 'xgb':
            import xgboost as xgb
            default_params = {
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'max_depth': 6,
                'learning_rate': 0.1,
                'n_estimators': 100,
                'subsample': 0.8,
                'colsample_bytree': 0.8
            }
            default_params.update(params)
            return xgb.XGBClassifier(**default_params)
            
        else:  # Random Forest
            from sklearn.ensemble import RandomForestClassifier
            default_params = {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'random_state': 42
            }
            default_params.update(params)
            return RandomForestClassifier(**default_params)
    
    return model_factory

# ä¸»å‡½æ•°ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # é…ç½®
    config = ValidationConfig(
        n_splits=5,
        embargo_hours=2,
        walk_forward_steps=6
    )
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = EnhancedTimeSeriesValidator(config)
    
    # æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®æ•°æ®ï¼‰
    np.random.seed(42)
    n_samples = 5000
    
    X = pd.DataFrame({
        'timestamp': pd.date_range('2022-01-01', periods=n_samples, freq='5min'),
        'feature1': np.random.randn(n_samples),
        'feature2': np.random.randn(n_samples),
        'feature3': np.random.randn(n_samples)
    })
    
    y = pd.Series((np.random.randn(n_samples) > 0).astype(int))
    
    # åˆ›å»ºæ¨¡å‹å·¥å‚
    model_factory = create_model_factory('lgbm')
    
    # æ‰§è¡ŒéªŒè¯
    results = validator.comprehensive_validation(X, y, model_factory)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = validator.save_validation_report()
    
    print(f"éªŒè¯å®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜è‡³: {report_path}")
    print(f"ç»¼åˆå»ºè®®æ•°é‡: {len(results.get('recommendations', []))}")
    
    return results

if __name__ == "__main__":
    main()