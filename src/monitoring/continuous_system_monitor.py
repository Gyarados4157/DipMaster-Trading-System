#!/usr/bin/env python3
"""
DipMaster Trading System - æŒç»­ç³»ç»Ÿç›‘æ§å’Œä¸€è‡´æ€§éªŒè¯
åˆ›å»ºæ—¶é—´: 2025-08-18
ç‰ˆæœ¬: 1.0.0

åŠŸèƒ½: 
- å®æ—¶ç›‘æ§æ‰€æœ‰ç³»ç»Ÿç»„ä»¶
- éªŒè¯ä¿¡å·-æ‰§è¡Œä¸€è‡´æ€§
- æ£€æµ‹ç³»ç»Ÿå¥åº·çŠ¶æ€
- ç”Ÿæˆå‘Šè­¦å’ŒæŠ¥å‘Š
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np
from dataclasses import dataclass, asdict
import psutil
import aiofiles
import hashlib

@dataclass
class SystemHealthMetrics:
    """ç³»ç»Ÿå¥åº·æŒ‡æ ‡"""
    timestamp: str
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_latency: float
    active_connections: int
    error_count: int
    warning_count: int
    uptime: float

@dataclass
class SignalExecutionConsistency:
    """ä¿¡å·æ‰§è¡Œä¸€è‡´æ€§æŒ‡æ ‡"""
    signal_id: str
    signal_timestamp: str
    signal_strength: float
    execution_timestamp: Optional[str]
    execution_delay: Optional[float]
    target_position: float
    actual_position: float
    consistency_score: float
    deviation_reason: Optional[str]

@dataclass
class RiskAlert:
    """é£é™©å‘Šè­¦"""
    alert_id: str
    timestamp: str
    severity: str  # "LOW", "MEDIUM", "HIGH", "CRITICAL"
    category: str  # "RISK", "PERFORMANCE", "SYSTEM", "CONSISTENCY"
    message: str
    affected_component: str
    suggested_action: str
    auto_resolved: bool = False

class ContinuousSystemMonitor:
    """æŒç»­ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self, config_path: str = "config/monitoring_config.json"):
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        self.monitoring_active = False
        
        # ç›‘æ§çŠ¶æ€
        self.system_metrics_history = []
        self.signal_consistency_history = []
        self.alerts_history = []
        self.component_status = {}
        
        # é˜ˆå€¼é…ç½®
        self.thresholds = {
            "cpu_usage_critical": 90.0,
            "memory_usage_critical": 85.0,
            "disk_usage_critical": 90.0,
            "signal_delay_warning": 5.0,  # ç§’
            "consistency_score_warning": 0.8,
            "error_rate_critical": 0.05
        }
        
        # ç»„ä»¶è·¯å¾„
        self.monitored_paths = {
            "data_infrastructure": "data/continuous_optimization/",
            "feature_engineering": "data/continuous_optimization/",
            "model_training": "results/model_training/",
            "portfolio_optimization": "results/portfolio_optimization/",
            "execution_reports": "results/execution_reports/",
            "logs": "logs/"
        }
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½ç›‘æ§é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            # é»˜è®¤é…ç½®
            default_config = {
                "monitoring_interval": 60,  # ç§’
                "health_check_interval": 300,  # ç§’
                "alert_cooldown": 1800,  # ç§’
                "max_history_size": 1000,
                "kafka_enabled": False,
                "report_generation_hours": [8, 16, 0]
            }
            return default_config
    
    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger("SystemMonitor")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
            log_dir = Path("logs")
            log_dir.mkdir(exist_ok=True)
            
            file_handler = logging.FileHandler(
                log_dir / f"system_monitor_{datetime.now().strftime('%Y%m%d')}.log"
            )
            
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        
        return logger
    
    async def start_monitoring(self):
        """å¯åŠ¨æŒç»­ç›‘æ§"""
        self.monitoring_active = True
        self.logger.info("ğŸš€ å¯åŠ¨DipMasteræŒç»­ç³»ç»Ÿç›‘æ§")
        
        # å¯åŠ¨å¹¶å‘ç›‘æ§ä»»åŠ¡
        tasks = [
            self._system_health_monitor(),
            self._signal_consistency_monitor(),
            self._component_status_monitor(),
            self._alert_manager(),
            self._report_generator()
        ]
        
        try:
            await asyncio.gather(*tasks)
        except Exception as e:
            self.logger.error(f"ç›‘æ§ç³»ç»Ÿå¼‚å¸¸: {e}")
            self.monitoring_active = False
    
    async def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_active = False
        self.logger.info("ğŸ›‘ åœæ­¢ç³»ç»Ÿç›‘æ§")
    
    async def _system_health_monitor(self):
        """ç³»ç»Ÿå¥åº·ç›‘æ§"""
        while self.monitoring_active:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                metrics = await self._collect_system_metrics()
                self.system_metrics_history.append(metrics)
                
                # é™åˆ¶å†å²è®°å½•å¤§å°
                if len(self.system_metrics_history) > self.config["max_history_size"]:
                    self.system_metrics_history.pop(0)
                
                # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
                await self._check_system_alerts(metrics)
                
                await asyncio.sleep(self.config["monitoring_interval"])
                
            except Exception as e:
                self.logger.error(f"ç³»ç»Ÿå¥åº·ç›‘æ§é”™è¯¯: {e}")
                await asyncio.sleep(30)
    
    async def _collect_system_metrics(self) -> SystemHealthMetrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_usage = psutil.cpu_percent(interval=1)
        
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        
        # ç£ç›˜ä½¿ç”¨ç‡
        disk = psutil.disk_usage('/')
        disk_usage = (disk.used / disk.total) * 100
        
        # ç½‘ç»œå»¶è¿Ÿï¼ˆç®€åŒ–å®ç°ï¼‰
        network_latency = await self._measure_network_latency()
        
        # æ´»è·ƒè¿æ¥æ•°
        connections = len(psutil.net_connections())
        
        # é”™è¯¯å’Œè­¦å‘Šè®¡æ•°
        error_count, warning_count = await self._count_recent_errors()
        
        # ç³»ç»Ÿè¿è¡Œæ—¶é—´
        uptime = time.time() - psutil.boot_time()
        
        return SystemHealthMetrics(
            timestamp=datetime.now().isoformat(),
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            disk_usage=disk_usage,
            network_latency=network_latency,
            active_connections=connections,
            error_count=error_count,
            warning_count=warning_count,
            uptime=uptime
        )
    
    async def _measure_network_latency(self) -> float:
        """æµ‹é‡ç½‘ç»œå»¶è¿Ÿ"""
        try:
            import subprocess
            result = subprocess.run(
                ['ping', '-c', '1', '8.8.8.8'], 
                capture_output=True, 
                text=True, 
                timeout=5
            )
            if result.returncode == 0:
                # è§£æpingç»“æœ
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'time=' in line:
                        time_str = line.split('time=')[1].split(' ')[0]
                        return float(time_str)
            return 0.0
        except:
            return 0.0
    
    async def _count_recent_errors(self) -> tuple[int, int]:
        """ç»Ÿè®¡æœ€è¿‘çš„é”™è¯¯å’Œè­¦å‘Šæ•°é‡"""
        error_count = 0
        warning_count = 0
        
        try:
            log_files = list(Path("logs").glob("*.log"))
            cutoff_time = datetime.now() - timedelta(hours=1)
            
            for log_file in log_files:
                async with aiofiles.open(log_file, 'r') as f:
                    content = await f.read()
                    lines = content.split('\n')
                    
                    for line in lines[-1000:]:  # æ£€æŸ¥æœ€å1000è¡Œ
                        if 'ERROR' in line:
                            error_count += 1
                        elif 'WARNING' in line:
                            warning_count += 1
        except:
            pass
        
        return error_count, warning_count
    
    async def _signal_consistency_monitor(self):
        """ä¿¡å·æ‰§è¡Œä¸€è‡´æ€§ç›‘æ§"""
        while self.monitoring_active:
            try:
                consistency_metrics = await self._analyze_signal_consistency()
                self.signal_consistency_history.extend(consistency_metrics)
                
                # æ£€æŸ¥ä¸€è‡´æ€§å‘Šè­¦
                for metric in consistency_metrics:
                    if metric.consistency_score < self.thresholds["consistency_score_warning"]:
                        await self._generate_alert(
                            severity="MEDIUM",
                            category="CONSISTENCY",
                            message=f"ä¿¡å·æ‰§è¡Œä¸€è‡´æ€§ä½: {metric.consistency_score:.2f}",
                            affected_component="signal_execution",
                            suggested_action="æ£€æŸ¥ä¿¡å·å»¶è¿Ÿå’Œæ‰§è¡Œè·¯å¾„"
                        )
                
                await asyncio.sleep(self.config["monitoring_interval"])
                
            except Exception as e:
                self.logger.error(f"ä¿¡å·ä¸€è‡´æ€§ç›‘æ§é”™è¯¯: {e}")
                await asyncio.sleep(30)
    
    async def _analyze_signal_consistency(self) -> List[SignalExecutionConsistency]:
        """åˆ†æä¿¡å·æ‰§è¡Œä¸€è‡´æ€§"""
        consistency_metrics = []
        
        try:
            # è¯»å–æœ€è¿‘çš„ä¿¡å·å’Œæ‰§è¡Œæ•°æ®
            signal_files = list(Path("results/model_training").glob("*signals*.json"))
            execution_files = list(Path("results/execution_reports").glob("*.json"))
            
            if not signal_files or not execution_files:
                return consistency_metrics
            
            # è¯»å–æœ€æ–°çš„ä¿¡å·æ–‡ä»¶
            latest_signal_file = max(signal_files, key=lambda x: x.stat().st_mtime)
            with open(latest_signal_file, 'r') as f:
                signals_data = json.load(f)
            
            # è¯»å–æœ€æ–°çš„æ‰§è¡Œæ–‡ä»¶
            latest_execution_file = max(execution_files, key=lambda x: x.stat().st_mtime)
            with open(latest_execution_file, 'r') as f:
                execution_data = json.load(f)
            
            # æ¯”è¾ƒä¿¡å·å’Œæ‰§è¡Œçš„ä¸€è‡´æ€§
            for signal in signals_data.get("signals", [])[-10:]:  # æ£€æŸ¥æœ€è¿‘10ä¸ªä¿¡å·
                signal_id = signal.get("signal_id", str(hash(str(signal))))
                signal_timestamp = signal.get("timestamp", "")
                signal_strength = signal.get("strength", 0.0)
                
                # æŸ¥æ‰¾å¯¹åº”çš„æ‰§è¡Œè®°å½•
                execution_record = None
                for exec_rec in execution_data.get("executions", []):
                    if abs(float(exec_rec.get("timestamp", 0)) - float(signal.get("timestamp", 0))) < 300:  # 5åˆ†é’Ÿå†…
                        execution_record = exec_rec
                        break
                
                if execution_record:
                    execution_timestamp = execution_record.get("timestamp", "")
                    execution_delay = abs(float(execution_timestamp) - float(signal_timestamp))
                    target_position = signal.get("target_position", 0.0)
                    actual_position = execution_record.get("actual_position", 0.0)
                    
                    # è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°
                    position_diff = abs(target_position - actual_position)
                    consistency_score = max(0, 1 - position_diff / max(abs(target_position), 1))
                    
                    consistency_metric = SignalExecutionConsistency(
                        signal_id=signal_id,
                        signal_timestamp=signal_timestamp,
                        signal_strength=signal_strength,
                        execution_timestamp=execution_timestamp,
                        execution_delay=execution_delay,
                        target_position=target_position,
                        actual_position=actual_position,
                        consistency_score=consistency_score,
                        deviation_reason=None if consistency_score > 0.9 else "ä»“ä½åå·®è¿‡å¤§"
                    )
                    
                    consistency_metrics.append(consistency_metric)
        
        except Exception as e:
            self.logger.error(f"ä¿¡å·ä¸€è‡´æ€§åˆ†æé”™è¯¯: {e}")
        
        return consistency_metrics
    
    async def _component_status_monitor(self):
        """ç»„ä»¶çŠ¶æ€ç›‘æ§"""
        while self.monitoring_active:
            try:
                for component, path in self.monitored_paths.items():
                    status = await self._check_component_status(component, path)
                    self.component_status[component] = status
                
                await asyncio.sleep(self.config["health_check_interval"])
                
            except Exception as e:
                self.logger.error(f"ç»„ä»¶çŠ¶æ€ç›‘æ§é”™è¯¯: {e}")
                await asyncio.sleep(60)
    
    async def _check_component_status(self, component: str, path: str) -> Dict[str, Any]:
        """æ£€æŸ¥ç»„ä»¶çŠ¶æ€"""
        status = {
            "component": component,
            "status": "UNKNOWN",
            "last_update": None,
            "file_count": 0,
            "total_size": 0,
            "health_score": 0.0
        }
        
        try:
            path_obj = Path(path)
            if path_obj.exists():
                files = list(path_obj.glob("**/*"))
                recent_files = [f for f in files if f.is_file() and 
                              (datetime.now() - datetime.fromtimestamp(f.stat().st_mtime)).days < 1]
                
                status.update({
                    "status": "ACTIVE" if recent_files else "STALE",
                    "last_update": max([f.stat().st_mtime for f in files if f.is_file()]) if files else None,
                    "file_count": len([f for f in files if f.is_file()]),
                    "total_size": sum([f.stat().st_size for f in files if f.is_file()]),
                    "health_score": min(1.0, len(recent_files) / max(1, len(files) * 0.1))
                })
            else:
                status["status"] = "MISSING"
        
        except Exception as e:
            status["status"] = "ERROR"
            status["error"] = str(e)
        
        return status
    
    async def _check_system_alerts(self, metrics: SystemHealthMetrics):
        """æ£€æŸ¥ç³»ç»Ÿå‘Šè­¦æ¡ä»¶"""
        # CPUä½¿ç”¨ç‡å‘Šè­¦
        if metrics.cpu_usage > self.thresholds["cpu_usage_critical"]:
            await self._generate_alert(
                severity="HIGH",
                category="SYSTEM",
                message=f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_usage:.1f}%",
                affected_component="system",
                suggested_action="æ£€æŸ¥CPUå¯†é›†å‹è¿›ç¨‹ï¼Œè€ƒè™‘æ‰©å®¹"
            )
        
        # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
        if metrics.memory_usage > self.thresholds["memory_usage_critical"]:
            await self._generate_alert(
                severity="HIGH",
                category="SYSTEM",
                message=f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_usage:.1f}%",
                affected_component="system",
                suggested_action="æ£€æŸ¥å†…å­˜æ³„æ¼ï¼Œæ¸…ç†ç¼“å­˜"
            )
        
        # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦
        if metrics.disk_usage > self.thresholds["disk_usage_critical"]:
            await self._generate_alert(
                severity="CRITICAL",
                category="SYSTEM",
                message=f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.disk_usage:.1f}%",
                affected_component="system",
                suggested_action="æ¸…ç†æ—¥å¿—æ–‡ä»¶ï¼Œæ‰©å±•å­˜å‚¨ç©ºé—´"
            )
        
        # é”™è¯¯ç‡å‘Šè­¦
        total_operations = max(1, metrics.error_count + metrics.warning_count + 100)
        error_rate = metrics.error_count / total_operations
        if error_rate > self.thresholds["error_rate_critical"]:
            await self._generate_alert(
                severity="HIGH",
                category="SYSTEM",
                message=f"é”™è¯¯ç‡è¿‡é«˜: {error_rate:.1%}",
                affected_component="system",
                suggested_action="æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—ï¼Œä¿®å¤é”™è¯¯æº"
            )
    
    async def _generate_alert(self, severity: str, category: str, message: str, 
                            affected_component: str, suggested_action: str):
        """ç”Ÿæˆå‘Šè­¦"""
        alert_id = hashlib.md5(f"{category}_{message}_{affected_component}".encode()).hexdigest()[:8]
        
        # æ£€æŸ¥é‡å¤å‘Šè­¦ï¼ˆå†·å´æœŸï¼‰
        recent_alerts = [a for a in self.alerts_history 
                        if (datetime.now() - datetime.fromisoformat(a.timestamp)).seconds < self.config["alert_cooldown"]]
        
        if any(a.message == message for a in recent_alerts):
            return  # è·³è¿‡é‡å¤å‘Šè­¦
        
        alert = RiskAlert(
            alert_id=alert_id,
            timestamp=datetime.now().isoformat(),
            severity=severity,
            category=category,
            message=message,
            affected_component=affected_component,
            suggested_action=suggested_action
        )
        
        self.alerts_history.append(alert)
        self.logger.warning(f"å‘Šè­¦ç”Ÿæˆ [{severity}] {category}: {message}")
        
        # ä¿å­˜å‘Šè­¦åˆ°æ–‡ä»¶
        await self._save_alert(alert)
    
    async def _save_alert(self, alert: RiskAlert):
        """ä¿å­˜å‘Šè­¦åˆ°æ–‡ä»¶"""
        try:
            alerts_dir = Path("logs/alerts")
            alerts_dir.mkdir(exist_ok=True, parents=True)
            
            alert_file = alerts_dir / f"alerts_{datetime.now().strftime('%Y%m%d')}.jsonl"
            
            async with aiofiles.open(alert_file, 'a') as f:
                await f.write(json.dumps(asdict(alert), ensure_ascii=False) + '\n')
        
        except Exception as e:
            self.logger.error(f"ä¿å­˜å‘Šè­¦å¤±è´¥: {e}")
    
    async def _alert_manager(self):
        """å‘Šè­¦ç®¡ç†å™¨"""
        while self.monitoring_active:
            try:
                # æ¸…ç†è¿‡æœŸå‘Šè­¦
                cutoff_time = datetime.now() - timedelta(days=7)
                self.alerts_history = [
                    a for a in self.alerts_history 
                    if datetime.fromisoformat(a.timestamp) > cutoff_time
                ]
                
                await asyncio.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"å‘Šè­¦ç®¡ç†å™¨é”™è¯¯: {e}")
                await asyncio.sleep(300)
    
    async def _report_generator(self):
        """æŠ¥å‘Šç”Ÿæˆå™¨"""
        while self.monitoring_active:
            try:
                current_hour = datetime.now().hour
                if current_hour in self.config["report_generation_hours"]:
                    await self._generate_comprehensive_report()
                    await asyncio.sleep(3600)  # ç­‰å¾…1å°æ—¶é¿å…é‡å¤ç”Ÿæˆ
                
                await asyncio.sleep(300)  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"æŠ¥å‘Šç”Ÿæˆå™¨é”™è¯¯: {e}")
                await asyncio.sleep(600)
    
    async def _generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆç›‘æ§æŠ¥å‘Š"""
        try:
            report = {
                "report_id": f"monitor_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "reporting_period": "24h",
                
                # ç³»ç»Ÿå¥åº·æ¦‚è¿°
                "system_health_summary": self._summarize_system_health(),
                
                # ä¿¡å·ä¸€è‡´æ€§æ¦‚è¿°
                "signal_consistency_summary": self._summarize_signal_consistency(),
                
                # ç»„ä»¶çŠ¶æ€æ¦‚è¿°
                "component_status_summary": self.component_status,
                
                # å‘Šè­¦æ¦‚è¿°
                "alerts_summary": self._summarize_alerts(),
                
                # å»ºè®®å’Œè¡ŒåŠ¨é¡¹
                "recommendations": self._generate_recommendations()
            }
            
            # ä¿å­˜æŠ¥å‘Š
            reports_dir = Path("results/monitoring_reports")
            reports_dir.mkdir(exist_ok=True, parents=True)
            
            report_file = reports_dir / f"{report['report_id']}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ç”Ÿæˆç›‘æ§æŠ¥å‘Š: {report_file}")
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _summarize_system_health(self) -> Dict[str, Any]:
        """æ€»ç»“ç³»ç»Ÿå¥åº·çŠ¶å†µ"""
        if not self.system_metrics_history:
            return {"status": "no_data"}
        
        recent_metrics = self.system_metrics_history[-24:]  # æœ€è¿‘24ä¸ªæ•°æ®ç‚¹
        
        return {
            "avg_cpu_usage": np.mean([m.cpu_usage for m in recent_metrics]),
            "max_cpu_usage": np.max([m.cpu_usage for m in recent_metrics]),
            "avg_memory_usage": np.mean([m.memory_usage for m in recent_metrics]),
            "max_memory_usage": np.max([m.memory_usage for m in recent_metrics]),
            "avg_disk_usage": np.mean([m.disk_usage for m in recent_metrics]),
            "total_errors": sum([m.error_count for m in recent_metrics]),
            "total_warnings": sum([m.warning_count for m in recent_metrics]),
            "uptime_hours": recent_metrics[-1].uptime / 3600 if recent_metrics else 0
        }
    
    def _summarize_signal_consistency(self) -> Dict[str, Any]:
        """æ€»ç»“ä¿¡å·ä¸€è‡´æ€§"""
        if not self.signal_consistency_history:
            return {"status": "no_data"}
        
        recent_consistency = self.signal_consistency_history[-50:]  # æœ€è¿‘50ä¸ªä¿¡å·
        
        return {
            "avg_consistency_score": np.mean([c.consistency_score for c in recent_consistency]),
            "min_consistency_score": np.min([c.consistency_score for c in recent_consistency]),
            "avg_execution_delay": np.mean([c.execution_delay for c in recent_consistency if c.execution_delay]),
            "signals_with_issues": len([c for c in recent_consistency if c.consistency_score < 0.8]),
            "total_signals_analyzed": len(recent_consistency)
        }
    
    def _summarize_alerts(self) -> Dict[str, Any]:
        """æ€»ç»“å‘Šè­¦æƒ…å†µ"""
        recent_alerts = [a for a in self.alerts_history 
                        if (datetime.now() - datetime.fromisoformat(a.timestamp)).days < 1]
        
        return {
            "total_alerts_24h": len(recent_alerts),
            "critical_alerts": len([a for a in recent_alerts if a.severity == "CRITICAL"]),
            "high_alerts": len([a for a in recent_alerts if a.severity == "HIGH"]),
            "medium_alerts": len([a for a in recent_alerts if a.severity == "MEDIUM"]),
            "alerts_by_category": {
                category: len([a for a in recent_alerts if a.category == category])
                for category in set([a.category for a in recent_alerts])
            }
        }
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆå»ºè®®å’Œè¡ŒåŠ¨é¡¹"""
        recommendations = []
        
        # åŸºäºç³»ç»Ÿå¥åº·ç”Ÿæˆå»ºè®®
        if self.system_metrics_history:
            latest_metrics = self.system_metrics_history[-1]
            
            if latest_metrics.cpu_usage > 80:
                recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–æ‰©å®¹")
            
            if latest_metrics.memory_usage > 80:
                recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼")
            
            if latest_metrics.error_count > 10:
                recommendations.append("é”™è¯¯æ•°é‡è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—")
        
        # åŸºäºä¿¡å·ä¸€è‡´æ€§ç”Ÿæˆå»ºè®®
        if self.signal_consistency_history:
            recent_consistency = self.signal_consistency_history[-10:]
            avg_score = np.mean([c.consistency_score for c in recent_consistency])
            
            if avg_score < 0.8:
                recommendations.append("ä¿¡å·æ‰§è¡Œä¸€è‡´æ€§è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ‰§è¡Œè·¯å¾„")
        
        # åŸºäºç»„ä»¶çŠ¶æ€ç”Ÿæˆå»ºè®®
        for component, status in self.component_status.items():
            if status.get("status") == "STALE":
                recommendations.append(f"{component}ç»„ä»¶æ•°æ®é™ˆæ—§ï¼Œå»ºè®®æ£€æŸ¥æ›´æ–°æœºåˆ¶")
            elif status.get("status") == "ERROR":
                recommendations.append(f"{component}ç»„ä»¶å¼‚å¸¸ï¼Œå»ºè®®ç«‹å³æ£€æŸ¥")
        
        return recommendations if recommendations else ["ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæ— ç‰¹æ®Šå»ºè®®"]

# è¿è¡Œæ¥å£
async def run_continuous_monitoring():
    """è¿è¡ŒæŒç»­ç›‘æ§"""
    monitor = ContinuousSystemMonitor()
    
    try:
        await monitor.start_monitoring()
    except KeyboardInterrupt:
        await monitor.stop_monitoring()
        print("ç›‘æ§å·²åœæ­¢")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨DipMasteræŒç»­ç³»ç»Ÿç›‘æ§...")
    asyncio.run(run_continuous_monitoring())